{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "client_5d5d24a96f0d417089f2601d83de16a9 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='CfTULjIbd6PYKlQASmTULw8xS8emXJanwHA3k3M7nESJ',\n",
    "    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "body = client_5d5d24a96f0d417089f2601d83de16a9.get_object(Bucket='default-donotdelete-pr-zdopmag1jdqncb',Key='Combined_News_DJIA.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df_data_1 = pd.read_csv(body)\n",
    "df_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
       "      <td>b'This is a busy day:  The European Union has ...</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
       "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
       "      <td>b' Russia has just beaten the United States ov...</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
       "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
       "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
       "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
       "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
       "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
       "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'U.S. troops still in Georgia (did you know t...</td>\n",
       "      <td>b'Why Russias response to Georgia was right'</td>\n",
       "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
       "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
       "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
       "      <td>b'War in Georgia: The Israeli connection'</td>\n",
       "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
       "      <td>b'Christopher King argues that the US and NATO...</td>\n",
       "      <td>b'America: The New Mexico?'</td>\n",
       "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
       "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
       "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
       "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
       "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
       "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
       "      <td>b'Russian forces sink Georgian ships '</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Elephants extinct by 2020?'</td>\n",
       "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
       "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
       "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
       "      <td>b'Israeli defence minister: US against strike ...</td>\n",
       "      <td>b'Gorbachev: We Had No Choice'</td>\n",
       "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
       "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
       "      <td>b'Georgian president  says US military will ta...</td>\n",
       "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>1</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
       "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
       "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
       "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
       "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
       "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
       "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n",
       "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
       "      <td>b'War in the Caucasus is as much the product o...</td>\n",
       "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
       "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
       "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
       "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
       "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
       "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
       "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n",
       "2  2008-08-12      0  b'Remember that adorable 9-year-old who sang a...   \n",
       "3  2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...   \n",
       "4  2008-08-14      1  b'All the experts admit that we should legalis...   \n",
       "\n",
       "                                                Top2  \\\n",
       "0            b'BREAKING: Musharraf to be impeached.'   \n",
       "1        b'Bush puts foot down on Georgian conflict'   \n",
       "2                 b\"Russia 'ends Georgia operation'\"   \n",
       "3  b\"When the president ordered to attack Tskhinv...   \n",
       "4  b'War in South Osetia - 89 pictures made by a ...   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into So...   \n",
       "1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n",
       "2  b'\"If we had no sexual harassment we would hav...   \n",
       "3  b' Israel clears troops who killed Reuters cam...   \n",
       "4  b'Swedish wrestler Ara Abrahamian throws away ...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital...   \n",
       "1  b'Georgian army flees in disarray as Russians ...   \n",
       "2  b\"Al-Qa'eda is losing support in Iraq because ...   \n",
       "3  b'Britain\\'s policy of being tough on drugs is...   \n",
       "4  b'Russia exaggerated the death toll in South O...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. ...   \n",
       "1      b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "2  b'Ceasefire in Georgia: Putin Outmaneuvers the...   \n",
       "3  b'Body of 14 year old found in trunk; Latest (...   \n",
       "4  b'Missile That Killed 9 Inside Pakistan May Ha...   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia...   \n",
       "1  b'What were the Mossad with fraudulent New Zea...   \n",
       "2  b'Why Microsoft and Intel tried to kill the XO...   \n",
       "3  b'China has moved 10 *million* quake survivors...   \n",
       "4  b\"Rushdie Condemns Random House's Refusal to P...   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n",
       "1  b'Russia angered by Israeli military sale to G...   \n",
       "2  b'Stratfor: The Russo-Georgian War and the Bal...   \n",
       "3  b\"Bush announces Operation Get All Up In Russi...   \n",
       "4  b'Poland and US agree to missle defense deal. ...   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but...  ...   \n",
       "1  b'An American citizen living in S.Ossetia blam...  ...   \n",
       "2  b\"I'm Trying to Get a Sense of This Whole Geor...  ...   \n",
       "3             b'Russian forces sink Georgian ships '  ...   \n",
       "4  b'Will the Russians conquer Tblisi? Bet on it,...  ...   \n",
       "\n",
       "                                               Top16  \\\n",
       "0  b'Georgia Invades South Ossetia - if Russia ge...   \n",
       "1  b'Israel and the US behind the Georgian aggres...   \n",
       "2  b'U.S. troops still in Georgia (did you know t...   \n",
       "3                      b'Elephants extinct by 2020?'   \n",
       "4  b'Bank analyst forecast Georgian crisis 2 days...   \n",
       "\n",
       "                                               Top17  \\\n",
       "0                b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1  b'\"Do not believe TV, neither Russian nor Geor...   \n",
       "2       b'Why Russias response to Georgia was right'   \n",
       "3  b'US humanitarian missions soon in Georgia - i...   \n",
       "4  b\"Georgia confict could set back Russia's US r...   \n",
       "\n",
       "                                               Top18  \\\n",
       "0  b'Condoleezza Rice: \"The US would not act to p...   \n",
       "1  b'Riots are still going on in Montreal (Canada...   \n",
       "2  b'Gorbachev accuses U.S. of making a \"serious ...   \n",
       "3             b\"Georgia's DDOS came from US sources\"   \n",
       "4  b'War in the Caucasus is as much the product o...   \n",
       "\n",
       "                                               Top19  \\\n",
       "0  b'This is a busy day:  The European Union has ...   \n",
       "1    b'China to overtake US as largest manufacturer'   \n",
       "2         b'Russia, Georgia, and NATO: Cold War Two'   \n",
       "3  b'Russian convoy heads into Georgia, violating...   \n",
       "4  b'\"Non-media\" photos of South Ossetia/Georgia ...   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n",
       "1                     b'War in South Ossetia [PICS]'   \n",
       "2  b'Remember that adorable 62-year-old who led y...   \n",
       "3  b'Israeli defence minister: US against strike ...   \n",
       "4  b'Georgian TV reporter shot by Russian sniper ...   \n",
       "\n",
       "                                               Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n",
       "1  b'Israeli Physicians Group Condemns State Tort...   \n",
       "2          b'War in Georgia: The Israeli connection'   \n",
       "3                     b'Gorbachev: We Had No Choice'   \n",
       "4  b'Saudi Arabia: Mother moves to block child ma...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  b'Caucasus in crisis: Georgia invades South Os...   \n",
       "1  b' Russia has just beaten the United States ov...   \n",
       "2  b'All signs point to the US encouraging Georgi...   \n",
       "3  b'Witness: Russian forces head towards Tbilisi...   \n",
       "4   b'Taliban wages war on humanitarian aid workers'   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a se...   \n",
       "1  b'Perhaps *the* question about the Georgia - R...   \n",
       "2  b'Christopher King argues that the US and NATO...   \n",
       "3  b' Quarter of Russians blame U.S. for conflict...   \n",
       "4  b'Russia: World  \"can forget about\" Georgia\\'s...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Ban...   \n",
       "1                 b'Russia is so much better at war'   \n",
       "2                        b'America: The New Mexico?'   \n",
       "3  b'Georgian president  says US military will ta...   \n",
       "4  b'Darfur rebels accuse Sudan of mounting major...   \n",
       "\n",
       "                                               Top25  \n",
       "0           b\"No Help for Mexico's Kidnapping Surge\"  \n",
       "1  b\"So this is what it's come to: trading sex fo...  \n",
       "2  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...  \n",
       "3  b'2006: Nobel laureate Aleksander Solzhenitsyn...  \n",
       "4  b'Philippines : Peace Advocate say Muslims nee...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_1 = pd.read_csv('Data/Combined_News_DJIA.csv')\n",
    "df_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1989, 27)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data and pre-process the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stops = stopwords.words('english')\n",
    "stops.extend('b,.,[,],(,),;,/,-,\\',?,\",:,<,>,n\\'t,|,#,\\'s,\\\",\\'re,\\'ve,\\'ll,\\'d,\\'re'.split(','))\n",
    "stops.extend(',')\n",
    "stops[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = df_data_1[df_data_1['Date'] < '2015-01-01'].iloc[:,2:27]\n",
    "train_target = df_data_1[df_data_1['Date'] < '2015-01-01']['Label']\n",
    "test_raw = df_data_1[df_data_1['Date'] > '2014-12-31'].iloc[:,2:27]\n",
    "test_target = df_data_1[df_data_1['Date'] > '2014-12-31']['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_down = np.sum(train_target == 0)\n",
    "train_up = np.sum(train_target == 1)\n",
    "\n",
    "test_down = np.sum(test_target == 0)\n",
    "test_up = np.sum(test_target == 1)\n",
    "\n",
    "print('In train data set {} days is down and {} days is up'.format(train_down,train_up))\n",
    "print('In test data set {} days is down and {} days is up'.format(test_down,test_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw.isnull().sum().sum() # there is some columns with na value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            try:\n",
    "                df.iloc[row,col] = [word.lower() for word in word_tokenize(df.iloc[row,col]) if word not in stops and word.isalpha()]\n",
    "            except:\n",
    "                print(\"Row {} and colum {} is Na\".format(row,col))\n",
    "                \n",
    "    print('Finish text pre-processing')\n",
    "    return df          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pre = pre_process(train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pre.head() # all the string has been token and clean stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pre = pre_process(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is NLTK version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "import nltk.classify.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_feature(df,num_news,trainable=True):\n",
    "    trainheadlines = []\n",
    "    for row in range(0,len(df)):\n",
    "        top_news = []\n",
    "        for x in df.iloc[row,0:num_news]:\n",
    "            top_news += x\n",
    "        trainheadlines.append(top_news)  # combine the number of top news word as one list \n",
    "        \n",
    "    train_feature = []    \n",
    "    for i in tqdm(range(len(trainheadlines))):\n",
    "        d = {}\n",
    "        for word in trainheadlines[i]:\n",
    "            d[word] = True\n",
    "        if trainable == True:\n",
    "            train_feature.append((d,train_target[i]))  # change the word into true lable, and sentence lable\n",
    "        else:\n",
    "            train_feature.append((d,test_target[i+len(train_pre)]))\n",
    "        \n",
    "    print(\"Finish...\") \n",
    "    print(\"We use top {} news as feature\".format(num_news))\n",
    "    return train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_news = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = get_train_feature(train_pre,num_news,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = get_train_feature(test_pre,num_news,trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a NaiveBayesClassifier with our training feature words.\n",
    "classifier = NaiveBayesClassifier.train(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for test data by using {} top news is: {}'.format(num_news,nltk.classify.util.accuracy(classifier, test_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see which words fit best in each class.\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_acc = []\n",
    "for i in range(1,23):\n",
    "    train_feature = get_train_feature(train_pre,i,trainable=True)\n",
    "    test_feature = get_train_feature(test_pre,i,trainable=False)\n",
    "    classifier = NaiveBayesClassifier.train(train_feature)\n",
    "    NB_acc.append(nltk.classify.util.accuracy(classifier, test_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(NB_acc)\n",
    "plt.title('NavieBayes Result')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Top New Use')\n",
    "plt.xticks(np.arange(len(NB_acc)), np.arange(1, len(NB_acc)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the above plot, we could see when we use top 2 news as training dataset, we could get highest accuracy in Navie Bayes model. The accuracy is new 52% which also is higher than random guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see most the accuracy is near 50% which is same as random guess probability. However, from the informative features we can see the word like hints, vanished, and missed those negative words take obvious higher ratio in lable 0 (down)\n",
    "## We maybe think need to swith to n-gram model or change to BOW using machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW By Using Count Vectorizer  and TF-IDF (sklearn version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = df_data_1[df_data_1['Date'] < '2015-01-01'].iloc[:,2:27]\n",
    "train_target1 = df_data_1[df_data_1['Date'] < '2015-01-01']['Label']\n",
    "test1 = df_data_1[df_data_1['Date'] > '2014-12-31'].iloc[:,2:27]\n",
    "test_target1 = df_data_1[df_data_1['Date'] > '2014-12-31']['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare(train,test,num_news,type_vertor,ngram=False):\n",
    "    trainheadlines = []\n",
    "    for row in range(0,len(train.index)):\n",
    "        trainheadlines.append(' '.join(str(x) for x in train.iloc[row,:num_news])) # combine all news into one sentence dependence how many news you want\n",
    "    \n",
    "    testheadlines = []\n",
    "    for row in range(0,len(test.index)):\n",
    "        testheadlines.append(' '.join(str(x) for x in test.iloc[row,:num_news]))  \n",
    "        \n",
    "    if type_vertor == 'count':\n",
    "        if ngram == True:\n",
    "            count_vec = CountVectorizer(stop_words='english',ngram_range=(2,2))\n",
    "        else:\n",
    "            count_vec = CountVectorizer(stop_words='english')\n",
    "        \n",
    "        count_train = count_vec.fit_transform(trainheadlines)\n",
    "        count_test = count_vec.transform(testheadlines)\n",
    "        \n",
    "        count_occur_df = pd.DataFrame((count, word) for word, count in zip(count_train.toarray().tolist()[0], count_vec.get_feature_names()))\n",
    "        count_occur_df.columns = ['Word', 'Count']\n",
    "        count_occur_df.sort_values('Count', ascending=False, inplace=True)\n",
    "        print(\"The count matrix shape is {}\".format(count_train.shape))\n",
    "        print(\"Top 5 count occurence is: \")\n",
    "        print(count_occur_df.head())\n",
    "        return count_train, count_test\n",
    "    \n",
    "    if type_vertor == 'tf-idf':\n",
    "        if ngram == True:\n",
    "            tfidf_vec = TfidfVectorizer(max_df=0.97, max_features = 100000, stop_words='english',ngram_range=(2,2))\n",
    "        else:\n",
    "            tfidf_vec = TfidfVectorizer(max_df=0.97, max_features = 200000, stop_words='english')\n",
    "            \n",
    "        tfidf_train = tfidf_vec.fit_transform(trainheadlines)\n",
    "        tfidf_test = tfidf_vec.transform(testheadlines)\n",
    "        tfidf_count_occur_df = pd.DataFrame((count, word) for word, count in zip(tfidf_train.toarray().tolist()[0], tfidf_vec.get_feature_names()))\n",
    "        tfidf_count_occur_df.columns = ['Word', 'TF-IDF']\n",
    "        tfidf_count_occur_df.sort_values('TF-IDF', ascending=False, inplace=True)\n",
    "        print(\"The TF-IDF matrix shape is {}\".format(tfidf_train.shape))\n",
    "        print(\"Top 5 TF-IDF is: \")\n",
    "        print(tfidf_count_occur_df.head())\n",
    "        return tfidf_train, tfidf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_count_train,basic_count_test = data_prepare(train1,test1,20,'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tfidf_train,basic_tfidf_test = data_prepare(train1,test1,20,'tf-idf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with different vector way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train,test,train_label,test_label,num_news):\n",
    "    start = time.time()\n",
    "    model = LogisticRegression()\n",
    "    LR = model.fit(train,train_label)\n",
    "    predictions = LR.predict(test)\n",
    "    acc = np.mean(predictions == test_label)\n",
    "    print('This model takes {} second by using sklearn.'.format(time.time()-start))\n",
    "    print('Accuracy for test data by using {} top news is: {}'.format(num_news,acc))\n",
    "    return LR,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic_LR_count,count_acc = model(basic_count_train,basic_count_test,train_target1,test_target1,num_news) \n",
    "# This is basic model by using count occurence which is not good as navie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic_LR_tfidf,tfidf_acc = model(basic_tfidf_train,basic_tfidf_test,train_target1,test_target1,num_news) \n",
    "# This is basic model by using cTF-IDF which is same as navie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basic_count_acc = []\n",
    "for i in range(1,26):   # this is basic count vector by using logistic regression\n",
    "    basic_count_train,basic_count_test = data_prepare(train1,test1,i,'count')\n",
    "    Basic_LR_count,count_acc = model(basic_count_train,basic_count_test,train_target1,test_target1,i) \n",
    "    basic_count_acc.append(count_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(basic_count_acc)\n",
    "plt.title('Logistic Regression With Count Vector Result')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Top New Use')\n",
    "plt.xticks(np.arange(len(basic_count_acc)), np.arange(1, len(basic_count_acc)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From above plot, we could see with the top news we use increasing, the accuracy is decreasing. I think because we add too much noise to model and logistic  regression could preformence best only on n >> p even with lasso penalty.  \n",
    "### The best accuracy is around 53% by using only one top news which is better than Navie Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basic_tfidf_acc = []\n",
    "for i in range(1,26):   # this is basic tf-idf vector by using logistic regression\n",
    "    basic_tfidf_train,basic_tfidf_test = data_prepare(train1,test1,i,'tf-idf')\n",
    "    Basic_LR_tfidf,tfidf_acc = model(basic_tfidf_train,basic_tfidf_test,train_target1,test_target1,i)  \n",
    "    basic_tfidf_acc.append(tfidf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(basic_tfidf_acc)\n",
    "plt.title('Logistic Regression With TF-IDF Vector Result')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Top New Use')\n",
    "plt.xticks(np.arange(len(basic_tfidf_acc)), np.arange(1, len(basic_tfidf_acc)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From above plot, we could see with the top news we use increasing, the accuracy is decreasing first then increasing. I think because we add too much noise to model and logistic regression could preformence best only on n >> p even with lasso penalty.\n",
    "### The best accuracy is around 51% by using two top news which is not good as Navie Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "advance_count_acc = []\n",
    "for i in range(1,26):   # this is advance count vector in ngram by using logistic regression\n",
    "    advance_count_train,advance_count_test = data_prepare(train1,test1,i,'count',ngram=True)\n",
    "    Advance_LR_count,Advance_count_acc = model(advance_count_train,advance_count_test,train_target1,test_target1,i) \n",
    "    advance_count_acc.append(Advance_count_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(advance_count_acc)\n",
    "plt.title('Logistic Regression With Count Vector Use Ngram Result')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Top New Use')\n",
    "plt.xticks(np.arange(len(advance_count_acc)), np.arange(1, len(advance_count_acc)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From above plot,we could find most of accuracy is above 50% and the best accuracy is near 54% which is get by using top 18 news and so far this is the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "advance_tfidf_acc = []\n",
    "for i in range(1,26):   # this is advance TD-IDF vector in ngram by using logistic regression, for this one I shrink the number of feature to 100000 due to CPU\n",
    "    advance_tfidf_train,advance_tfidf_test = data_prepare(train1,test1,i,'tf-idf',ngram=True)\n",
    "    Advance_LR_tfidf,Advance_tfidf_acc = model(advance_tfidf_train,advance_tfidf_test,train_target1,test_target1,i) \n",
    "    advance_tfidf_acc.append(Advance_tfidf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(advance_tfidf_acc)\n",
    "plt.title('Logistic Regression With TF-IDF Vector Use Ngram Result')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Top New Use')\n",
    "plt.xticks(np.arange(len(advance_tfidf_acc)), np.arange(1, len(advance_tfidf_acc)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From above plot, we can see the best accuracy is near 51.33% which is using top 1 or top 2 . Since I shrink the number of feature to 100000, some of the information maybe exclude. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB model with different vertor way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model(train,test,train_label,test_label,num_news):\n",
    "    start = time.time()\n",
    "    xgb_model = XGBClassifier()\n",
    "    XGB = xgb_model.fit(train,train_label)\n",
    "    predictions = XGB.predict(test)\n",
    "    acc = np.mean(predictions == test_label)\n",
    "    print('This model takes {} second by using sklearn.'.format(time.time()-start))\n",
    "    print('Accuracy for test data by using {} top news is: {}'.format(num_news,acc))\n",
    "    return XGB,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "advance_count_acc = []\n",
    "for i in range(1,26):   # this is advance count vector in ngram by using XGB model\n",
    "    advance_count_train,advance_count_test = data_prepare(train1,test1,i,'count',ngram=True)\n",
    "    Advance_XGB_count,Advance_count_acc = xgb_model(advance_count_train,advance_count_test,train_target1,test_target1,i) \n",
    "    advance_count_acc.append(Advance_count_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(advance_count_acc)\n",
    "plt.title('XGB With Count Vector Use Ngram Result')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Top New Use')\n",
    "plt.xticks(np.arange(len(advance_count_acc)), np.arange(1, len(advance_count_acc)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From above plot we could see most of accuracy is below 50% and the best is near 52% which is not really good and XGB takes longer when training. \n",
    "### For future improvement, I would like to do hyper-parameters turning ML model or maybe change to deep learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belowe will be spark version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ibmos2spark\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'service_id': 'iam-ServiceId-8ccbe184-10b7-4c6c-94e6-2edebc3056d0',\n",
    "    'iam_service_endpoint': 'https://iam.ng.bluemix.net/oidc/token',\n",
    "    'api_key': 'CfTULjIbd6PYKlQASmTULw8xS8emXJanwHA3k3M7nESJ'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_5d5d24a96f0d417089f2601d83de16a9_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_data_2 = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .load(cos.url('Combined_News_DJIA.csv', 'default-donotdelete-pr-zdopmag1jdqncb'))\n",
    "df_data_2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2 = df_data_2.dropna() # clean all Na value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import * # Change column type\n",
    "new_df2 = new_df2.withColumn(\"Label\", new_df2[\"Label\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, Tokenizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import concat, col, lit, concat_ws, udf, array\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_combine(num_news):\n",
    "    col_list = new_df2.columns[2:][:num_news]\n",
    "    df = new_df2.withColumn('concat_cols',concat(*col_list)) # select how many top news you want to concat as one column\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_df2 = df_combine(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_df2.count(),len(com_df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "com_df2.select('concat_cols').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend([\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\",\"b\"])\n",
    "stops[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"concat_cols\", outputCol=\"words\")\n",
    "# stop words\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(stops)\n",
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=200000, minDF=2) # indicate min number of term show in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwordsRemover, countVectors])\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(com_df2)\n",
    "dataset = pipelineFit.transform(com_df2)\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2 = dataset[dataset['Date'] < '2015-01-01']\n",
    "test_df2 = dataset[dataset['Date'] > '2014-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_df2 = train_df2.dropna()\n",
    "test_new_df2 = test_df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_df2.count(), test_new_df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"Label\", featuresCol=\"features\", maxIter=20, regParam=0.8, elasticNetParam=0)\n",
    "lrModel = lr.fit(train_new_df2)\n",
    "predictions = lrModel.transform(test_new_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Label',predictionCol=\"prediction\")\n",
    "lr_acc = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression with spark version is {0:0.3f}'.format(lr_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Deep Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = df_data_1[df_data_1['Date'] < '2015-01-01'].iloc[:,2:27]\n",
    "train_target2 = df_data_1[df_data_1['Date'] < '2015-01-01']['Label']\n",
    "test2 = df_data_1[df_data_1['Date'] > '2014-12-31'].iloc[:,2:27]\n",
    "test_target2 = df_data_1[df_data_1['Date'] > '2014-12-31']['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare2(train,test,num_news,m_len):\n",
    "    trainheadlines2 = []\n",
    "    for row in range(0,len(train.index)):\n",
    "        trainheadlines2.append('00'.join(str(x) for x in train.iloc[row,:num_news])) # combine all news into one sentence dependence how many news you want\n",
    "    \n",
    "    testheadlines2 = []\n",
    "    for row in range(0,len(test.index)):\n",
    "        testheadlines2.append('00'.join(str(x) for x in test.iloc[row,:num_news]))  \n",
    "        \n",
    "    tk = Tokenizer(lower = True)\n",
    "    tk.fit_on_texts(trainheadlines2)\n",
    "    \n",
    "    X_train = tk.texts_to_sequences(trainheadlines2)\n",
    "    X_test = tk.texts_to_sequences(testheadlines2)\n",
    "    print('Number of unique word is {}'.format(len(tk.word_index)))\n",
    "    \n",
    "    max_len = m_len\n",
    "    X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "    X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "    print(X_train.shape,X_test.shape)\n",
    "    print('Finish data preparing...')\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = data_prepare2(train2,test2,20,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Embedding(max_features,200,mask_zero=True))\n",
    "model1.add(Bidirectional(LSTM(128,dropout=0.4, recurrent_dropout=0.4,return_sequences=True)))\n",
    "model1.add(Bidirectional(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False)))\n",
    "model1.add(Dense(1,activation='softmax'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X_train, train_target2, validation_data=(X_test, test_target2),epochs=3, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The accuracy is near 51% but no more improve after first epoch. Try other model later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "import spacy  # For preprocessing\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = df_data_1[df_data_1['Date'] < '2015-01-01'].iloc[:,2:27]\n",
    "train_target3 = df_data_1[df_data_1['Date'] < '2015-01-01']['Label']\n",
    "test3 = df_data_1[df_data_1['Date'] > '2014-12-31'].iloc[:,2:27]\n",
    "test_target3 = df_data_1[df_data_1['Date'] > '2014-12-31']['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare3(train,test,num_news):\n",
    "    trainheadlines3 = []\n",
    "    for row in range(0,len(train.index)):\n",
    "        trainheadlines3.append('0'.join(str(x[2:]) for x in train.iloc[row,:num_news])) # combine all news into one sentence dependence how many news you want\n",
    "                                                                                        #  clean the b' or each news \n",
    "    testheadlines3 = []\n",
    "    for row in range(0,len(test.index)):\n",
    "        testheadlines3.append('0'.join(str(x[2:]) for x in test.iloc[row,:num_news])) \n",
    "        \n",
    "    print('Finish combine the news...')  \n",
    "    \n",
    "    nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "    def cleaning(doc):\n",
    "        # Lemmatizes and removes stopwords, punctuation\n",
    "        # doc needs to be a spacy Doc object\n",
    "        txt = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "        # Word2Vec uses context words to learn the vector representation of a target word,\n",
    "        # if a sentence is only one or two words long,\n",
    "        # the benefit for the training is very small\n",
    "        if len(txt) > 2:\n",
    "            return ' '.join(txt)   \n",
    "        \n",
    "    brief_cleaning_train = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in trainheadlines3)\n",
    "    brief_cleaning_test = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in testheadlines3)\n",
    "    \n",
    "    t = time()\n",
    "\n",
    "    txt_train = [cleaning(doc) for doc in nlp.pipe(brief_cleaning_train, batch_size=50, n_threads=-1)]\n",
    "    txt_test = [cleaning(doc) for doc in nlp.pipe(brief_cleaning_test, batch_size=50, n_threads=-1)]\n",
    "\n",
    "    print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "    \n",
    "    df_clean_train = pd.DataFrame({'clean': txt_train})\n",
    "    df_clean_train = df_clean_train.dropna().drop_duplicates()\n",
    "    \n",
    "    df_clean_test = pd.DataFrame({'clean': txt_test})\n",
    "    df_clean_test = df_clean_test.dropna().drop_duplicates()\n",
    "    \n",
    "    print('Finish cleaning...')\n",
    "    return df_clean_train, df_clean_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish combine the news...\n",
      "Time to clean up everything: 0.81 mins\n",
      "Finish cleaning...\n"
     ]
    }
   ],
   "source": [
    "df_clean_train, df_clean_test = data_prepare3(train3,test3,22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'georgia down russian warplane country brink war break musharraf impeach russia today column troop roll south ossetia footage fight youtube russian tank move capital south ossetia reportedly completely destroy georgian artillery fire afghan child rape impunity u n official say sick year old rape russian tank enter south ossetia whilst georgia shoot russian jet break georgia invades south ossetia russia warn intervene enemy combatent trial sham salim haman sentence year keep longer feel like georgian troop retreat s osettain capital presumably leave people kill video u s prep georgia war russia rice give green light israel attack iran say u s veto israeli military op announce class action lawsuit behalf american public fbi russia georgia war nyt story open ceremony olympics fucking disgrace proof decline journalism china tell bush stay country affair world war iii start today georgia invades south ossetia russia get involve nato absorb georgia unleash scale war al qaeda face islamist backlash condoleezza rice act prevent israeli strike iran israeli defense minister ehud barak israel prepare uncompromise victory case military hostility busy day european union approve new sanction iran protest nuclear programme georgia withdraw soldier iraq help fight russian force georgia breakaway region south ossetia pentagon think attack iran bad idea news amp world report caucasus crisis georgia invades south ossetia'"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_train.clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>georgia down russian warplane country brink wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will not america nato help will not help help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remember adorable year old sing open ceremony ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u s refuse israel weapon attack iran report ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expert admit legalise drug war south osetia pi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean\n",
       "0  georgia down russian warplane country brink wa...\n",
       "1  will not america nato help will not help help ...\n",
       "2  remember adorable year old sing open ceremony ...\n",
       "3    u s refuse israel weapon attack iran report ...\n",
       "4  expert admit legalise drug war south osetia pi..."
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>st case cancer result sheer bad luck unhealthy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scow gt beijing high speed train reduce trip t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oil fall barrel yota give away fuel cell pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hots fire french magazine hq bibi netanyahus c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w charlie hebdo issue come week hard suffer gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean\n",
       "0  st case cancer result sheer bad luck unhealthy...\n",
       "1  scow gt beijing high speed train reduce trip t...\n",
       "2    oil fall barrel yota give away fuel cell pat...\n",
       "3  hots fire french magazine hq bibi netanyahus c...\n",
       "4  w charlie hebdo issue come week hard suffer gr..."
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_bigrams(df):\n",
    "    t = time()\n",
    "    sent = [row.split() for row in df['clean']] # seperate the each word for each sentence\n",
    "    phrases = Phrases(sent, min_count=5, progress_per=100) # detect the bigrams combinetion, Creates the relevant phrases from the list of sentences:\n",
    "    bigram = Phraser(phrases) # save memory for bigrams detection \n",
    "    sentences = bigram[sent] # Transform the corpus based on the bigrams detected\n",
    "    print('Time to detect everything: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:54:06: collecting all words and their counts\n",
      "INFO - 16:54:06: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #100, processed 4521 words and 6291 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #200, processed 9458 words and 11981 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #300, processed 15480 words and 18652 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #400, processed 21366 words and 24802 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #500, processed 27217 words and 30691 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #600, processed 33566 words and 37144 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #700, processed 39409 words and 42786 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #800, processed 45229 words and 48418 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #900, processed 51066 words and 53885 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #1000, processed 56934 words and 59288 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #1100, processed 63022 words and 64822 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #1200, processed 68703 words and 69917 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #1300, processed 74873 words and 75374 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #1400, processed 81217 words and 80914 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #1500, processed 86978 words and 85858 word types\n",
      "INFO - 16:54:06: PROGRESS: at sentence #1600, processed 92748 words and 90924 word types\n",
      "INFO - 16:54:06: collected 91482 word types from a corpus of 93394 words (unigram + bigrams) and 1611 sentences\n",
      "INFO - 16:54:06: using 91482 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 16:54:06: source_vocab length 91482\n",
      "INFO - 16:54:07: Phraser built with 339 phrasegrams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to detect everything: 0.02 mins\n"
     ]
    }
   ],
   "source": [
    "sentences = data_bigrams(df_clean_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12733"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['say',\n",
       " 'government',\n",
       " 'people',\n",
       " 'kill',\n",
       " 'israel',\n",
       " 'world',\n",
       " 'police',\n",
       " 'man',\n",
       " 'year',\n",
       " 'woman']"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10] \n",
    "# mainly a sanity check of the effectiveness of the lemmatization, removal of stopwords, punctuation, and addition of bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=5,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.003, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:54:30: collecting all words and their counts\n",
      "INFO - 16:54:30: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #100, processed 4316 words, keeping 2123 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #200, processed 9021 words, keeping 3394 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #300, processed 14808 words, keeping 4658 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #400, processed 20451 words, keeping 5624 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #500, processed 26036 words, keeping 6458 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #600, processed 32124 words, keeping 7409 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #700, processed 37723 words, keeping 8101 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #800, processed 43278 words, keeping 8794 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #900, processed 48862 words, keeping 9359 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #1000, processed 54479 words, keeping 9891 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #1100, processed 60291 words, keeping 10428 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #1200, processed 65680 words, keeping 10911 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #1300, processed 71549 words, keeping 11390 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #1400, processed 77595 words, keeping 11847 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #1500, processed 83094 words, keeping 12241 word types\n",
      "INFO - 16:54:30: PROGRESS: at sentence #1600, processed 88602 words, keeping 12688 word types\n",
      "INFO - 16:54:30: collected 12733 word types from a corpus of 89216 raw words and 1611 sentences\n",
      "INFO - 16:54:30: Loading a fresh vocabulary\n",
      "INFO - 16:54:30: effective_min_count=5 retains 3526 unique words (27% of original 12733, drops 9207)\n",
      "INFO - 16:54:30: effective_min_count=5 leaves 74718 word corpus (83% of original 89216, drops 14498)\n",
      "INFO - 16:54:30: deleting the raw counts dictionary of 12733 items\n",
      "INFO - 16:54:30: sample=6e-05 downsamples 1658 most-common words\n",
      "INFO - 16:54:30: downsampling leaves estimated 40477 word corpus (54.2% of prior 74718)\n",
      "INFO - 16:54:30: estimated required memory for 3526 words and 300 dimensions: 10225400 bytes\n",
      "INFO - 16:54:30: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.02 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=100)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:54:33: training model with 3 workers on 3526 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
      "INFO - 16:54:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:33: EPOCH - 1 : training on 89216 raw words (40306 effective words) took 0.4s, 91981 effective words/s\n",
      "INFO - 16:54:34: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:34: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:34: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:34: EPOCH - 2 : training on 89216 raw words (40565 effective words) took 0.5s, 79902 effective words/s\n",
      "INFO - 16:54:34: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:34: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:34: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:34: EPOCH - 3 : training on 89216 raw words (40532 effective words) took 0.4s, 104784 effective words/s\n",
      "INFO - 16:54:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:35: EPOCH - 4 : training on 89216 raw words (40666 effective words) took 0.4s, 105548 effective words/s\n",
      "INFO - 16:54:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:35: EPOCH - 5 : training on 89216 raw words (40430 effective words) took 0.4s, 104443 effective words/s\n",
      "INFO - 16:54:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:36: EPOCH - 6 : training on 89216 raw words (40443 effective words) took 0.6s, 71546 effective words/s\n",
      "INFO - 16:54:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:36: EPOCH - 7 : training on 89216 raw words (40455 effective words) took 0.5s, 85298 effective words/s\n",
      "INFO - 16:54:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:36: EPOCH - 8 : training on 89216 raw words (40407 effective words) took 0.4s, 108982 effective words/s\n",
      "INFO - 16:54:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:37: EPOCH - 9 : training on 89216 raw words (40524 effective words) took 0.4s, 106230 effective words/s\n",
      "INFO - 16:54:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:37: EPOCH - 10 : training on 89216 raw words (40367 effective words) took 0.4s, 104374 effective words/s\n",
      "INFO - 16:54:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:38: EPOCH - 11 : training on 89216 raw words (40490 effective words) took 0.4s, 106127 effective words/s\n",
      "INFO - 16:54:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:38: EPOCH - 12 : training on 89216 raw words (40578 effective words) took 0.4s, 107404 effective words/s\n",
      "INFO - 16:54:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:38: EPOCH - 13 : training on 89216 raw words (40388 effective words) took 0.4s, 101041 effective words/s\n",
      "INFO - 16:54:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:39: EPOCH - 14 : training on 89216 raw words (40658 effective words) took 0.5s, 75792 effective words/s\n",
      "INFO - 16:54:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:39: EPOCH - 15 : training on 89216 raw words (40491 effective words) took 0.4s, 100701 effective words/s\n",
      "INFO - 16:54:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:40: EPOCH - 16 : training on 89216 raw words (40470 effective words) took 0.4s, 106424 effective words/s\n",
      "INFO - 16:54:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:40: EPOCH - 17 : training on 89216 raw words (40695 effective words) took 0.4s, 103187 effective words/s\n",
      "INFO - 16:54:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:41: EPOCH - 18 : training on 89216 raw words (40393 effective words) took 0.4s, 99366 effective words/s\n",
      "INFO - 16:54:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:41: EPOCH - 19 : training on 89216 raw words (40539 effective words) took 0.5s, 88294 effective words/s\n",
      "INFO - 16:54:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:42: EPOCH - 20 : training on 89216 raw words (40527 effective words) took 0.4s, 90922 effective words/s\n",
      "INFO - 16:54:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:42: EPOCH - 21 : training on 89216 raw words (40542 effective words) took 0.4s, 105515 effective words/s\n",
      "INFO - 16:54:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:42: EPOCH - 22 : training on 89216 raw words (40622 effective words) took 0.4s, 103531 effective words/s\n",
      "INFO - 16:54:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:43: EPOCH - 23 : training on 89216 raw words (40614 effective words) took 0.4s, 109628 effective words/s\n",
      "INFO - 16:54:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:43: worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:54:43: EPOCH - 24 : training on 89216 raw words (40691 effective words) took 0.4s, 114676 effective words/s\n",
      "INFO - 16:54:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:44: EPOCH - 25 : training on 89216 raw words (40619 effective words) took 0.4s, 106475 effective words/s\n",
      "INFO - 16:54:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:44: EPOCH - 26 : training on 89216 raw words (40674 effective words) took 0.4s, 105813 effective words/s\n",
      "INFO - 16:54:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:44: EPOCH - 27 : training on 89216 raw words (40501 effective words) took 0.4s, 112538 effective words/s\n",
      "INFO - 16:54:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:45: EPOCH - 28 : training on 89216 raw words (40571 effective words) took 0.4s, 114847 effective words/s\n",
      "INFO - 16:54:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:45: EPOCH - 29 : training on 89216 raw words (40379 effective words) took 0.4s, 113943 effective words/s\n",
      "INFO - 16:54:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:45: EPOCH - 30 : training on 89216 raw words (40525 effective words) took 0.4s, 108268 effective words/s\n",
      "INFO - 16:54:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:46: EPOCH - 31 : training on 89216 raw words (40714 effective words) took 0.4s, 113772 effective words/s\n",
      "INFO - 16:54:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:46: EPOCH - 32 : training on 89216 raw words (40435 effective words) took 0.4s, 107364 effective words/s\n",
      "INFO - 16:54:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:47: EPOCH - 33 : training on 89216 raw words (40417 effective words) took 0.4s, 108190 effective words/s\n",
      "INFO - 16:54:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:47: EPOCH - 34 : training on 89216 raw words (40569 effective words) took 0.3s, 118169 effective words/s\n",
      "INFO - 16:54:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:47: EPOCH - 35 : training on 89216 raw words (40649 effective words) took 0.4s, 108764 effective words/s\n",
      "INFO - 16:54:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:48: EPOCH - 36 : training on 89216 raw words (40381 effective words) took 0.4s, 105457 effective words/s\n",
      "INFO - 16:54:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:48: EPOCH - 37 : training on 89216 raw words (40501 effective words) took 0.4s, 111392 effective words/s\n",
      "INFO - 16:54:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:48: EPOCH - 38 : training on 89216 raw words (40607 effective words) took 0.4s, 110027 effective words/s\n",
      "INFO - 16:54:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:49: EPOCH - 39 : training on 89216 raw words (40288 effective words) took 0.4s, 113095 effective words/s\n",
      "INFO - 16:54:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:54:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:54:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:54:49: EPOCH - 40 : training on 89216 raw words (40524 effective words) took 0.4s, 106076 effective words/s\n",
      "INFO - 16:54:49: training on a 3568640 raw words (1620747 effective words) took 16.3s, 99468 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.27 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=40, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of word2vector model has 3526 unique word.\n"
     ]
    }
   ],
   "source": [
    "print('The size of word2vector model has {} unique word.'.format(len(w2v_model.wv.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:06:10: precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('public', 0.9999708533287048),\n",
       " ('germany', 0.9999703168869019),\n",
       " ('beat', 0.9999698996543884),\n",
       " ('find', 0.9999698400497437),\n",
       " ('animal', 0.9999685287475586),\n",
       " ('use', 0.9999684691429138),\n",
       " ('people', 0.9999682903289795),\n",
       " ('r', 0.9999681711196899),\n",
       " ('young', 0.9999680519104004),\n",
       " ('president', 0.9999679923057556)]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=60).fit(X=w2v_model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('use', 0.9999858140945435),\n",
       " ('minister', 0.9999852776527405),\n",
       " ('death', 0.9999849796295166),\n",
       " ('ban', 0.9999849200248718),\n",
       " ('attack', 0.9999847412109375),\n",
       " ('force', 0.999984622001648),\n",
       " ('find', 0.9999845027923584),\n",
       " ('reveal', 0.9999843835830688),\n",
       " ('news', 0.9999842643737793),\n",
       " ('amp', 0.9999841451644897)]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster_center = model.cluster_centers_[0]\n",
    "negative_cluster_center = model.cluster_centers_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(w2v_model.wv.vocab.keys())\n",
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: w2v_model.wv[f'{x}']) # give each word with vector(300,1) value\n",
    "words['cluster'] =words.vectors.apply(lambda x: model.predict([np.array(x)])) # give each word cluester label, here 1 as negative, 0 as positive\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>georgia</td>\n",
       "      <td>[0.008894088, 0.00045192052, -0.044640012, 0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>russian</td>\n",
       "      <td>[0.008630889, 0.00025897525, -0.043860912, 0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>warplane</td>\n",
       "      <td>[0.008271443, 0.00064765214, -0.044254463, 0.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>country</td>\n",
       "      <td>[0.009205525, 0.0005108211, -0.044364717, 0.03...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brink</td>\n",
       "      <td>[0.008224017, -0.0001931631, -0.044000722, 0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      words                                            vectors  cluster\n",
       "0   georgia  [0.008894088, 0.00045192052, -0.044640012, 0.0...        1\n",
       "1   russian  [0.008630889, 0.00025897525, -0.043860912, 0.0...        1\n",
       "2  warplane  [0.008271443, 0.00064765214, -0.044254463, 0.0...        0\n",
       "3   country  [0.009205525, 0.0005108211, -0.044364717, 0.03...        0\n",
       "4     brink  [0.008224017, -0.0001931631, -0.044000722, 0.0...        1"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster_value'] = [1 if i==0 else -1 for i in words.cluster] # positive as 1, negative as -1\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1) # calculate the distance of each word to each cluster and find closest\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_value</th>\n",
       "      <th>closeness_score</th>\n",
       "      <th>sentiment_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>georgia</td>\n",
       "      <td>[0.008894088, 0.00045192052, -0.044640012, 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>131.176886</td>\n",
       "      <td>-131.176886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>russian</td>\n",
       "      <td>[0.008630889, 0.00025897525, -0.043860912, 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>175.615628</td>\n",
       "      <td>-175.615628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>warplane</td>\n",
       "      <td>[0.008271443, 0.00064765214, -0.044254463, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114.953636</td>\n",
       "      <td>114.953636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>country</td>\n",
       "      <td>[0.009205525, 0.0005108211, -0.044364717, 0.03...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.619845</td>\n",
       "      <td>165.619845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brink</td>\n",
       "      <td>[0.008224017, -0.0001931631, -0.044000722, 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>104.345433</td>\n",
       "      <td>-104.345433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>war</td>\n",
       "      <td>[0.008892752, -5.2093124e-05, -0.04392394, 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>168.340736</td>\n",
       "      <td>-168.340736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>break</td>\n",
       "      <td>[0.008576797, -0.00049717183, -0.04428344, 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>166.974171</td>\n",
       "      <td>-166.974171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>russia</td>\n",
       "      <td>[0.009179152, 0.00042925557, -0.0443352, 0.036...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>161.004733</td>\n",
       "      <td>-161.004733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>today</td>\n",
       "      <td>[0.008245497, 0.0003048374, -0.044000056, 0.03...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>159.706017</td>\n",
       "      <td>-159.706017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>troop</td>\n",
       "      <td>[0.008092308, 0.00011362135, -0.04478939, 0.03...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>160.644945</td>\n",
       "      <td>-160.644945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      words                                            vectors  cluster  \\\n",
       "0   georgia  [0.008894088, 0.00045192052, -0.044640012, 0.0...        1   \n",
       "1   russian  [0.008630889, 0.00025897525, -0.043860912, 0.0...        1   \n",
       "2  warplane  [0.008271443, 0.00064765214, -0.044254463, 0.0...        0   \n",
       "3   country  [0.009205525, 0.0005108211, -0.044364717, 0.03...        0   \n",
       "4     brink  [0.008224017, -0.0001931631, -0.044000722, 0.0...        1   \n",
       "5       war  [0.008892752, -5.2093124e-05, -0.04392394, 0.0...        1   \n",
       "6     break  [0.008576797, -0.00049717183, -0.04428344, 0.0...        1   \n",
       "7    russia  [0.009179152, 0.00042925557, -0.0443352, 0.036...        1   \n",
       "8     today  [0.008245497, 0.0003048374, -0.044000056, 0.03...        1   \n",
       "9     troop  [0.008092308, 0.00011362135, -0.04478939, 0.03...        1   \n",
       "\n",
       "   cluster_value  closeness_score  sentiment_coeff  \n",
       "0             -1       131.176886      -131.176886  \n",
       "1             -1       175.615628      -175.615628  \n",
       "2              1       114.953636       114.953636  \n",
       "3              1       165.619845       165.619845  \n",
       "4             -1       104.345433      -104.345433  \n",
       "5             -1       168.340736      -168.340736  \n",
       "6             -1       166.974171      -166.974171  \n",
       "7             -1       161.004733      -161.004733  \n",
       "8             -1       159.706017      -159.706017  \n",
       "9             -1       160.644945      -160.644945  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = dict(zip(words.words.values, words.sentiment_coeff.values)) # create sentiment dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_weighting = df_clean_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_weighting_test = df_clean_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(file_weighting.clean)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(file_weighting.clean) # replace each word with their corresponding tfidf score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word, if the word is not in the tfidf dictionary, then use 0 replace\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    \n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y: dictionary[f'{y}'] if (y in dictionary) else 0, x.clean.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = file_weighting.clean.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores_test = file_weighting_test.clean.apply(lambda x: \n",
    "                                                            list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-131.17688567607024, 0, -175.61562832866895, ...\n",
       "1    [-143.12949225604245, -147.63652853422514, -15...\n",
       "2    [143.7357951783305, 0, -178.07546404831825, -1...\n",
       "3    [84.89212272674192, -171.03634662360338, 168.5...\n",
       "4    [-156.03686300776005, -166.6966336440695, 132....\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaced_closeness_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [139.8428364753893, -158.5862535832076, -155.3...\n",
       "1    [-79.67898890587733, 0, -138.4526608766789, -1...\n",
       "2    [164.5859995134624, -165.63267322024998, -85.7...\n",
       "3    [0, -169.57810249327324, 157.72538564746128, -...\n",
       "4    [-151.73530576663066, 0, 0, -164.6798459500979...\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaced_closeness_scores_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using closeness scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_rate = replaced_closeness_scores.apply(lambda x: np.mean(np.array(x) >= 0))\n",
    "negative_rate = replaced_closeness_scores.apply(lambda x: np.mean(np.array(x) < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_rate_test = replaced_closeness_scores_test.apply(lambda x: np.mean(np.array(x) >= 0))\n",
    "negative_rate_test = replaced_closeness_scores_test.apply(lambda x: np.mean(np.array(x) < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_new_df = pd.DataFrame(data=[file_weighting.clean, positive_rate, negative_rate,train_target3]).T\n",
    "replacement_new_df.columns = ['sentence', 'positive rate', 'negative rate', 'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_new_df_test = pd.DataFrame(data=[file_weighting_test.clean, positive_rate_test, negative_rate_test]).T\n",
    "replacement_new_df_test.columns = ['sentence', 'positive rate', 'negative rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>positive rate</th>\n",
       "      <th>negative rate</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>georgia down russian warplane country brink wa...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will not america nato help will not help help ...</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remember adorable year old sing open ceremony ...</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u s refuse israel weapon attack iran report ...</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expert admit legalise drug war south osetia pi...</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence positive rate  \\\n",
       "0  georgia down russian warplane country brink wa...      0.454545   \n",
       "1  will not america nato help will not help help ...      0.487179   \n",
       "2  remember adorable year old sing open ceremony ...      0.514286   \n",
       "3    u s refuse israel weapon attack iran report ...      0.465517   \n",
       "4  expert admit legalise drug war south osetia pi...      0.542857   \n",
       "\n",
       "  negative rate Label  \n",
       "0      0.545455     0  \n",
       "1      0.512821     1  \n",
       "2      0.485714     0  \n",
       "3      0.534483     0  \n",
       "4      0.457143     1  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>positive rate</th>\n",
       "      <th>negative rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>st case cancer result sheer bad luck unhealthy...</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scow gt beijing high speed train reduce trip t...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oil fall barrel yota give away fuel cell pat...</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hots fire french magazine hq bibi netanyahus c...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w charlie hebdo issue come week hard suffer gr...</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.282051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence positive rate  \\\n",
       "0  st case cancer result sheer bad luck unhealthy...      0.536585   \n",
       "1  scow gt beijing high speed train reduce trip t...           0.5   \n",
       "2    oil fall barrel yota give away fuel cell pat...      0.418182   \n",
       "3  hots fire french magazine hq bibi netanyahus c...           0.5   \n",
       "4  w charlie hebdo issue come week hard suffer gr...      0.717949   \n",
       "\n",
       "  negative rate  \n",
       "0      0.463415  \n",
       "1           0.5  \n",
       "2      0.581818  \n",
       "3           0.5  \n",
       "4      0.282051  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_new_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence         object\n",
       "positive rate    object\n",
       "negative rate    object\n",
       "Label            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_new_df = replacement_new_df.astype({'Label': 'int','positive rate':'float','negative rate':'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_new_df_test = replacement_new_df_test.astype({'positive rate':'float','negative rate':'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence          object\n",
       "positive rate    float64\n",
       "negative rate    float64\n",
       "Label              int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence          object\n",
       "positive rate    float64\n",
       "negative rate    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_new_df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "LR = model.fit(replacement_new_df[['positive rate','negative rate']],replacement_new_df['Label'])\n",
    "predictions = LR.predict(replacement_new_df[['positive rate','negative rate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1\n",
       "0  0  738\n",
       "1  0  873"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.541899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.541899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.702899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.541899\n",
       "precision  0.541899\n",
       "recall     1.000000\n",
       "f1         0.702899"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = predictions\n",
    "y_test = replacement_new_df['Label']\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(replacement_new_df['Label'], predictions))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = LR.predict(replacement_new_df_test[['positive rate','negative rate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1\n",
       "0  0  186\n",
       "1  0  192"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.507937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.507937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.673684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.507937\n",
       "precision  0.507937\n",
       "recall     1.000000\n",
       "f1         0.673684"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = predictions\n",
    "y_test = test_target3\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(test_target3, predictions))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "XGB = xgb_model.fit(replacement_new_df[['positive rate','negative rate']],replacement_new_df['Label'])\n",
    "XGB_predictions = XGB.predict(replacement_new_df[['positive rate','negative rate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_predictions_test = XGB.predict(replacement_new_df_test[['positive rate','negative rate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  380  358\n",
       "1  142  731"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.689634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.671258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.837342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.745158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.689634\n",
       "precision  0.671258\n",
       "recall     0.837342\n",
       "f1         0.745158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = XGB_predictions\n",
    "y_test = replacement_new_df['Label']\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(replacement_new_df['Label'], XGB_predictions))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1\n",
       "0  81  105\n",
       "1  69  123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.539474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.539683\n",
       "precision  0.539474\n",
       "recall     0.640625\n",
       "f1         0.585714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = XGB_predictions_test\n",
    "y_test = test_target3\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(test_target3, XGB_predictions_test))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try another way by using NLTK （Vader） with unsupervised sentimental analysis, since Vader is good at dealing with social media text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vader_score(sent):\n",
    "    # Polarity score returns dictionary\n",
    "    ss = sid.polarity_scores(sent)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "        print()\n",
    "    return list(ss.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.9972, \n",
      "neg: 0.309, \n",
      "neu: 0.651, \n",
      "pos: 0.041, \n",
      "compound: -0.9899, \n",
      "neg: 0.3, \n",
      "neu: 0.609, \n",
      "pos: 0.09, \n",
      "compound: -0.9942, \n",
      "neg: 0.29, \n",
      "neu: 0.619, \n",
      "pos: 0.091, \n",
      "compound: -0.9485, \n",
      "neg: 0.196, \n",
      "neu: 0.7, \n",
      "pos: 0.104, \n",
      "compound: -0.9883, \n",
      "neg: 0.279, \n",
      "neu: 0.597, \n",
      "pos: 0.124, \n",
      "compound: -0.9839, \n",
      "neg: 0.284, \n",
      "neu: 0.584, \n",
      "pos: 0.132, \n",
      "compound: -0.9941, \n",
      "neg: 0.347, \n",
      "neu: 0.585, \n",
      "pos: 0.068, \n",
      "compound: -0.9933, \n",
      "neg: 0.281, \n",
      "neu: 0.648, \n",
      "pos: 0.07, \n",
      "compound: -0.9951, \n",
      "neg: 0.313, \n",
      "neu: 0.616, \n",
      "pos: 0.072, \n",
      "compound: -0.9953, \n",
      "neg: 0.307, \n",
      "neu: 0.594, \n",
      "pos: 0.099, \n",
      "compound: -0.9704, \n",
      "neg: 0.229, \n",
      "neu: 0.629, \n",
      "pos: 0.142, \n",
      "compound: -0.9958, \n",
      "neg: 0.325, \n",
      "neu: 0.618, \n",
      "pos: 0.057, \n",
      "compound: -0.9949, \n",
      "neg: 0.334, \n",
      "neu: 0.549, \n",
      "pos: 0.118, \n",
      "compound: -0.9908, \n",
      "neg: 0.278, \n",
      "neu: 0.65, \n",
      "pos: 0.072, \n",
      "compound: -0.8885, \n",
      "neg: 0.217, \n",
      "neu: 0.61, \n",
      "pos: 0.173, \n",
      "compound: -0.9287, \n",
      "neg: 0.188, \n",
      "neu: 0.699, \n",
      "pos: 0.113, \n",
      "compound: -0.9972, \n",
      "neg: 0.351, \n",
      "neu: 0.585, \n",
      "pos: 0.064, \n",
      "compound: -0.99, \n",
      "neg: 0.27, \n",
      "neu: 0.648, \n",
      "pos: 0.082, \n",
      "compound: -0.9806, \n",
      "neg: 0.264, \n",
      "neu: 0.576, \n",
      "pos: 0.16, \n",
      "compound: -0.9929, \n",
      "neg: 0.307, \n",
      "neu: 0.597, \n",
      "pos: 0.096, \n",
      "compound: -0.996, \n",
      "neg: 0.335, \n",
      "neu: 0.589, \n",
      "pos: 0.076, \n",
      "compound: -0.9931, \n",
      "neg: 0.281, \n",
      "neu: 0.623, \n",
      "pos: 0.096, \n",
      "compound: -0.9927, \n",
      "neg: 0.298, \n",
      "neu: 0.617, \n",
      "pos: 0.085, \n",
      "compound: -0.9823, \n",
      "neg: 0.25, \n",
      "neu: 0.666, \n",
      "pos: 0.084, \n",
      "compound: -0.9855, \n",
      "neg: 0.245, \n",
      "neu: 0.7, \n",
      "pos: 0.056, \n",
      "compound: -0.9862, \n",
      "neg: 0.279, \n",
      "neu: 0.568, \n",
      "pos: 0.153, \n",
      "compound: -0.9971, \n",
      "neg: 0.331, \n",
      "neu: 0.596, \n",
      "pos: 0.073, \n",
      "compound: -0.9877, \n",
      "neg: 0.274, \n",
      "neu: 0.663, \n",
      "pos: 0.063, \n",
      "compound: -0.9969, \n",
      "neg: 0.379, \n",
      "neu: 0.568, \n",
      "pos: 0.053, \n",
      "compound: -0.9949, \n",
      "neg: 0.337, \n",
      "neu: 0.602, \n",
      "pos: 0.061, \n",
      "compound: -0.9899, \n",
      "neg: 0.269, \n",
      "neu: 0.643, \n",
      "pos: 0.088, \n",
      "compound: -0.9837, \n",
      "neg: 0.265, \n",
      "neu: 0.605, \n",
      "pos: 0.13, \n",
      "compound: -0.9961, \n",
      "neg: 0.348, \n",
      "neu: 0.603, \n",
      "pos: 0.049, \n",
      "compound: -0.9908, \n",
      "neg: 0.259, \n",
      "neu: 0.72, \n",
      "pos: 0.021, \n",
      "compound: -0.9923, \n",
      "neg: 0.282, \n",
      "neu: 0.689, \n",
      "pos: 0.029, \n",
      "compound: -0.9893, \n",
      "neg: 0.266, \n",
      "neu: 0.607, \n",
      "pos: 0.127, \n",
      "compound: -0.9907, \n",
      "neg: 0.321, \n",
      "neu: 0.557, \n",
      "pos: 0.122, \n",
      "compound: -0.9946, \n",
      "neg: 0.343, \n",
      "neu: 0.508, \n",
      "pos: 0.149, \n",
      "compound: -0.9927, \n",
      "neg: 0.3, \n",
      "neu: 0.595, \n",
      "pos: 0.105, \n",
      "compound: -0.9837, \n",
      "neg: 0.24, \n",
      "neu: 0.661, \n",
      "pos: 0.099, \n",
      "compound: -0.975, \n",
      "neg: 0.252, \n",
      "neu: 0.616, \n",
      "pos: 0.133, \n",
      "compound: -0.9846, \n",
      "neg: 0.228, \n",
      "neu: 0.659, \n",
      "pos: 0.113, \n",
      "compound: -0.9892, \n",
      "neg: 0.25, \n",
      "neu: 0.65, \n",
      "pos: 0.1, \n",
      "compound: -0.9963, \n",
      "neg: 0.31, \n",
      "neu: 0.617, \n",
      "pos: 0.074, \n",
      "compound: -0.9831, \n",
      "neg: 0.224, \n",
      "neu: 0.655, \n",
      "pos: 0.121, \n",
      "compound: -0.9153, \n",
      "neg: 0.235, \n",
      "neu: 0.604, \n",
      "pos: 0.16, \n",
      "compound: -0.9921, \n",
      "neg: 0.283, \n",
      "neu: 0.61, \n",
      "pos: 0.106, \n",
      "compound: -0.9769, \n",
      "neg: 0.22, \n",
      "neu: 0.678, \n",
      "pos: 0.102, \n",
      "compound: -0.8734, \n",
      "neg: 0.174, \n",
      "neu: 0.689, \n",
      "pos: 0.138, \n",
      "compound: -0.9902, \n",
      "neg: 0.259, \n",
      "neu: 0.626, \n",
      "pos: 0.115, \n",
      "compound: -0.9738, \n",
      "neg: 0.24, \n",
      "neu: 0.622, \n",
      "pos: 0.138, \n",
      "compound: -0.9895, \n",
      "neg: 0.277, \n",
      "neu: 0.566, \n",
      "pos: 0.157, \n",
      "compound: -0.9889, \n",
      "neg: 0.26, \n",
      "neu: 0.634, \n",
      "pos: 0.106, \n",
      "compound: -0.9882, \n",
      "neg: 0.284, \n",
      "neu: 0.573, \n",
      "pos: 0.143, \n",
      "compound: -0.9965, \n",
      "neg: 0.348, \n",
      "neu: 0.55, \n",
      "pos: 0.101, \n",
      "compound: -0.9924, \n",
      "neg: 0.31, \n",
      "neu: 0.586, \n",
      "pos: 0.104, \n",
      "compound: -0.9899, \n",
      "neg: 0.264, \n",
      "neu: 0.664, \n",
      "pos: 0.073, \n",
      "compound: -0.9947, \n",
      "neg: 0.335, \n",
      "neu: 0.533, \n",
      "pos: 0.132, \n",
      "compound: -0.9977, \n",
      "neg: 0.401, \n",
      "neu: 0.528, \n",
      "pos: 0.071, \n",
      "compound: -0.9892, \n",
      "neg: 0.335, \n",
      "neu: 0.504, \n",
      "pos: 0.161, \n",
      "compound: -0.9911, \n",
      "neg: 0.246, \n",
      "neu: 0.665, \n",
      "pos: 0.089, \n",
      "compound: -0.9959, \n",
      "neg: 0.331, \n",
      "neu: 0.549, \n",
      "pos: 0.12, \n",
      "compound: -0.9337, \n",
      "neg: 0.222, \n",
      "neu: 0.629, \n",
      "pos: 0.149, \n",
      "compound: -0.9966, \n",
      "neg: 0.332, \n",
      "neu: 0.607, \n",
      "pos: 0.061, \n",
      "compound: -0.9843, \n",
      "neg: 0.229, \n",
      "neu: 0.695, \n",
      "pos: 0.076, \n",
      "compound: -0.988, \n",
      "neg: 0.281, \n",
      "neu: 0.579, \n",
      "pos: 0.139, \n",
      "compound: -0.9969, \n",
      "neg: 0.368, \n",
      "neu: 0.55, \n",
      "pos: 0.081, \n",
      "compound: -0.9977, \n",
      "neg: 0.351, \n",
      "neu: 0.616, \n",
      "pos: 0.033, \n",
      "compound: -0.9921, \n",
      "neg: 0.281, \n",
      "neu: 0.621, \n",
      "pos: 0.099, \n",
      "compound: -0.9584, \n",
      "neg: 0.18, \n",
      "neu: 0.693, \n",
      "pos: 0.126, \n",
      "compound: -0.875, \n",
      "neg: 0.149, \n",
      "neu: 0.761, \n",
      "pos: 0.09, \n",
      "compound: -0.995, \n",
      "neg: 0.284, \n",
      "neu: 0.643, \n",
      "pos: 0.074, \n",
      "compound: -0.6249, \n",
      "neg: 0.191, \n",
      "neu: 0.667, \n",
      "pos: 0.142, \n",
      "compound: -0.926, \n",
      "neg: 0.173, \n",
      "neu: 0.721, \n",
      "pos: 0.106, \n",
      "compound: -0.9941, \n",
      "neg: 0.303, \n",
      "neu: 0.612, \n",
      "pos: 0.085, \n",
      "compound: -0.9867, \n",
      "neg: 0.264, \n",
      "neu: 0.631, \n",
      "pos: 0.104, \n",
      "compound: -0.993, \n",
      "neg: 0.265, \n",
      "neu: 0.659, \n",
      "pos: 0.076, \n",
      "compound: -0.994, \n",
      "neg: 0.325, \n",
      "neu: 0.596, \n",
      "pos: 0.079, \n",
      "compound: -0.9926, \n",
      "neg: 0.295, \n",
      "neu: 0.609, \n",
      "pos: 0.096, \n",
      "compound: -0.9538, \n",
      "neg: 0.214, \n",
      "neu: 0.645, \n",
      "pos: 0.14, \n",
      "compound: -0.9974, \n",
      "neg: 0.363, \n",
      "neu: 0.54, \n",
      "pos: 0.097, \n",
      "compound: -0.9959, \n",
      "neg: 0.341, \n",
      "neu: 0.521, \n",
      "pos: 0.138, \n",
      "compound: -0.9588, \n",
      "neg: 0.238, \n",
      "neu: 0.61, \n",
      "pos: 0.152, \n",
      "compound: -0.997, \n",
      "neg: 0.361, \n",
      "neu: 0.547, \n",
      "pos: 0.091, \n",
      "compound: -0.9903, \n",
      "neg: 0.244, \n",
      "neu: 0.673, \n",
      "pos: 0.083, \n",
      "compound: -0.992, \n",
      "neg: 0.279, \n",
      "neu: 0.623, \n",
      "pos: 0.098, \n",
      "compound: -0.9946, \n",
      "neg: 0.336, \n",
      "neu: 0.529, \n",
      "pos: 0.136, \n",
      "compound: -0.9851, \n",
      "neg: 0.212, \n",
      "neu: 0.706, \n",
      "pos: 0.081, \n",
      "compound: -0.9977, \n",
      "neg: 0.384, \n",
      "neu: 0.566, \n",
      "pos: 0.05, \n",
      "compound: -0.886, \n",
      "neg: 0.161, \n",
      "neu: 0.718, \n",
      "pos: 0.12, \n",
      "compound: -0.9896, \n",
      "neg: 0.251, \n",
      "neu: 0.665, \n",
      "pos: 0.084, \n",
      "compound: -0.9781, \n",
      "neg: 0.277, \n",
      "neu: 0.564, \n",
      "pos: 0.159, \n",
      "compound: -0.9944, \n",
      "neg: 0.297, \n",
      "neu: 0.634, \n",
      "pos: 0.069, \n",
      "compound: -0.9933, \n",
      "neg: 0.28, \n",
      "neu: 0.652, \n",
      "pos: 0.068, \n",
      "compound: -0.9974, \n",
      "neg: 0.369, \n",
      "neu: 0.537, \n",
      "pos: 0.094, \n",
      "compound: -0.9781, \n",
      "neg: 0.221, \n",
      "neu: 0.697, \n",
      "pos: 0.082, \n",
      "compound: -0.4588, \n",
      "neg: 0.208, \n",
      "neu: 0.593, \n",
      "pos: 0.199, \n",
      "compound: -0.9961, \n",
      "neg: 0.337, \n",
      "neu: 0.584, \n",
      "pos: 0.079, \n",
      "compound: -0.9916, \n",
      "neg: 0.308, \n",
      "neu: 0.569, \n",
      "pos: 0.123, \n",
      "compound: -0.9958, \n",
      "neg: 0.338, \n",
      "neu: 0.523, \n",
      "pos: 0.139, \n",
      "compound: -0.9926, \n",
      "neg: 0.267, \n",
      "neu: 0.663, \n",
      "pos: 0.07, \n",
      "compound: -0.9917, \n",
      "neg: 0.305, \n",
      "neu: 0.6, \n",
      "pos: 0.095, \n",
      "compound: -0.9954, \n",
      "neg: 0.28, \n",
      "neu: 0.672, \n",
      "pos: 0.048, \n",
      "compound: -0.9839, \n",
      "neg: 0.249, \n",
      "neu: 0.612, \n",
      "pos: 0.139, \n",
      "compound: -0.9972, \n",
      "neg: 0.328, \n",
      "neu: 0.599, \n",
      "pos: 0.074, \n",
      "compound: -0.9966, \n",
      "neg: 0.348, \n",
      "neu: 0.573, \n",
      "pos: 0.079, \n",
      "compound: -0.9958, \n",
      "neg: 0.287, \n",
      "neu: 0.653, \n",
      "pos: 0.06, \n",
      "compound: -0.9946, \n",
      "neg: 0.282, \n",
      "neu: 0.617, \n",
      "pos: 0.101, \n",
      "compound: -0.9952, \n",
      "neg: 0.289, \n",
      "neu: 0.626, \n",
      "pos: 0.085, \n",
      "compound: -0.9956, \n",
      "neg: 0.309, \n",
      "neu: 0.613, \n",
      "pos: 0.078, \n",
      "compound: -0.9913, \n",
      "neg: 0.236, \n",
      "neu: 0.685, \n",
      "pos: 0.079, \n",
      "compound: -0.9986, \n",
      "neg: 0.391, \n",
      "neu: 0.534, \n",
      "pos: 0.074, \n",
      "compound: -0.9987, \n",
      "neg: 0.464, \n",
      "neu: 0.473, \n",
      "pos: 0.063, \n",
      "compound: -0.9946, \n",
      "neg: 0.305, \n",
      "neu: 0.586, \n",
      "pos: 0.109, \n",
      "compound: -0.9904, \n",
      "neg: 0.275, \n",
      "neu: 0.631, \n",
      "pos: 0.095, \n",
      "compound: -0.994, \n",
      "neg: 0.31, \n",
      "neu: 0.573, \n",
      "pos: 0.117, \n",
      "compound: -0.9972, \n",
      "neg: 0.36, \n",
      "neu: 0.558, \n",
      "pos: 0.082, \n",
      "compound: -0.995, \n",
      "neg: 0.301, \n",
      "neu: 0.583, \n",
      "pos: 0.115, \n",
      "compound: -0.996, \n",
      "neg: 0.331, \n",
      "neu: 0.612, \n",
      "pos: 0.057, \n",
      "compound: -0.9729, \n",
      "neg: 0.189, \n",
      "neu: 0.701, \n",
      "pos: 0.109, \n",
      "compound: -0.9925, \n",
      "neg: 0.283, \n",
      "neu: 0.653, \n",
      "pos: 0.064, \n",
      "compound: -0.9393, \n",
      "neg: 0.216, \n",
      "neu: 0.623, \n",
      "pos: 0.161, \n",
      "compound: -0.9961, \n",
      "neg: 0.322, \n",
      "neu: 0.579, \n",
      "pos: 0.099, \n",
      "compound: -0.9919, \n",
      "neg: 0.291, \n",
      "neu: 0.591, \n",
      "pos: 0.119, \n",
      "compound: -0.9618, \n",
      "neg: 0.228, \n",
      "neu: 0.606, \n",
      "pos: 0.165, \n",
      "compound: -0.9823, \n",
      "neg: 0.246, \n",
      "neu: 0.617, \n",
      "pos: 0.137, \n",
      "compound: -0.9964, \n",
      "neg: 0.319, \n",
      "neu: 0.644, \n",
      "pos: 0.037, \n",
      "compound: -0.9894, \n",
      "neg: 0.264, \n",
      "neu: 0.586, \n",
      "pos: 0.15, \n",
      "compound: -0.9922, \n",
      "neg: 0.255, \n",
      "neu: 0.634, \n",
      "pos: 0.111, \n",
      "compound: -0.9943, \n",
      "neg: 0.29, \n",
      "neu: 0.638, \n",
      "pos: 0.072, \n",
      "compound: -0.9938, \n",
      "neg: 0.296, \n",
      "neu: 0.622, \n",
      "pos: 0.082, \n",
      "compound: -0.9928, \n",
      "neg: 0.295, \n",
      "neu: 0.654, \n",
      "pos: 0.051, \n",
      "compound: -0.9643, \n",
      "neg: 0.244, \n",
      "neu: 0.606, \n",
      "pos: 0.15, \n",
      "compound: -0.9702, \n",
      "neg: 0.26, \n",
      "neu: 0.591, \n",
      "pos: 0.149, \n",
      "compound: -0.9939, \n",
      "neg: 0.302, \n",
      "neu: 0.619, \n",
      "pos: 0.08, \n",
      "compound: -0.9916, \n",
      "neg: 0.316, \n",
      "neu: 0.567, \n",
      "pos: 0.116, \n",
      "compound: -0.9881, \n",
      "neg: 0.277, \n",
      "neu: 0.558, \n",
      "pos: 0.166, \n",
      "compound: -0.9955, \n",
      "neg: 0.301, \n",
      "neu: 0.591, \n",
      "pos: 0.108, \n",
      "compound: -0.9882, \n",
      "neg: 0.242, \n",
      "neu: 0.634, \n",
      "pos: 0.124, \n",
      "compound: -0.9864, \n",
      "neg: 0.233, \n",
      "neu: 0.666, \n",
      "pos: 0.101, \n",
      "compound: -0.9929, \n",
      "neg: 0.28, \n",
      "neu: 0.627, \n",
      "pos: 0.093, \n",
      "compound: -0.994, \n",
      "neg: 0.298, \n",
      "neu: 0.597, \n",
      "pos: 0.105, \n",
      "compound: -0.9973, \n",
      "neg: 0.385, \n",
      "neu: 0.5, \n",
      "pos: 0.115, \n",
      "compound: -0.9908, \n",
      "neg: 0.23, \n",
      "neu: 0.67, \n",
      "pos: 0.1, \n",
      "compound: -0.9974, \n",
      "neg: 0.355, \n",
      "neu: 0.58, \n",
      "pos: 0.065, \n",
      "compound: -0.9633, \n",
      "neg: 0.216, \n",
      "neu: 0.644, \n",
      "pos: 0.14, \n",
      "compound: -0.9855, \n",
      "neg: 0.207, \n",
      "neu: 0.728, \n",
      "pos: 0.065, \n",
      "compound: -0.9978, \n",
      "neg: 0.379, \n",
      "neu: 0.579, \n",
      "pos: 0.041, \n",
      "compound: -0.9941, \n",
      "neg: 0.288, \n",
      "neu: 0.62, \n",
      "pos: 0.091, \n",
      "compound: -0.9904, \n",
      "neg: 0.256, \n",
      "neu: 0.667, \n",
      "pos: 0.077, \n",
      "compound: -0.9874, \n",
      "neg: 0.221, \n",
      "neu: 0.685, \n",
      "pos: 0.093, \n",
      "compound: -0.9968, \n",
      "neg: 0.334, \n",
      "neu: 0.582, \n",
      "pos: 0.084, \n",
      "compound: -0.9959, \n",
      "neg: 0.351, \n",
      "neu: 0.549, \n",
      "pos: 0.1, \n",
      "compound: -0.9975, \n",
      "neg: 0.373, \n",
      "neu: 0.539, \n",
      "pos: 0.088, \n",
      "compound: -0.998, \n",
      "neg: 0.313, \n",
      "neu: 0.622, \n",
      "pos: 0.064, \n",
      "compound: -0.9824, \n",
      "neg: 0.238, \n",
      "neu: 0.63, \n",
      "pos: 0.132, \n",
      "compound: -0.996, \n",
      "neg: 0.281, \n",
      "neu: 0.635, \n",
      "pos: 0.085, \n",
      "compound: -0.9953, \n",
      "neg: 0.286, \n",
      "neu: 0.636, \n",
      "pos: 0.078, \n",
      "compound: -0.9956, \n",
      "neg: 0.349, \n",
      "neu: 0.55, \n",
      "pos: 0.1, \n",
      "compound: -0.9959, \n",
      "neg: 0.307, \n",
      "neu: 0.624, \n",
      "pos: 0.069, \n",
      "compound: -0.9911, \n",
      "neg: 0.218, \n",
      "neu: 0.729, \n",
      "pos: 0.053, \n",
      "compound: -0.9894, \n",
      "neg: 0.235, \n",
      "neu: 0.67, \n",
      "pos: 0.095, \n",
      "compound: -0.9764, \n",
      "neg: 0.216, \n",
      "neu: 0.694, \n",
      "pos: 0.09, \n",
      "compound: -0.9932, \n",
      "neg: 0.291, \n",
      "neu: 0.599, \n",
      "pos: 0.11, \n",
      "compound: -0.9922, \n",
      "neg: 0.278, \n",
      "neu: 0.619, \n",
      "pos: 0.103, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.9932, \n",
      "neg: 0.303, \n",
      "neu: 0.571, \n",
      "pos: 0.126, \n",
      "compound: -0.9979, \n",
      "neg: 0.353, \n",
      "neu: 0.582, \n",
      "pos: 0.065, \n",
      "compound: -0.9808, \n",
      "neg: 0.221, \n",
      "neu: 0.677, \n",
      "pos: 0.102, \n",
      "compound: -0.9969, \n",
      "neg: 0.304, \n",
      "neu: 0.615, \n",
      "pos: 0.081, \n",
      "compound: -0.9925, \n",
      "neg: 0.271, \n",
      "neu: 0.669, \n",
      "pos: 0.06, \n",
      "compound: -0.9912, \n",
      "neg: 0.254, \n",
      "neu: 0.645, \n",
      "pos: 0.1, \n",
      "compound: -0.9955, \n",
      "neg: 0.321, \n",
      "neu: 0.593, \n",
      "pos: 0.086, \n",
      "compound: -0.9971, \n",
      "neg: 0.335, \n",
      "neu: 0.601, \n",
      "pos: 0.064, \n",
      "compound: -0.9951, \n",
      "neg: 0.323, \n",
      "neu: 0.537, \n",
      "pos: 0.14, \n",
      "compound: -0.9912, \n",
      "neg: 0.232, \n",
      "neu: 0.68, \n",
      "pos: 0.088, \n",
      "compound: -0.9849, \n",
      "neg: 0.279, \n",
      "neu: 0.579, \n",
      "pos: 0.142, \n",
      "compound: -0.9871, \n",
      "neg: 0.215, \n",
      "neu: 0.676, \n",
      "pos: 0.109, \n",
      "compound: -0.9917, \n",
      "neg: 0.257, \n",
      "neu: 0.623, \n",
      "pos: 0.121, \n",
      "compound: -0.9842, \n",
      "neg: 0.252, \n",
      "neu: 0.604, \n",
      "pos: 0.144, \n",
      "compound: -0.9776, \n",
      "neg: 0.193, \n",
      "neu: 0.73, \n",
      "pos: 0.076, \n",
      "compound: -0.9584, \n",
      "neg: 0.224, \n",
      "neu: 0.594, \n",
      "pos: 0.182, \n",
      "compound: -0.9618, \n",
      "neg: 0.176, \n",
      "neu: 0.731, \n",
      "pos: 0.094, \n",
      "compound: -0.9967, \n",
      "neg: 0.343, \n",
      "neu: 0.589, \n",
      "pos: 0.068, \n",
      "compound: -0.9868, \n",
      "neg: 0.235, \n",
      "neu: 0.619, \n",
      "pos: 0.146, \n",
      "compound: -0.993, \n",
      "neg: 0.271, \n",
      "neu: 0.604, \n",
      "pos: 0.126, \n",
      "compound: -0.9942, \n",
      "neg: 0.299, \n",
      "neu: 0.594, \n",
      "pos: 0.106, \n",
      "compound: -0.9959, \n",
      "neg: 0.306, \n",
      "neu: 0.598, \n",
      "pos: 0.096, \n",
      "compound: -0.9888, \n",
      "neg: 0.251, \n",
      "neu: 0.657, \n",
      "pos: 0.091, \n",
      "compound: -0.994, \n",
      "neg: 0.286, \n",
      "neu: 0.596, \n",
      "pos: 0.117, \n",
      "compound: -0.988, \n",
      "neg: 0.247, \n",
      "neu: 0.622, \n",
      "pos: 0.132, \n",
      "compound: -0.9938, \n",
      "neg: 0.264, \n",
      "neu: 0.637, \n",
      "pos: 0.099, \n",
      "compound: -0.9965, \n",
      "neg: 0.299, \n",
      "neu: 0.585, \n",
      "pos: 0.116, \n",
      "compound: -0.994, \n",
      "neg: 0.306, \n",
      "neu: 0.598, \n",
      "pos: 0.097, \n",
      "compound: -0.9321, \n",
      "neg: 0.16, \n",
      "neu: 0.746, \n",
      "pos: 0.095, \n",
      "compound: -0.9942, \n",
      "neg: 0.266, \n",
      "neu: 0.663, \n",
      "pos: 0.071, \n",
      "compound: -0.8807, \n",
      "neg: 0.178, \n",
      "neu: 0.671, \n",
      "pos: 0.151, \n",
      "compound: -0.9982, \n",
      "neg: 0.366, \n",
      "neu: 0.594, \n",
      "pos: 0.04, \n",
      "compound: -0.9924, \n",
      "neg: 0.278, \n",
      "neu: 0.642, \n",
      "pos: 0.08, \n",
      "compound: -0.9955, \n",
      "neg: 0.275, \n",
      "neu: 0.629, \n",
      "pos: 0.096, \n",
      "compound: -0.9823, \n",
      "neg: 0.228, \n",
      "neu: 0.624, \n",
      "pos: 0.148, \n",
      "compound: -0.9932, \n",
      "neg: 0.265, \n",
      "neu: 0.637, \n",
      "pos: 0.098, \n",
      "compound: -0.9905, \n",
      "neg: 0.247, \n",
      "neu: 0.647, \n",
      "pos: 0.105, \n",
      "compound: -0.9944, \n",
      "neg: 0.255, \n",
      "neu: 0.648, \n",
      "pos: 0.097, \n",
      "compound: -0.9919, \n",
      "neg: 0.267, \n",
      "neu: 0.637, \n",
      "pos: 0.096, \n",
      "compound: -0.9801, \n",
      "neg: 0.204, \n",
      "neu: 0.678, \n",
      "pos: 0.117, \n",
      "compound: -0.9929, \n",
      "neg: 0.264, \n",
      "neu: 0.676, \n",
      "pos: 0.06, \n",
      "compound: -0.9698, \n",
      "neg: 0.192, \n",
      "neu: 0.709, \n",
      "pos: 0.099, \n",
      "compound: 0.296, \n",
      "neg: 0.17, \n",
      "neu: 0.671, \n",
      "pos: 0.159, \n",
      "compound: -0.9905, \n",
      "neg: 0.273, \n",
      "neu: 0.585, \n",
      "pos: 0.142, \n",
      "compound: -0.9964, \n",
      "neg: 0.371, \n",
      "neu: 0.536, \n",
      "pos: 0.094, \n",
      "compound: -0.9912, \n",
      "neg: 0.249, \n",
      "neu: 0.63, \n",
      "pos: 0.121, \n",
      "compound: -0.969, \n",
      "neg: 0.25, \n",
      "neu: 0.571, \n",
      "pos: 0.178, \n",
      "compound: -0.9571, \n",
      "neg: 0.233, \n",
      "neu: 0.615, \n",
      "pos: 0.151, \n",
      "compound: -0.9917, \n",
      "neg: 0.225, \n",
      "neu: 0.712, \n",
      "pos: 0.063, \n",
      "compound: -0.9118, \n",
      "neg: 0.201, \n",
      "neu: 0.615, \n",
      "pos: 0.184, \n",
      "compound: -0.9698, \n",
      "neg: 0.215, \n",
      "neu: 0.649, \n",
      "pos: 0.136, \n",
      "compound: -0.9876, \n",
      "neg: 0.226, \n",
      "neu: 0.633, \n",
      "pos: 0.14, \n",
      "compound: -0.9874, \n",
      "neg: 0.267, \n",
      "neu: 0.579, \n",
      "pos: 0.154, \n",
      "compound: -0.9674, \n",
      "neg: 0.191, \n",
      "neu: 0.676, \n",
      "pos: 0.133, \n",
      "compound: -0.9957, \n",
      "neg: 0.324, \n",
      "neu: 0.572, \n",
      "pos: 0.104, \n",
      "compound: -0.9937, \n",
      "neg: 0.284, \n",
      "neu: 0.609, \n",
      "pos: 0.106, \n",
      "compound: 0.6249, \n",
      "neg: 0.226, \n",
      "neu: 0.528, \n",
      "pos: 0.247, \n",
      "compound: -0.9954, \n",
      "neg: 0.303, \n",
      "neu: 0.643, \n",
      "pos: 0.054, \n",
      "compound: -0.9946, \n",
      "neg: 0.259, \n",
      "neu: 0.727, \n",
      "pos: 0.014, \n",
      "compound: -0.9806, \n",
      "neg: 0.239, \n",
      "neu: 0.604, \n",
      "pos: 0.157, \n",
      "compound: -0.9468, \n",
      "neg: 0.185, \n",
      "neu: 0.702, \n",
      "pos: 0.113, \n",
      "compound: -0.9923, \n",
      "neg: 0.288, \n",
      "neu: 0.601, \n",
      "pos: 0.111, \n",
      "compound: -0.9987, \n",
      "neg: 0.437, \n",
      "neu: 0.526, \n",
      "pos: 0.037, \n",
      "compound: -0.9972, \n",
      "neg: 0.35, \n",
      "neu: 0.564, \n",
      "pos: 0.086, \n",
      "compound: -0.9984, \n",
      "neg: 0.325, \n",
      "neu: 0.598, \n",
      "pos: 0.077, \n",
      "compound: -0.9978, \n",
      "neg: 0.362, \n",
      "neu: 0.577, \n",
      "pos: 0.061, \n",
      "compound: -0.9975, \n",
      "neg: 0.331, \n",
      "neu: 0.609, \n",
      "pos: 0.061, \n",
      "compound: -0.995, \n",
      "neg: 0.259, \n",
      "neu: 0.648, \n",
      "pos: 0.093, \n",
      "compound: -0.9962, \n",
      "neg: 0.321, \n",
      "neu: 0.583, \n",
      "pos: 0.095, \n",
      "compound: -0.9982, \n",
      "neg: 0.371, \n",
      "neu: 0.539, \n",
      "pos: 0.091, \n",
      "compound: -0.9937, \n",
      "neg: 0.251, \n",
      "neu: 0.659, \n",
      "pos: 0.09, \n",
      "compound: -0.9956, \n",
      "neg: 0.307, \n",
      "neu: 0.594, \n",
      "pos: 0.099, \n",
      "compound: -0.9831, \n",
      "neg: 0.235, \n",
      "neu: 0.628, \n",
      "pos: 0.137, \n",
      "compound: -0.9898, \n",
      "neg: 0.238, \n",
      "neu: 0.674, \n",
      "pos: 0.088, \n",
      "compound: -0.981, \n",
      "neg: 0.185, \n",
      "neu: 0.715, \n",
      "pos: 0.1, \n",
      "compound: -0.9944, \n",
      "neg: 0.281, \n",
      "neu: 0.636, \n",
      "pos: 0.083, \n",
      "compound: -0.9887, \n",
      "neg: 0.228, \n",
      "neu: 0.702, \n",
      "pos: 0.07, \n",
      "compound: -0.9955, \n",
      "neg: 0.297, \n",
      "neu: 0.586, \n",
      "pos: 0.117, \n",
      "compound: -0.9982, \n",
      "neg: 0.358, \n",
      "neu: 0.502, \n",
      "pos: 0.14, \n",
      "compound: -0.9959, \n",
      "neg: 0.271, \n",
      "neu: 0.604, \n",
      "pos: 0.124, \n",
      "compound: -0.9977, \n",
      "neg: 0.32, \n",
      "neu: 0.592, \n",
      "pos: 0.088, \n",
      "compound: -0.996, \n",
      "neg: 0.274, \n",
      "neu: 0.638, \n",
      "pos: 0.088, \n",
      "compound: -0.9912, \n",
      "neg: 0.213, \n",
      "neu: 0.681, \n",
      "pos: 0.106, \n",
      "compound: -0.984, \n",
      "neg: 0.164, \n",
      "neu: 0.775, \n",
      "pos: 0.061, \n",
      "compound: -0.9917, \n",
      "neg: 0.236, \n",
      "neu: 0.694, \n",
      "pos: 0.069, \n",
      "compound: -0.959, \n",
      "neg: 0.173, \n",
      "neu: 0.706, \n",
      "pos: 0.121, \n",
      "compound: -0.9949, \n",
      "neg: 0.327, \n",
      "neu: 0.553, \n",
      "pos: 0.12, \n",
      "compound: -0.9976, \n",
      "neg: 0.302, \n",
      "neu: 0.64, \n",
      "pos: 0.059, \n",
      "compound: -0.998, \n",
      "neg: 0.346, \n",
      "neu: 0.584, \n",
      "pos: 0.069, \n",
      "compound: 0.5423, \n",
      "neg: 0.122, \n",
      "neu: 0.725, \n",
      "pos: 0.153, \n",
      "compound: -0.9914, \n",
      "neg: 0.227, \n",
      "neu: 0.686, \n",
      "pos: 0.086, \n",
      "compound: -0.9922, \n",
      "neg: 0.276, \n",
      "neu: 0.622, \n",
      "pos: 0.102, \n",
      "compound: -0.9945, \n",
      "neg: 0.252, \n",
      "neu: 0.652, \n",
      "pos: 0.096, \n",
      "compound: -0.9826, \n",
      "neg: 0.181, \n",
      "neu: 0.708, \n",
      "pos: 0.111, \n",
      "compound: -0.9915, \n",
      "neg: 0.239, \n",
      "neu: 0.643, \n",
      "pos: 0.118, \n",
      "compound: -0.9633, \n",
      "neg: 0.199, \n",
      "neu: 0.653, \n",
      "pos: 0.148, \n",
      "compound: -0.9969, \n",
      "neg: 0.301, \n",
      "neu: 0.578, \n",
      "pos: 0.121, \n",
      "compound: -0.9888, \n",
      "neg: 0.216, \n",
      "neu: 0.684, \n",
      "pos: 0.1, \n",
      "compound: -0.9741, \n",
      "neg: 0.221, \n",
      "neu: 0.639, \n",
      "pos: 0.139, \n",
      "compound: -0.9927, \n",
      "neg: 0.28, \n",
      "neu: 0.599, \n",
      "pos: 0.121, \n",
      "compound: -0.995, \n",
      "neg: 0.255, \n",
      "neu: 0.663, \n",
      "pos: 0.082, \n",
      "compound: -0.9501, \n",
      "neg: 0.204, \n",
      "neu: 0.642, \n",
      "pos: 0.154, \n",
      "compound: -0.9814, \n",
      "neg: 0.207, \n",
      "neu: 0.692, \n",
      "pos: 0.102, \n",
      "compound: -0.9801, \n",
      "neg: 0.189, \n",
      "neu: 0.719, \n",
      "pos: 0.091, \n",
      "compound: -0.979, \n",
      "neg: 0.257, \n",
      "neu: 0.565, \n",
      "pos: 0.178, \n",
      "compound: -0.9938, \n",
      "neg: 0.276, \n",
      "neu: 0.642, \n",
      "pos: 0.082, \n",
      "compound: -0.9903, \n",
      "neg: 0.224, \n",
      "neu: 0.683, \n",
      "pos: 0.094, \n",
      "compound: -0.9834, \n",
      "neg: 0.242, \n",
      "neu: 0.599, \n",
      "pos: 0.159, \n",
      "compound: -0.9925, \n",
      "neg: 0.246, \n",
      "neu: 0.669, \n",
      "pos: 0.085, \n",
      "compound: -0.979, \n",
      "neg: 0.169, \n",
      "neu: 0.714, \n",
      "pos: 0.117, \n",
      "compound: -0.9925, \n",
      "neg: 0.231, \n",
      "neu: 0.636, \n",
      "pos: 0.133, \n",
      "compound: -0.9223, \n",
      "neg: 0.187, \n",
      "neu: 0.637, \n",
      "pos: 0.176, \n",
      "compound: -0.8035, \n",
      "neg: 0.168, \n",
      "neu: 0.681, \n",
      "pos: 0.151, \n",
      "compound: -0.9732, \n",
      "neg: 0.197, \n",
      "neu: 0.68, \n",
      "pos: 0.123, \n",
      "compound: -0.9983, \n",
      "neg: 0.349, \n",
      "neu: 0.552, \n",
      "pos: 0.099, \n",
      "compound: -0.9879, \n",
      "neg: 0.238, \n",
      "neu: 0.648, \n",
      "pos: 0.114, \n",
      "compound: -0.9325, \n",
      "neg: 0.146, \n",
      "neu: 0.755, \n",
      "pos: 0.099, \n",
      "compound: -0.9968, \n",
      "neg: 0.329, \n",
      "neu: 0.549, \n",
      "pos: 0.122, \n",
      "compound: -0.9932, \n",
      "neg: 0.242, \n",
      "neu: 0.643, \n",
      "pos: 0.116, \n",
      "compound: -0.995, \n",
      "neg: 0.237, \n",
      "neu: 0.653, \n",
      "pos: 0.11, \n",
      "compound: -0.9643, \n",
      "neg: 0.205, \n",
      "neu: 0.646, \n",
      "pos: 0.15, \n",
      "compound: -0.7579, \n",
      "neg: 0.241, \n",
      "neu: 0.554, \n",
      "pos: 0.205, \n",
      "compound: -0.9971, \n",
      "neg: 0.299, \n",
      "neu: 0.586, \n",
      "pos: 0.115, \n",
      "compound: -0.9969, \n",
      "neg: 0.295, \n",
      "neu: 0.657, \n",
      "pos: 0.047, \n",
      "compound: -0.9828, \n",
      "neg: 0.23, \n",
      "neu: 0.634, \n",
      "pos: 0.136, \n",
      "compound: -0.9881, \n",
      "neg: 0.234, \n",
      "neu: 0.634, \n",
      "pos: 0.132, \n",
      "compound: -0.9936, \n",
      "neg: 0.235, \n",
      "neu: 0.662, \n",
      "pos: 0.103, \n",
      "compound: -0.9942, \n",
      "neg: 0.284, \n",
      "neu: 0.566, \n",
      "pos: 0.15, \n",
      "compound: -0.9987, \n",
      "neg: 0.378, \n",
      "neu: 0.54, \n",
      "pos: 0.083, \n",
      "compound: -0.9894, \n",
      "neg: 0.234, \n",
      "neu: 0.641, \n",
      "pos: 0.126, \n",
      "compound: -0.9712, \n",
      "neg: 0.229, \n",
      "neu: 0.629, \n",
      "pos: 0.143, \n",
      "compound: -0.995, \n",
      "neg: 0.245, \n",
      "neu: 0.685, \n",
      "pos: 0.07, \n",
      "compound: -0.9805, \n",
      "neg: 0.259, \n",
      "neu: 0.591, \n",
      "pos: 0.15, \n",
      "compound: -0.9919, \n",
      "neg: 0.249, \n",
      "neu: 0.624, \n",
      "pos: 0.127, \n",
      "compound: -0.9891, \n",
      "neg: 0.245, \n",
      "neu: 0.607, \n",
      "pos: 0.148, \n",
      "compound: -0.9887, \n",
      "neg: 0.228, \n",
      "neu: 0.643, \n",
      "pos: 0.129, \n",
      "compound: -0.9946, \n",
      "neg: 0.242, \n",
      "neu: 0.639, \n",
      "pos: 0.118, \n",
      "compound: 0.7964, \n",
      "neg: 0.174, \n",
      "neu: 0.605, \n",
      "pos: 0.221, \n",
      "compound: -0.9758, \n",
      "neg: 0.2, \n",
      "neu: 0.66, \n",
      "pos: 0.14, \n",
      "compound: -0.9666, \n",
      "neg: 0.214, \n",
      "neu: 0.627, \n",
      "pos: 0.159, \n",
      "compound: -0.9882, \n",
      "neg: 0.209, \n",
      "neu: 0.7, \n",
      "pos: 0.092, \n",
      "compound: -0.9968, \n",
      "neg: 0.305, \n",
      "neu: 0.567, \n",
      "pos: 0.128, \n",
      "compound: -0.9969, \n",
      "neg: 0.305, \n",
      "neu: 0.584, \n",
      "pos: 0.111, \n",
      "compound: -0.9909, \n",
      "neg: 0.258, \n",
      "neu: 0.589, \n",
      "pos: 0.152, \n",
      "compound: -0.9928, \n",
      "neg: 0.229, \n",
      "neu: 0.677, \n",
      "pos: 0.094, \n",
      "compound: -0.9846, \n",
      "neg: 0.238, \n",
      "neu: 0.617, \n",
      "pos: 0.145, \n",
      "compound: -0.8957, \n",
      "neg: 0.163, \n",
      "neu: 0.704, \n",
      "pos: 0.133, \n",
      "compound: -0.9831, \n",
      "neg: 0.183, \n",
      "neu: 0.718, \n",
      "pos: 0.099, \n",
      "compound: -0.9826, \n",
      "neg: 0.225, \n",
      "neu: 0.645, \n",
      "pos: 0.129, \n",
      "compound: -0.9926, \n",
      "neg: 0.295, \n",
      "neu: 0.59, \n",
      "pos: 0.115, \n",
      "compound: -0.9618, \n",
      "neg: 0.185, \n",
      "neu: 0.674, \n",
      "pos: 0.141, \n",
      "compound: -0.9847, \n",
      "neg: 0.241, \n",
      "neu: 0.609, \n",
      "pos: 0.15, \n",
      "compound: -0.9871, \n",
      "neg: 0.228, \n",
      "neu: 0.653, \n",
      "pos: 0.119, \n",
      "compound: -0.985, \n",
      "neg: 0.246, \n",
      "neu: 0.594, \n",
      "pos: 0.16, \n",
      "compound: -0.9966, \n",
      "neg: 0.29, \n",
      "neu: 0.643, \n",
      "pos: 0.067, \n",
      "compound: -0.9758, \n",
      "neg: 0.203, \n",
      "neu: 0.653, \n",
      "pos: 0.144, \n",
      "compound: -0.9977, \n",
      "neg: 0.327, \n",
      "neu: 0.613, \n",
      "pos: 0.06, \n",
      "compound: -0.7269, \n",
      "neg: 0.167, \n",
      "neu: 0.669, \n",
      "pos: 0.164, \n",
      "compound: -0.9942, \n",
      "neg: 0.264, \n",
      "neu: 0.648, \n",
      "pos: 0.088, \n",
      "compound: -0.9892, \n",
      "neg: 0.236, \n",
      "neu: 0.642, \n",
      "pos: 0.122, \n",
      "compound: -0.9953, \n",
      "neg: 0.27, \n",
      "neu: 0.641, \n",
      "pos: 0.088, \n",
      "compound: -0.9988, \n",
      "neg: 0.401, \n",
      "neu: 0.563, \n",
      "pos: 0.036, \n",
      "compound: -0.9906, \n",
      "neg: 0.267, \n",
      "neu: 0.594, \n",
      "pos: 0.14, \n",
      "compound: -0.9774, \n",
      "neg: 0.211, \n",
      "neu: 0.661, \n",
      "pos: 0.128, \n",
      "compound: -0.9764, \n",
      "neg: 0.203, \n",
      "neu: 0.665, \n",
      "pos: 0.132, \n",
      "compound: -0.9919, \n",
      "neg: 0.268, \n",
      "neu: 0.602, \n",
      "pos: 0.13, \n",
      "compound: -0.9943, \n",
      "neg: 0.262, \n",
      "neu: 0.604, \n",
      "pos: 0.134, \n",
      "compound: -0.9987, \n",
      "neg: 0.351, \n",
      "neu: 0.606, \n",
      "pos: 0.043, \n",
      "compound: -0.9928, \n",
      "neg: 0.251, \n",
      "neu: 0.649, \n",
      "pos: 0.101, \n",
      "compound: -0.9934, \n",
      "neg: 0.219, \n",
      "neu: 0.732, \n",
      "pos: 0.049, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.9913, \n",
      "neg: 0.26, \n",
      "neu: 0.609, \n",
      "pos: 0.131, \n",
      "compound: -0.9551, \n",
      "neg: 0.22, \n",
      "neu: 0.631, \n",
      "pos: 0.149, \n",
      "compound: -0.8854, \n",
      "neg: 0.19, \n",
      "neu: 0.636, \n",
      "pos: 0.174, \n",
      "compound: -0.9938, \n",
      "neg: 0.275, \n",
      "neu: 0.616, \n",
      "pos: 0.109, \n",
      "compound: -0.994, \n",
      "neg: 0.247, \n",
      "neu: 0.658, \n",
      "pos: 0.096, \n",
      "compound: -0.9987, \n",
      "neg: 0.356, \n",
      "neu: 0.584, \n",
      "pos: 0.06, \n",
      "compound: -0.9982, \n",
      "neg: 0.33, \n",
      "neu: 0.584, \n",
      "pos: 0.086, \n",
      "compound: -0.998, \n",
      "neg: 0.336, \n",
      "neu: 0.6, \n",
      "pos: 0.064, \n",
      "compound: -0.9928, \n",
      "neg: 0.253, \n",
      "neu: 0.613, \n",
      "pos: 0.134, \n",
      "compound: -0.9938, \n",
      "neg: 0.275, \n",
      "neu: 0.616, \n",
      "pos: 0.109, \n",
      "compound: -0.9933, \n",
      "neg: 0.266, \n",
      "neu: 0.63, \n",
      "pos: 0.104, \n",
      "compound: -0.9946, \n",
      "neg: 0.294, \n",
      "neu: 0.544, \n",
      "pos: 0.162, \n",
      "compound: -0.989, \n",
      "neg: 0.221, \n",
      "neu: 0.67, \n",
      "pos: 0.108, \n",
      "compound: -0.9929, \n",
      "neg: 0.23, \n",
      "neu: 0.699, \n",
      "pos: 0.071, \n",
      "compound: 0.6908, \n",
      "neg: 0.161, \n",
      "neu: 0.656, \n",
      "pos: 0.183, \n",
      "compound: -0.9871, \n",
      "neg: 0.256, \n",
      "neu: 0.638, \n",
      "pos: 0.106, \n",
      "compound: -0.9982, \n",
      "neg: 0.353, \n",
      "neu: 0.561, \n",
      "pos: 0.086, \n",
      "compound: -0.9978, \n",
      "neg: 0.304, \n",
      "neu: 0.642, \n",
      "pos: 0.054, \n",
      "compound: -0.9892, \n",
      "neg: 0.196, \n",
      "neu: 0.695, \n",
      "pos: 0.108, \n",
      "compound: -0.9963, \n",
      "neg: 0.291, \n",
      "neu: 0.653, \n",
      "pos: 0.056, \n",
      "compound: -0.9959, \n",
      "neg: 0.262, \n",
      "neu: 0.634, \n",
      "pos: 0.104, \n",
      "compound: -0.9666, \n",
      "neg: 0.247, \n",
      "neu: 0.553, \n",
      "pos: 0.2, \n",
      "compound: -0.9981, \n",
      "neg: 0.358, \n",
      "neu: 0.526, \n",
      "pos: 0.116, \n",
      "compound: -0.995, \n",
      "neg: 0.269, \n",
      "neu: 0.619, \n",
      "pos: 0.112, \n",
      "compound: -0.9899, \n",
      "neg: 0.232, \n",
      "neu: 0.638, \n",
      "pos: 0.13, \n",
      "compound: -0.9967, \n",
      "neg: 0.312, \n",
      "neu: 0.563, \n",
      "pos: 0.124, \n",
      "compound: -0.988, \n",
      "neg: 0.245, \n",
      "neu: 0.634, \n",
      "pos: 0.122, \n",
      "compound: -0.9506, \n",
      "neg: 0.239, \n",
      "neu: 0.57, \n",
      "pos: 0.191, \n",
      "compound: -0.9968, \n",
      "neg: 0.309, \n",
      "neu: 0.61, \n",
      "pos: 0.081, \n",
      "compound: -0.5994, \n",
      "neg: 0.152, \n",
      "neu: 0.692, \n",
      "pos: 0.156, \n",
      "compound: -0.9917, \n",
      "neg: 0.223, \n",
      "neu: 0.68, \n",
      "pos: 0.097, \n",
      "compound: -0.9909, \n",
      "neg: 0.242, \n",
      "neu: 0.628, \n",
      "pos: 0.13, \n",
      "compound: -0.9958, \n",
      "neg: 0.283, \n",
      "neu: 0.633, \n",
      "pos: 0.084, \n",
      "compound: -0.9972, \n",
      "neg: 0.32, \n",
      "neu: 0.601, \n",
      "pos: 0.079, \n",
      "compound: -0.9916, \n",
      "neg: 0.245, \n",
      "neu: 0.656, \n",
      "pos: 0.098, \n",
      "compound: -0.9969, \n",
      "neg: 0.273, \n",
      "neu: 0.64, \n",
      "pos: 0.087, \n",
      "compound: -0.9965, \n",
      "neg: 0.312, \n",
      "neu: 0.597, \n",
      "pos: 0.091, \n",
      "compound: -0.9932, \n",
      "neg: 0.23, \n",
      "neu: 0.693, \n",
      "pos: 0.077, \n",
      "compound: -0.9861, \n",
      "neg: 0.255, \n",
      "neu: 0.605, \n",
      "pos: 0.14, \n",
      "compound: -0.9908, \n",
      "neg: 0.27, \n",
      "neu: 0.571, \n",
      "pos: 0.159, \n",
      "compound: -0.9967, \n",
      "neg: 0.283, \n",
      "neu: 0.599, \n",
      "pos: 0.117, \n",
      "compound: -0.7906, \n",
      "neg: 0.198, \n",
      "neu: 0.611, \n",
      "pos: 0.191, \n",
      "compound: -0.9964, \n",
      "neg: 0.289, \n",
      "neu: 0.596, \n",
      "pos: 0.115, \n",
      "compound: -0.9966, \n",
      "neg: 0.256, \n",
      "neu: 0.672, \n",
      "pos: 0.072, \n",
      "compound: -0.994, \n",
      "neg: 0.281, \n",
      "neu: 0.582, \n",
      "pos: 0.136, \n",
      "compound: -0.9921, \n",
      "neg: 0.252, \n",
      "neu: 0.64, \n",
      "pos: 0.108, \n",
      "compound: -0.9941, \n",
      "neg: 0.303, \n",
      "neu: 0.57, \n",
      "pos: 0.127, \n",
      "compound: -0.9976, \n",
      "neg: 0.342, \n",
      "neu: 0.632, \n",
      "pos: 0.026, \n",
      "compound: -0.9972, \n",
      "neg: 0.287, \n",
      "neu: 0.614, \n",
      "pos: 0.099, \n",
      "compound: -0.985, \n",
      "neg: 0.188, \n",
      "neu: 0.75, \n",
      "pos: 0.062, \n",
      "compound: -0.9982, \n",
      "neg: 0.369, \n",
      "neu: 0.571, \n",
      "pos: 0.059, \n",
      "compound: -0.9968, \n",
      "neg: 0.315, \n",
      "neu: 0.621, \n",
      "pos: 0.064, \n",
      "compound: -0.9966, \n",
      "neg: 0.294, \n",
      "neu: 0.603, \n",
      "pos: 0.103, \n",
      "compound: -0.9957, \n",
      "neg: 0.264, \n",
      "neu: 0.655, \n",
      "pos: 0.081, \n",
      "compound: -0.9753, \n",
      "neg: 0.209, \n",
      "neu: 0.701, \n",
      "pos: 0.09, \n",
      "compound: -0.9716, \n",
      "neg: 0.178, \n",
      "neu: 0.722, \n",
      "pos: 0.1, \n",
      "compound: -0.998, \n",
      "neg: 0.316, \n",
      "neu: 0.619, \n",
      "pos: 0.066, \n",
      "compound: -0.9861, \n",
      "neg: 0.241, \n",
      "neu: 0.623, \n",
      "pos: 0.136, \n",
      "compound: -0.9964, \n",
      "neg: 0.325, \n",
      "neu: 0.563, \n",
      "pos: 0.113, \n",
      "compound: -0.9895, \n",
      "neg: 0.255, \n",
      "neu: 0.62, \n",
      "pos: 0.125, \n",
      "compound: -0.9732, \n",
      "neg: 0.242, \n",
      "neu: 0.631, \n",
      "pos: 0.127, \n",
      "compound: -0.9883, \n",
      "neg: 0.242, \n",
      "neu: 0.626, \n",
      "pos: 0.132, \n",
      "compound: -0.9349, \n",
      "neg: 0.195, \n",
      "neu: 0.64, \n",
      "pos: 0.164, \n",
      "compound: -0.9717, \n",
      "neg: 0.229, \n",
      "neu: 0.609, \n",
      "pos: 0.162, \n",
      "compound: -0.8399, \n",
      "neg: 0.193, \n",
      "neu: 0.65, \n",
      "pos: 0.157, \n",
      "compound: -0.9951, \n",
      "neg: 0.254, \n",
      "neu: 0.656, \n",
      "pos: 0.09, \n",
      "compound: -0.9136, \n",
      "neg: 0.153, \n",
      "neu: 0.742, \n",
      "pos: 0.105, \n",
      "compound: -0.9958, \n",
      "neg: 0.261, \n",
      "neu: 0.637, \n",
      "pos: 0.102, \n",
      "compound: -0.9938, \n",
      "neg: 0.284, \n",
      "neu: 0.605, \n",
      "pos: 0.111, \n",
      "compound: -0.9901, \n",
      "neg: 0.235, \n",
      "neu: 0.655, \n",
      "pos: 0.11, \n",
      "compound: -0.9962, \n",
      "neg: 0.273, \n",
      "neu: 0.62, \n",
      "pos: 0.107, \n",
      "compound: -0.9964, \n",
      "neg: 0.243, \n",
      "neu: 0.696, \n",
      "pos: 0.061, \n",
      "compound: -0.9957, \n",
      "neg: 0.286, \n",
      "neu: 0.61, \n",
      "pos: 0.104, \n",
      "compound: -0.9965, \n",
      "neg: 0.29, \n",
      "neu: 0.626, \n",
      "pos: 0.083, \n",
      "compound: -0.9948, \n",
      "neg: 0.257, \n",
      "neu: 0.654, \n",
      "pos: 0.089, \n",
      "compound: -0.9938, \n",
      "neg: 0.291, \n",
      "neu: 0.638, \n",
      "pos: 0.071, \n",
      "compound: -0.9948, \n",
      "neg: 0.312, \n",
      "neu: 0.606, \n",
      "pos: 0.081, \n",
      "compound: -0.9878, \n",
      "neg: 0.24, \n",
      "neu: 0.612, \n",
      "pos: 0.148, \n",
      "compound: -0.9974, \n",
      "neg: 0.333, \n",
      "neu: 0.607, \n",
      "pos: 0.061, \n",
      "compound: -0.9783, \n",
      "neg: 0.238, \n",
      "neu: 0.618, \n",
      "pos: 0.144, \n",
      "compound: -0.9964, \n",
      "neg: 0.306, \n",
      "neu: 0.601, \n",
      "pos: 0.094, \n",
      "compound: -0.9967, \n",
      "neg: 0.281, \n",
      "neu: 0.643, \n",
      "pos: 0.077, \n",
      "compound: -0.9974, \n",
      "neg: 0.357, \n",
      "neu: 0.523, \n",
      "pos: 0.119, \n",
      "compound: -0.9949, \n",
      "neg: 0.259, \n",
      "neu: 0.632, \n",
      "pos: 0.109, \n",
      "compound: -0.9894, \n",
      "neg: 0.243, \n",
      "neu: 0.642, \n",
      "pos: 0.115, \n",
      "compound: -0.9894, \n",
      "neg: 0.252, \n",
      "neu: 0.619, \n",
      "pos: 0.129, \n",
      "compound: -0.9682, \n",
      "neg: 0.233, \n",
      "neu: 0.625, \n",
      "pos: 0.141, \n",
      "compound: -0.9914, \n",
      "neg: 0.214, \n",
      "neu: 0.698, \n",
      "pos: 0.088, \n",
      "compound: -0.9873, \n",
      "neg: 0.247, \n",
      "neu: 0.605, \n",
      "pos: 0.148, \n",
      "compound: -0.9984, \n",
      "neg: 0.333, \n",
      "neu: 0.618, \n",
      "pos: 0.049, \n",
      "compound: -0.9796, \n",
      "neg: 0.188, \n",
      "neu: 0.694, \n",
      "pos: 0.118, \n",
      "compound: -0.992, \n",
      "neg: 0.248, \n",
      "neu: 0.653, \n",
      "pos: 0.099, \n",
      "compound: -0.9965, \n",
      "neg: 0.287, \n",
      "neu: 0.613, \n",
      "pos: 0.1, \n",
      "compound: -0.8115, \n",
      "neg: 0.15, \n",
      "neu: 0.721, \n",
      "pos: 0.129, \n",
      "compound: -0.99, \n",
      "neg: 0.231, \n",
      "neu: 0.674, \n",
      "pos: 0.095, \n",
      "compound: -0.9413, \n",
      "neg: 0.175, \n",
      "neu: 0.704, \n",
      "pos: 0.122, \n",
      "compound: -0.7412, \n",
      "neg: 0.165, \n",
      "neu: 0.698, \n",
      "pos: 0.137, \n",
      "compound: -0.9912, \n",
      "neg: 0.235, \n",
      "neu: 0.64, \n",
      "pos: 0.125, \n",
      "compound: -0.998, \n",
      "neg: 0.346, \n",
      "neu: 0.558, \n",
      "pos: 0.095, \n",
      "compound: -0.9946, \n",
      "neg: 0.268, \n",
      "neu: 0.612, \n",
      "pos: 0.121, \n",
      "compound: -0.9925, \n",
      "neg: 0.277, \n",
      "neu: 0.603, \n",
      "pos: 0.12, \n",
      "compound: -0.9927, \n",
      "neg: 0.277, \n",
      "neu: 0.606, \n",
      "pos: 0.116, \n",
      "compound: -0.9979, \n",
      "neg: 0.347, \n",
      "neu: 0.572, \n",
      "pos: 0.081, \n",
      "compound: -0.9933, \n",
      "neg: 0.283, \n",
      "neu: 0.586, \n",
      "pos: 0.131, \n",
      "compound: -0.994, \n",
      "neg: 0.276, \n",
      "neu: 0.622, \n",
      "pos: 0.102, \n",
      "compound: -0.9836, \n",
      "neg: 0.237, \n",
      "neu: 0.627, \n",
      "pos: 0.136, \n",
      "compound: -0.9948, \n",
      "neg: 0.306, \n",
      "neu: 0.561, \n",
      "pos: 0.133, \n",
      "compound: -0.9942, \n",
      "neg: 0.246, \n",
      "neu: 0.658, \n",
      "pos: 0.096, \n",
      "compound: -0.9926, \n",
      "neg: 0.24, \n",
      "neu: 0.658, \n",
      "pos: 0.102, \n",
      "compound: -0.9983, \n",
      "neg: 0.365, \n",
      "neu: 0.529, \n",
      "pos: 0.106, \n",
      "compound: -0.91, \n",
      "neg: 0.197, \n",
      "neu: 0.645, \n",
      "pos: 0.158, \n",
      "compound: -0.9774, \n",
      "neg: 0.203, \n",
      "neu: 0.689, \n",
      "pos: 0.108, \n",
      "compound: -0.9975, \n",
      "neg: 0.321, \n",
      "neu: 0.578, \n",
      "pos: 0.101, \n",
      "compound: -0.9943, \n",
      "neg: 0.287, \n",
      "neu: 0.621, \n",
      "pos: 0.092, \n",
      "compound: -0.9918, \n",
      "neg: 0.216, \n",
      "neu: 0.736, \n",
      "pos: 0.048, \n",
      "compound: -0.9931, \n",
      "neg: 0.222, \n",
      "neu: 0.708, \n",
      "pos: 0.07, \n",
      "compound: -0.9984, \n",
      "neg: 0.34, \n",
      "neu: 0.582, \n",
      "pos: 0.078, \n",
      "compound: -0.9938, \n",
      "neg: 0.221, \n",
      "neu: 0.705, \n",
      "pos: 0.074, \n",
      "compound: -0.9863, \n",
      "neg: 0.237, \n",
      "neu: 0.615, \n",
      "pos: 0.149, \n",
      "compound: -0.9934, \n",
      "neg: 0.223, \n",
      "neu: 0.698, \n",
      "pos: 0.08, \n",
      "compound: -0.9607, \n",
      "neg: 0.181, \n",
      "neu: 0.714, \n",
      "pos: 0.105, \n",
      "compound: -0.9983, \n",
      "neg: 0.325, \n",
      "neu: 0.576, \n",
      "pos: 0.099, \n",
      "compound: -0.9921, \n",
      "neg: 0.262, \n",
      "neu: 0.654, \n",
      "pos: 0.084, \n",
      "compound: -0.9959, \n",
      "neg: 0.263, \n",
      "neu: 0.623, \n",
      "pos: 0.114, \n",
      "compound: -0.9969, \n",
      "neg: 0.238, \n",
      "neu: 0.74, \n",
      "pos: 0.023, \n",
      "compound: -0.9981, \n",
      "neg: 0.325, \n",
      "neu: 0.615, \n",
      "pos: 0.06, \n",
      "compound: -0.9925, \n",
      "neg: 0.232, \n",
      "neu: 0.637, \n",
      "pos: 0.131, \n",
      "compound: -0.9936, \n",
      "neg: 0.261, \n",
      "neu: 0.622, \n",
      "pos: 0.117, \n",
      "compound: -0.9837, \n",
      "neg: 0.194, \n",
      "neu: 0.717, \n",
      "pos: 0.089, \n",
      "compound: -0.9719, \n",
      "neg: 0.187, \n",
      "neu: 0.695, \n",
      "pos: 0.118, \n",
      "compound: -0.9961, \n",
      "neg: 0.271, \n",
      "neu: 0.633, \n",
      "pos: 0.096, \n",
      "compound: -0.9965, \n",
      "neg: 0.265, \n",
      "neu: 0.663, \n",
      "pos: 0.072, \n",
      "compound: -0.9538, \n",
      "neg: 0.19, \n",
      "neu: 0.661, \n",
      "pos: 0.15, \n",
      "compound: -0.9948, \n",
      "neg: 0.241, \n",
      "neu: 0.644, \n",
      "pos: 0.115, \n",
      "compound: -0.9913, \n",
      "neg: 0.203, \n",
      "neu: 0.71, \n",
      "pos: 0.087, \n",
      "compound: -0.9936, \n",
      "neg: 0.227, \n",
      "neu: 0.673, \n",
      "pos: 0.101, \n",
      "compound: -0.9883, \n",
      "neg: 0.209, \n",
      "neu: 0.696, \n",
      "pos: 0.095, \n",
      "compound: -0.9673, \n",
      "neg: 0.224, \n",
      "neu: 0.633, \n",
      "pos: 0.143, \n",
      "compound: -0.9915, \n",
      "neg: 0.264, \n",
      "neu: 0.61, \n",
      "pos: 0.127, \n",
      "compound: -0.9934, \n",
      "neg: 0.248, \n",
      "neu: 0.681, \n",
      "pos: 0.071, \n",
      "compound: -0.9774, \n",
      "neg: 0.21, \n",
      "neu: 0.658, \n",
      "pos: 0.132, \n",
      "compound: -0.9966, \n",
      "neg: 0.324, \n",
      "neu: 0.593, \n",
      "pos: 0.083, \n",
      "compound: -0.9186, \n",
      "neg: 0.184, \n",
      "neu: 0.665, \n",
      "pos: 0.152, \n",
      "compound: -0.9975, \n",
      "neg: 0.316, \n",
      "neu: 0.555, \n",
      "pos: 0.129, \n",
      "compound: -0.9882, \n",
      "neg: 0.254, \n",
      "neu: 0.604, \n",
      "pos: 0.143, \n",
      "compound: -0.9937, \n",
      "neg: 0.267, \n",
      "neu: 0.603, \n",
      "pos: 0.131, \n",
      "compound: -0.9969, \n",
      "neg: 0.29, \n",
      "neu: 0.618, \n",
      "pos: 0.092, \n",
      "compound: -0.9747, \n",
      "neg: 0.196, \n",
      "neu: 0.691, \n",
      "pos: 0.113, \n",
      "compound: -0.9987, \n",
      "neg: 0.377, \n",
      "neu: 0.539, \n",
      "pos: 0.084, \n",
      "compound: -0.9934, \n",
      "neg: 0.225, \n",
      "neu: 0.685, \n",
      "pos: 0.09, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.9957, \n",
      "neg: 0.242, \n",
      "neu: 0.699, \n",
      "pos: 0.059, \n",
      "compound: -0.9948, \n",
      "neg: 0.243, \n",
      "neu: 0.65, \n",
      "pos: 0.107, \n",
      "compound: -0.9973, \n",
      "neg: 0.281, \n",
      "neu: 0.624, \n",
      "pos: 0.094, \n",
      "compound: -0.9186, \n",
      "neg: 0.159, \n",
      "neu: 0.711, \n",
      "pos: 0.13, \n",
      "compound: 0.8979, \n",
      "neg: 0.122, \n",
      "neu: 0.695, \n",
      "pos: 0.184, \n",
      "compound: -0.9986, \n",
      "neg: 0.344, \n",
      "neu: 0.584, \n",
      "pos: 0.072, \n",
      "compound: -0.9922, \n",
      "neg: 0.251, \n",
      "neu: 0.635, \n",
      "pos: 0.113, \n",
      "compound: -0.9834, \n",
      "neg: 0.242, \n",
      "neu: 0.626, \n",
      "pos: 0.132, \n",
      "compound: -0.9961, \n",
      "neg: 0.273, \n",
      "neu: 0.608, \n",
      "pos: 0.119, \n",
      "compound: -0.994, \n",
      "neg: 0.276, \n",
      "neu: 0.591, \n",
      "pos: 0.133, \n",
      "compound: -0.9957, \n",
      "neg: 0.286, \n",
      "neu: 0.619, \n",
      "pos: 0.095, \n",
      "compound: -0.9944, \n",
      "neg: 0.256, \n",
      "neu: 0.643, \n",
      "pos: 0.101, \n",
      "compound: -0.9878, \n",
      "neg: 0.189, \n",
      "neu: 0.74, \n",
      "pos: 0.071, \n",
      "compound: -0.9932, \n",
      "neg: 0.247, \n",
      "neu: 0.625, \n",
      "pos: 0.128, \n",
      "compound: -0.8979, \n",
      "neg: 0.187, \n",
      "neu: 0.652, \n",
      "pos: 0.161, \n",
      "compound: -0.9948, \n",
      "neg: 0.279, \n",
      "neu: 0.65, \n",
      "pos: 0.07, \n",
      "compound: -0.9074, \n",
      "neg: 0.171, \n",
      "neu: 0.727, \n",
      "pos: 0.102, \n",
      "compound: -0.9887, \n",
      "neg: 0.272, \n",
      "neu: 0.577, \n",
      "pos: 0.151, \n",
      "compound: -0.9775, \n",
      "neg: 0.222, \n",
      "neu: 0.634, \n",
      "pos: 0.144, \n",
      "compound: -0.9979, \n",
      "neg: 0.303, \n",
      "neu: 0.628, \n",
      "pos: 0.069, \n",
      "compound: -0.5859, \n",
      "neg: 0.166, \n",
      "neu: 0.688, \n",
      "pos: 0.146, \n",
      "compound: -0.9906, \n",
      "neg: 0.234, \n",
      "neu: 0.66, \n",
      "pos: 0.106, \n",
      "compound: -0.9953, \n",
      "neg: 0.252, \n",
      "neu: 0.673, \n",
      "pos: 0.075, \n",
      "compound: -0.9968, \n",
      "neg: 0.284, \n",
      "neu: 0.637, \n",
      "pos: 0.078, \n",
      "compound: -0.9919, \n",
      "neg: 0.259, \n",
      "neu: 0.636, \n",
      "pos: 0.105, \n",
      "compound: -0.9919, \n",
      "neg: 0.263, \n",
      "neu: 0.628, \n",
      "pos: 0.109, \n",
      "compound: -0.9907, \n",
      "neg: 0.215, \n",
      "neu: 0.689, \n",
      "pos: 0.096, \n",
      "compound: -0.9929, \n",
      "neg: 0.24, \n",
      "neu: 0.689, \n",
      "pos: 0.071, \n",
      "compound: -0.9524, \n",
      "neg: 0.193, \n",
      "neu: 0.654, \n",
      "pos: 0.153, \n",
      "compound: -0.9965, \n",
      "neg: 0.263, \n",
      "neu: 0.68, \n",
      "pos: 0.058, \n",
      "compound: -0.9978, \n",
      "neg: 0.336, \n",
      "neu: 0.589, \n",
      "pos: 0.075, \n",
      "compound: -0.9509, \n",
      "neg: 0.223, \n",
      "neu: 0.632, \n",
      "pos: 0.144, \n",
      "compound: -0.9819, \n",
      "neg: 0.196, \n",
      "neu: 0.699, \n",
      "pos: 0.105, \n",
      "compound: -0.9938, \n",
      "neg: 0.249, \n",
      "neu: 0.671, \n",
      "pos: 0.08, \n",
      "compound: -0.9894, \n",
      "neg: 0.203, \n",
      "neu: 0.708, \n",
      "pos: 0.089, \n",
      "compound: -0.9924, \n",
      "neg: 0.246, \n",
      "neu: 0.636, \n",
      "pos: 0.118, \n",
      "compound: -0.9919, \n",
      "neg: 0.228, \n",
      "neu: 0.676, \n",
      "pos: 0.096, \n",
      "compound: -0.9962, \n",
      "neg: 0.258, \n",
      "neu: 0.676, \n",
      "pos: 0.065, \n",
      "compound: -0.9705, \n",
      "neg: 0.213, \n",
      "neu: 0.64, \n",
      "pos: 0.147, \n",
      "compound: -0.8281, \n",
      "neg: 0.171, \n",
      "neu: 0.694, \n",
      "pos: 0.136, \n",
      "compound: -0.9889, \n",
      "neg: 0.269, \n",
      "neu: 0.622, \n",
      "pos: 0.108, \n",
      "compound: -0.9972, \n",
      "neg: 0.281, \n",
      "neu: 0.655, \n",
      "pos: 0.064, \n",
      "compound: -0.9947, \n",
      "neg: 0.217, \n",
      "neu: 0.741, \n",
      "pos: 0.042, \n",
      "compound: -0.9788, \n",
      "neg: 0.233, \n",
      "neu: 0.62, \n",
      "pos: 0.147, \n",
      "compound: -0.9623, \n",
      "neg: 0.179, \n",
      "neu: 0.735, \n",
      "pos: 0.086, \n",
      "compound: -0.9937, \n",
      "neg: 0.235, \n",
      "neu: 0.657, \n",
      "pos: 0.108, \n",
      "compound: -0.9859, \n",
      "neg: 0.232, \n",
      "neu: 0.619, \n",
      "pos: 0.149, \n",
      "compound: -0.9965, \n",
      "neg: 0.277, \n",
      "neu: 0.588, \n",
      "pos: 0.136, \n",
      "compound: -0.8271, \n",
      "neg: 0.168, \n",
      "neu: 0.694, \n",
      "pos: 0.138, \n",
      "compound: -0.991, \n",
      "neg: 0.258, \n",
      "neu: 0.634, \n",
      "pos: 0.108, \n",
      "compound: -0.9936, \n",
      "neg: 0.237, \n",
      "neu: 0.675, \n",
      "pos: 0.088, \n",
      "compound: -0.9976, \n",
      "neg: 0.25, \n",
      "neu: 0.701, \n",
      "pos: 0.049, \n",
      "compound: -0.9922, \n",
      "neg: 0.211, \n",
      "neu: 0.706, \n",
      "pos: 0.083, \n",
      "compound: -0.9976, \n",
      "neg: 0.307, \n",
      "neu: 0.621, \n",
      "pos: 0.072, \n",
      "compound: -0.9947, \n",
      "neg: 0.318, \n",
      "neu: 0.587, \n",
      "pos: 0.095, \n",
      "compound: -0.9918, \n",
      "neg: 0.245, \n",
      "neu: 0.671, \n",
      "pos: 0.084, \n",
      "compound: -0.9968, \n",
      "neg: 0.292, \n",
      "neu: 0.632, \n",
      "pos: 0.075, \n",
      "compound: -0.9972, \n",
      "neg: 0.308, \n",
      "neu: 0.591, \n",
      "pos: 0.1, \n",
      "compound: -0.959, \n",
      "neg: 0.175, \n",
      "neu: 0.709, \n",
      "pos: 0.117, \n",
      "compound: -0.8176, \n",
      "neg: 0.145, \n",
      "neu: 0.727, \n",
      "pos: 0.127, \n",
      "compound: -0.9652, \n",
      "neg: 0.208, \n",
      "neu: 0.628, \n",
      "pos: 0.164, \n",
      "compound: -0.992, \n",
      "neg: 0.288, \n",
      "neu: 0.561, \n",
      "pos: 0.151, \n",
      "compound: -0.9602, \n",
      "neg: 0.206, \n",
      "neu: 0.626, \n",
      "pos: 0.168, \n",
      "compound: -0.9719, \n",
      "neg: 0.221, \n",
      "neu: 0.635, \n",
      "pos: 0.144, \n",
      "compound: -0.9898, \n",
      "neg: 0.251, \n",
      "neu: 0.62, \n",
      "pos: 0.13, \n",
      "compound: -0.6712, \n",
      "neg: 0.206, \n",
      "neu: 0.586, \n",
      "pos: 0.208, \n",
      "compound: -0.765, \n",
      "neg: 0.179, \n",
      "neu: 0.662, \n",
      "pos: 0.159, \n",
      "compound: -0.9944, \n",
      "neg: 0.254, \n",
      "neu: 0.652, \n",
      "pos: 0.094, \n",
      "compound: -0.9451, \n",
      "neg: 0.212, \n",
      "neu: 0.629, \n",
      "pos: 0.158, \n",
      "compound: -0.9607, \n",
      "neg: 0.141, \n",
      "neu: 0.792, \n",
      "pos: 0.068, \n",
      "compound: -0.9964, \n",
      "neg: 0.268, \n",
      "neu: 0.66, \n",
      "pos: 0.072, \n",
      "compound: -0.9981, \n",
      "neg: 0.348, \n",
      "neu: 0.584, \n",
      "pos: 0.069, \n",
      "compound: -0.996, \n",
      "neg: 0.282, \n",
      "neu: 0.656, \n",
      "pos: 0.062, \n",
      "compound: -0.9975, \n",
      "neg: 0.33, \n",
      "neu: 0.537, \n",
      "pos: 0.133, \n",
      "compound: -0.9923, \n",
      "neg: 0.26, \n",
      "neu: 0.633, \n",
      "pos: 0.107, \n",
      "compound: -0.9977, \n",
      "neg: 0.331, \n",
      "neu: 0.581, \n",
      "pos: 0.089, \n",
      "compound: -0.9941, \n",
      "neg: 0.247, \n",
      "neu: 0.669, \n",
      "pos: 0.085, \n",
      "compound: -0.9882, \n",
      "neg: 0.245, \n",
      "neu: 0.616, \n",
      "pos: 0.139, \n",
      "compound: -0.9584, \n",
      "neg: 0.218, \n",
      "neu: 0.62, \n",
      "pos: 0.162, \n",
      "compound: -0.9899, \n",
      "neg: 0.196, \n",
      "neu: 0.726, \n",
      "pos: 0.078, \n",
      "compound: -0.9975, \n",
      "neg: 0.264, \n",
      "neu: 0.699, \n",
      "pos: 0.036, \n",
      "compound: -0.992, \n",
      "neg: 0.233, \n",
      "neu: 0.653, \n",
      "pos: 0.114, \n",
      "compound: -0.9945, \n",
      "neg: 0.246, \n",
      "neu: 0.655, \n",
      "pos: 0.099, \n",
      "compound: -0.9927, \n",
      "neg: 0.24, \n",
      "neu: 0.656, \n",
      "pos: 0.103, \n",
      "compound: -0.9905, \n",
      "neg: 0.235, \n",
      "neu: 0.624, \n",
      "pos: 0.141, \n",
      "compound: -0.9792, \n",
      "neg: 0.211, \n",
      "neu: 0.635, \n",
      "pos: 0.154, \n",
      "compound: -0.9442, \n",
      "neg: 0.168, \n",
      "neu: 0.707, \n",
      "pos: 0.126, \n",
      "compound: -0.9957, \n",
      "neg: 0.267, \n",
      "neu: 0.611, \n",
      "pos: 0.121, \n",
      "compound: -0.9902, \n",
      "neg: 0.249, \n",
      "neu: 0.62, \n",
      "pos: 0.131, \n",
      "compound: -0.9451, \n",
      "neg: 0.146, \n",
      "neu: 0.75, \n",
      "pos: 0.104, \n",
      "compound: -0.9959, \n",
      "neg: 0.29, \n",
      "neu: 0.609, \n",
      "pos: 0.101, \n",
      "compound: -0.9854, \n",
      "neg: 0.212, \n",
      "neu: 0.664, \n",
      "pos: 0.124, \n",
      "compound: -0.9775, \n",
      "neg: 0.248, \n",
      "neu: 0.597, \n",
      "pos: 0.155, \n",
      "compound: -0.9905, \n",
      "neg: 0.208, \n",
      "neu: 0.725, \n",
      "pos: 0.067, \n",
      "compound: -0.975, \n",
      "neg: 0.214, \n",
      "neu: 0.652, \n",
      "pos: 0.134, \n",
      "compound: -0.9416, \n",
      "neg: 0.205, \n",
      "neu: 0.623, \n",
      "pos: 0.173, \n",
      "compound: -0.9978, \n",
      "neg: 0.329, \n",
      "neu: 0.587, \n",
      "pos: 0.085, \n",
      "compound: -0.9929, \n",
      "neg: 0.217, \n",
      "neu: 0.686, \n",
      "pos: 0.097, \n",
      "compound: -0.9908, \n",
      "neg: 0.241, \n",
      "neu: 0.669, \n",
      "pos: 0.09, \n",
      "compound: -0.9883, \n",
      "neg: 0.242, \n",
      "neu: 0.622, \n",
      "pos: 0.136, \n",
      "compound: -0.991, \n",
      "neg: 0.221, \n",
      "neu: 0.689, \n",
      "pos: 0.09, \n",
      "compound: -0.9963, \n",
      "neg: 0.246, \n",
      "neu: 0.655, \n",
      "pos: 0.1, \n",
      "compound: -0.9957, \n",
      "neg: 0.271, \n",
      "neu: 0.62, \n",
      "pos: 0.109, \n",
      "compound: 0.3818, \n",
      "neg: 0.142, \n",
      "neu: 0.714, \n",
      "pos: 0.144, \n",
      "compound: -0.9764, \n",
      "neg: 0.201, \n",
      "neu: 0.681, \n",
      "pos: 0.118, \n",
      "compound: -0.9761, \n",
      "neg: 0.213, \n",
      "neu: 0.679, \n",
      "pos: 0.108, \n",
      "compound: -0.9442, \n",
      "neg: 0.209, \n",
      "neu: 0.646, \n",
      "pos: 0.145, \n",
      "compound: -0.7609, \n",
      "neg: 0.194, \n",
      "neu: 0.648, \n",
      "pos: 0.158, \n",
      "compound: -0.9914, \n",
      "neg: 0.244, \n",
      "neu: 0.647, \n",
      "pos: 0.109, \n",
      "compound: -0.9942, \n",
      "neg: 0.275, \n",
      "neu: 0.611, \n",
      "pos: 0.115, \n",
      "compound: -0.9947, \n",
      "neg: 0.286, \n",
      "neu: 0.593, \n",
      "pos: 0.12, \n",
      "compound: -0.9876, \n",
      "neg: 0.205, \n",
      "neu: 0.69, \n",
      "pos: 0.105, \n",
      "compound: -0.9976, \n",
      "neg: 0.297, \n",
      "neu: 0.62, \n",
      "pos: 0.083, \n",
      "compound: -0.9894, \n",
      "neg: 0.192, \n",
      "neu: 0.745, \n",
      "pos: 0.063, \n",
      "compound: -0.997, \n",
      "neg: 0.293, \n",
      "neu: 0.601, \n",
      "pos: 0.106, \n",
      "compound: -0.9595, \n",
      "neg: 0.169, \n",
      "neu: 0.697, \n",
      "pos: 0.134, \n",
      "compound: -0.996, \n",
      "neg: 0.255, \n",
      "neu: 0.662, \n",
      "pos: 0.083, \n",
      "compound: -0.9862, \n",
      "neg: 0.221, \n",
      "neu: 0.651, \n",
      "pos: 0.127, \n",
      "compound: -0.9737, \n",
      "neg: 0.184, \n",
      "neu: 0.7, \n",
      "pos: 0.116, \n",
      "compound: -0.9423, \n",
      "neg: 0.204, \n",
      "neu: 0.638, \n",
      "pos: 0.159, \n",
      "compound: -0.988, \n",
      "neg: 0.172, \n",
      "neu: 0.741, \n",
      "pos: 0.086, \n",
      "compound: -0.9933, \n",
      "neg: 0.185, \n",
      "neu: 0.761, \n",
      "pos: 0.054, \n",
      "compound: -0.9954, \n",
      "neg: 0.25, \n",
      "neu: 0.66, \n",
      "pos: 0.09, \n",
      "compound: -0.9976, \n",
      "neg: 0.353, \n",
      "neu: 0.563, \n",
      "pos: 0.084, \n",
      "compound: -0.9947, \n",
      "neg: 0.254, \n",
      "neu: 0.641, \n",
      "pos: 0.105, \n",
      "compound: -0.9937, \n",
      "neg: 0.259, \n",
      "neu: 0.617, \n",
      "pos: 0.124, \n",
      "compound: -0.9595, \n",
      "neg: 0.217, \n",
      "neu: 0.63, \n",
      "pos: 0.152, \n",
      "compound: -0.9966, \n",
      "neg: 0.266, \n",
      "neu: 0.639, \n",
      "pos: 0.095, \n",
      "compound: -0.9231, \n",
      "neg: 0.209, \n",
      "neu: 0.628, \n",
      "pos: 0.163, \n",
      "compound: 0.8137, \n",
      "neg: 0.123, \n",
      "neu: 0.733, \n",
      "pos: 0.144, \n",
      "compound: -0.9508, \n",
      "neg: 0.167, \n",
      "neu: 0.712, \n",
      "pos: 0.12, \n",
      "compound: -0.9397, \n",
      "neg: 0.206, \n",
      "neu: 0.64, \n",
      "pos: 0.154, \n",
      "compound: -0.9947, \n",
      "neg: 0.266, \n",
      "neu: 0.598, \n",
      "pos: 0.135, \n",
      "compound: -0.9964, \n",
      "neg: 0.244, \n",
      "neu: 0.685, \n",
      "pos: 0.07, \n",
      "compound: -0.9702, \n",
      "neg: 0.213, \n",
      "neu: 0.655, \n",
      "pos: 0.131, \n",
      "compound: -0.9953, \n",
      "neg: 0.316, \n",
      "neu: 0.598, \n",
      "pos: 0.085, \n",
      "compound: -0.9872, \n",
      "neg: 0.215, \n",
      "neu: 0.731, \n",
      "pos: 0.054, \n",
      "compound: -0.9861, \n",
      "neg: 0.194, \n",
      "neu: 0.749, \n",
      "pos: 0.058, \n",
      "compound: -0.9738, \n",
      "neg: 0.162, \n",
      "neu: 0.79, \n",
      "pos: 0.048, \n",
      "compound: -0.9169, \n",
      "neg: 0.202, \n",
      "neu: 0.662, \n",
      "pos: 0.136, \n",
      "compound: -0.93, \n",
      "neg: 0.157, \n",
      "neu: 0.743, \n",
      "pos: 0.1, \n",
      "compound: 0.128, \n",
      "neg: 0.142, \n",
      "neu: 0.714, \n",
      "pos: 0.144, \n",
      "compound: -0.9973, \n",
      "neg: 0.349, \n",
      "neu: 0.526, \n",
      "pos: 0.125, \n",
      "compound: -0.8807, \n",
      "neg: 0.172, \n",
      "neu: 0.685, \n",
      "pos: 0.144, \n",
      "compound: -0.9834, \n",
      "neg: 0.244, \n",
      "neu: 0.601, \n",
      "pos: 0.156, \n",
      "compound: -0.9913, \n",
      "neg: 0.195, \n",
      "neu: 0.762, \n",
      "pos: 0.042, \n",
      "compound: -0.9905, \n",
      "neg: 0.231, \n",
      "neu: 0.692, \n",
      "pos: 0.077, \n",
      "compound: -0.9688, \n",
      "neg: 0.199, \n",
      "neu: 0.672, \n",
      "pos: 0.129, \n",
      "compound: -0.926, \n",
      "neg: 0.155, \n",
      "neu: 0.722, \n",
      "pos: 0.123, \n",
      "compound: -0.9432, \n",
      "neg: 0.218, \n",
      "neu: 0.618, \n",
      "pos: 0.164, \n",
      "compound: -0.9958, \n",
      "neg: 0.294, \n",
      "neu: 0.616, \n",
      "pos: 0.089, \n",
      "compound: -0.9935, \n",
      "neg: 0.285, \n",
      "neu: 0.623, \n",
      "pos: 0.092, \n",
      "compound: -0.9925, \n",
      "neg: 0.275, \n",
      "neu: 0.61, \n",
      "pos: 0.115, \n",
      "compound: -0.9972, \n",
      "neg: 0.306, \n",
      "neu: 0.625, \n",
      "pos: 0.069, \n",
      "compound: -0.9195, \n",
      "neg: 0.155, \n",
      "neu: 0.735, \n",
      "pos: 0.11, \n",
      "compound: -0.9843, \n",
      "neg: 0.236, \n",
      "neu: 0.663, \n",
      "pos: 0.101, \n",
      "compound: -0.9413, \n",
      "neg: 0.231, \n",
      "neu: 0.597, \n",
      "pos: 0.172, \n",
      "compound: -0.9925, \n",
      "neg: 0.255, \n",
      "neu: 0.663, \n",
      "pos: 0.083, \n",
      "compound: -0.9722, \n",
      "neg: 0.2, \n",
      "neu: 0.664, \n",
      "pos: 0.135, \n",
      "compound: -0.9764, \n",
      "neg: 0.162, \n",
      "neu: 0.752, \n",
      "pos: 0.086, \n",
      "compound: -0.9958, \n",
      "neg: 0.275, \n",
      "neu: 0.629, \n",
      "pos: 0.096, \n",
      "compound: -0.993, \n",
      "neg: 0.239, \n",
      "neu: 0.662, \n",
      "pos: 0.1, \n",
      "compound: -0.9948, \n",
      "neg: 0.275, \n",
      "neu: 0.622, \n",
      "pos: 0.102, \n",
      "compound: 0.6808, \n",
      "neg: 0.153, \n",
      "neu: 0.676, \n",
      "pos: 0.171, \n",
      "compound: -0.9911, \n",
      "neg: 0.266, \n",
      "neu: 0.59, \n",
      "pos: 0.145, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.9936, \n",
      "neg: 0.25, \n",
      "neu: 0.666, \n",
      "pos: 0.084, \n",
      "compound: -0.9926, \n",
      "neg: 0.287, \n",
      "neu: 0.649, \n",
      "pos: 0.064, \n",
      "compound: -0.1027, \n",
      "neg: 0.115, \n",
      "neu: 0.771, \n",
      "pos: 0.114, \n",
      "compound: -0.9719, \n",
      "neg: 0.205, \n",
      "neu: 0.659, \n",
      "pos: 0.136, \n",
      "compound: -0.9657, \n",
      "neg: 0.214, \n",
      "neu: 0.645, \n",
      "pos: 0.14, \n",
      "compound: -0.9892, \n",
      "neg: 0.23, \n",
      "neu: 0.647, \n",
      "pos: 0.123, \n",
      "compound: -0.7184, \n",
      "neg: 0.181, \n",
      "neu: 0.654, \n",
      "pos: 0.165, \n",
      "compound: -0.9764, \n",
      "neg: 0.202, \n",
      "neu: 0.687, \n",
      "pos: 0.111, \n",
      "compound: -0.9922, \n",
      "neg: 0.233, \n",
      "neu: 0.681, \n",
      "pos: 0.086, \n",
      "compound: -0.9898, \n",
      "neg: 0.266, \n",
      "neu: 0.572, \n",
      "pos: 0.162, \n",
      "compound: -0.9952, \n",
      "neg: 0.271, \n",
      "neu: 0.653, \n",
      "pos: 0.076, \n",
      "compound: -0.9958, \n",
      "neg: 0.265, \n",
      "neu: 0.693, \n",
      "pos: 0.042, \n",
      "compound: -0.9883, \n",
      "neg: 0.228, \n",
      "neu: 0.671, \n",
      "pos: 0.101, \n",
      "compound: -0.9981, \n",
      "neg: 0.328, \n",
      "neu: 0.607, \n",
      "pos: 0.065, \n",
      "compound: -0.9904, \n",
      "neg: 0.264, \n",
      "neu: 0.634, \n",
      "pos: 0.103, \n",
      "compound: -0.9862, \n",
      "neg: 0.176, \n",
      "neu: 0.804, \n",
      "pos: 0.019, \n",
      "compound: -0.9942, \n",
      "neg: 0.288, \n",
      "neu: 0.626, \n",
      "pos: 0.085, \n",
      "compound: -0.9901, \n",
      "neg: 0.242, \n",
      "neu: 0.662, \n",
      "pos: 0.096, \n",
      "compound: -0.9948, \n",
      "neg: 0.287, \n",
      "neu: 0.626, \n",
      "pos: 0.087, \n",
      "compound: -0.9949, \n",
      "neg: 0.269, \n",
      "neu: 0.653, \n",
      "pos: 0.077, \n",
      "compound: -0.9908, \n",
      "neg: 0.234, \n",
      "neu: 0.66, \n",
      "pos: 0.106, \n",
      "compound: -0.9962, \n",
      "neg: 0.289, \n",
      "neu: 0.616, \n",
      "pos: 0.095, \n",
      "compound: -0.9895, \n",
      "neg: 0.236, \n",
      "neu: 0.634, \n",
      "pos: 0.129, \n",
      "compound: -0.9485, \n",
      "neg: 0.164, \n",
      "neu: 0.752, \n",
      "pos: 0.084, \n",
      "compound: -0.9953, \n",
      "neg: 0.349, \n",
      "neu: 0.511, \n",
      "pos: 0.14, \n",
      "compound: -0.9936, \n",
      "neg: 0.232, \n",
      "neu: 0.694, \n",
      "pos: 0.074, \n",
      "compound: -0.9945, \n",
      "neg: 0.274, \n",
      "neu: 0.656, \n",
      "pos: 0.07, \n",
      "compound: -0.9946, \n",
      "neg: 0.263, \n",
      "neu: 0.655, \n",
      "pos: 0.082, \n",
      "compound: -0.993, \n",
      "neg: 0.267, \n",
      "neu: 0.623, \n",
      "pos: 0.11, \n",
      "compound: -0.9919, \n",
      "neg: 0.245, \n",
      "neu: 0.646, \n",
      "pos: 0.109, \n",
      "compound: -0.9942, \n",
      "neg: 0.267, \n",
      "neu: 0.615, \n",
      "pos: 0.119, \n",
      "compound: -0.9856, \n",
      "neg: 0.231, \n",
      "neu: 0.68, \n",
      "pos: 0.089, \n",
      "compound: -0.9764, \n",
      "neg: 0.204, \n",
      "neu: 0.669, \n",
      "pos: 0.128, \n",
      "compound: -0.9975, \n",
      "neg: 0.271, \n",
      "neu: 0.631, \n",
      "pos: 0.098, \n",
      "compound: -0.9726, \n",
      "neg: 0.18, \n",
      "neu: 0.733, \n",
      "pos: 0.088, \n",
      "compound: -0.9382, \n",
      "neg: 0.215, \n",
      "neu: 0.608, \n",
      "pos: 0.177, \n",
      "compound: -0.9953, \n",
      "neg: 0.267, \n",
      "neu: 0.633, \n",
      "pos: 0.099, \n",
      "compound: -0.9931, \n",
      "neg: 0.262, \n",
      "neu: 0.648, \n",
      "pos: 0.09, \n",
      "compound: -0.9892, \n",
      "neg: 0.271, \n",
      "neu: 0.634, \n",
      "pos: 0.095, \n",
      "compound: -0.9952, \n",
      "neg: 0.258, \n",
      "neu: 0.665, \n",
      "pos: 0.077, \n",
      "compound: -0.997, \n",
      "neg: 0.273, \n",
      "neu: 0.657, \n",
      "pos: 0.07, \n",
      "compound: -0.9818, \n",
      "neg: 0.227, \n",
      "neu: 0.627, \n",
      "pos: 0.146, \n",
      "compound: -0.9959, \n",
      "neg: 0.269, \n",
      "neu: 0.616, \n",
      "pos: 0.115, \n",
      "compound: -0.9985, \n",
      "neg: 0.365, \n",
      "neu: 0.553, \n",
      "pos: 0.082, \n",
      "compound: -0.9878, \n",
      "neg: 0.232, \n",
      "neu: 0.661, \n",
      "pos: 0.107, \n",
      "compound: -0.998, \n",
      "neg: 0.308, \n",
      "neu: 0.636, \n",
      "pos: 0.055, \n",
      "compound: -0.9966, \n",
      "neg: 0.27, \n",
      "neu: 0.639, \n",
      "pos: 0.091, \n",
      "compound: -0.9925, \n",
      "neg: 0.25, \n",
      "neu: 0.648, \n",
      "pos: 0.102, \n",
      "compound: -0.993, \n",
      "neg: 0.204, \n",
      "neu: 0.731, \n",
      "pos: 0.065, \n",
      "compound: -0.9747, \n",
      "neg: 0.198, \n",
      "neu: 0.673, \n",
      "pos: 0.129, \n",
      "compound: -0.9744, \n",
      "neg: 0.196, \n",
      "neu: 0.717, \n",
      "pos: 0.087, \n",
      "compound: -0.9859, \n",
      "neg: 0.253, \n",
      "neu: 0.62, \n",
      "pos: 0.127, \n",
      "compound: -0.9989, \n",
      "neg: 0.391, \n",
      "neu: 0.501, \n",
      "pos: 0.109, \n",
      "compound: -0.9954, \n",
      "neg: 0.276, \n",
      "neu: 0.661, \n",
      "pos: 0.063, \n",
      "compound: -0.9964, \n",
      "neg: 0.244, \n",
      "neu: 0.663, \n",
      "pos: 0.094, \n",
      "compound: -0.9903, \n",
      "neg: 0.241, \n",
      "neu: 0.631, \n",
      "pos: 0.128, \n",
      "compound: -0.9939, \n",
      "neg: 0.263, \n",
      "neu: 0.627, \n",
      "pos: 0.11, \n",
      "compound: -0.9953, \n",
      "neg: 0.286, \n",
      "neu: 0.646, \n",
      "pos: 0.068, \n",
      "compound: -0.9985, \n",
      "neg: 0.311, \n",
      "neu: 0.6, \n",
      "pos: 0.089, \n",
      "compound: -0.9957, \n",
      "neg: 0.276, \n",
      "neu: 0.618, \n",
      "pos: 0.106, \n",
      "compound: -0.9969, \n",
      "neg: 0.318, \n",
      "neu: 0.609, \n",
      "pos: 0.073, \n",
      "compound: -0.9939, \n",
      "neg: 0.246, \n",
      "neu: 0.686, \n",
      "pos: 0.068, \n",
      "compound: -0.9803, \n",
      "neg: 0.181, \n",
      "neu: 0.713, \n",
      "pos: 0.106, \n",
      "compound: -0.9861, \n",
      "neg: 0.239, \n",
      "neu: 0.625, \n",
      "pos: 0.137, \n",
      "compound: -0.9678, \n",
      "neg: 0.201, \n",
      "neu: 0.677, \n",
      "pos: 0.122, \n",
      "compound: -0.9612, \n",
      "neg: 0.187, \n",
      "neu: 0.708, \n",
      "pos: 0.105, \n",
      "compound: -0.9868, \n",
      "neg: 0.226, \n",
      "neu: 0.681, \n",
      "pos: 0.093, \n",
      "compound: -0.9888, \n",
      "neg: 0.231, \n",
      "neu: 0.651, \n",
      "pos: 0.118, \n",
      "compound: -0.9937, \n",
      "neg: 0.249, \n",
      "neu: 0.645, \n",
      "pos: 0.106, \n",
      "compound: -0.9831, \n",
      "neg: 0.216, \n",
      "neu: 0.658, \n",
      "pos: 0.125, \n",
      "compound: -0.9907, \n",
      "neg: 0.226, \n",
      "neu: 0.711, \n",
      "pos: 0.063, \n",
      "compound: -0.9972, \n",
      "neg: 0.292, \n",
      "neu: 0.625, \n",
      "pos: 0.083, \n",
      "compound: -0.9883, \n",
      "neg: 0.235, \n",
      "neu: 0.648, \n",
      "pos: 0.117, \n",
      "compound: -0.986, \n",
      "neg: 0.226, \n",
      "neu: 0.679, \n",
      "pos: 0.095, \n",
      "compound: -0.9853, \n",
      "neg: 0.216, \n",
      "neu: 0.627, \n",
      "pos: 0.157, \n",
      "compound: -0.9884, \n",
      "neg: 0.232, \n",
      "neu: 0.648, \n",
      "pos: 0.121, \n",
      "compound: -0.9607, \n",
      "neg: 0.184, \n",
      "neu: 0.681, \n",
      "pos: 0.135, \n",
      "compound: -0.9922, \n",
      "neg: 0.274, \n",
      "neu: 0.619, \n",
      "pos: 0.107, \n",
      "compound: -0.9756, \n",
      "neg: 0.193, \n",
      "neu: 0.699, \n",
      "pos: 0.108, \n",
      "compound: -0.9887, \n",
      "neg: 0.229, \n",
      "neu: 0.685, \n",
      "pos: 0.085, \n",
      "compound: -0.9856, \n",
      "neg: 0.224, \n",
      "neu: 0.656, \n",
      "pos: 0.12, \n",
      "compound: -0.9963, \n",
      "neg: 0.272, \n",
      "neu: 0.645, \n",
      "pos: 0.083, \n",
      "compound: -0.9909, \n",
      "neg: 0.202, \n",
      "neu: 0.719, \n",
      "pos: 0.079, \n",
      "compound: -0.9874, \n",
      "neg: 0.208, \n",
      "neu: 0.707, \n",
      "pos: 0.085, \n",
      "compound: -0.9956, \n",
      "neg: 0.273, \n",
      "neu: 0.608, \n",
      "pos: 0.119, \n",
      "compound: -0.9946, \n",
      "neg: 0.244, \n",
      "neu: 0.697, \n",
      "pos: 0.059, \n",
      "compound: -0.9959, \n",
      "neg: 0.247, \n",
      "neu: 0.67, \n",
      "pos: 0.083, \n",
      "compound: -0.9849, \n",
      "neg: 0.21, \n",
      "neu: 0.672, \n",
      "pos: 0.118, \n",
      "compound: -0.9442, \n",
      "neg: 0.189, \n",
      "neu: 0.665, \n",
      "pos: 0.147, \n",
      "compound: -0.9919, \n",
      "neg: 0.224, \n",
      "neu: 0.746, \n",
      "pos: 0.03, \n",
      "compound: -0.9917, \n",
      "neg: 0.219, \n",
      "neu: 0.741, \n",
      "pos: 0.041, \n",
      "compound: -0.9935, \n",
      "neg: 0.237, \n",
      "neu: 0.684, \n",
      "pos: 0.079, \n",
      "compound: -0.9899, \n",
      "neg: 0.185, \n",
      "neu: 0.731, \n",
      "pos: 0.084, \n",
      "compound: -0.9926, \n",
      "neg: 0.245, \n",
      "neu: 0.685, \n",
      "pos: 0.069, \n",
      "compound: -0.9918, \n",
      "neg: 0.218, \n",
      "neu: 0.762, \n",
      "pos: 0.021, \n",
      "compound: -0.997, \n",
      "neg: 0.289, \n",
      "neu: 0.625, \n",
      "pos: 0.086, \n",
      "compound: -0.9935, \n",
      "neg: 0.268, \n",
      "neu: 0.587, \n",
      "pos: 0.145, \n",
      "compound: -0.9948, \n",
      "neg: 0.287, \n",
      "neu: 0.595, \n",
      "pos: 0.118, \n",
      "compound: -0.9958, \n",
      "neg: 0.275, \n",
      "neu: 0.657, \n",
      "pos: 0.067, \n",
      "compound: -0.9893, \n",
      "neg: 0.278, \n",
      "neu: 0.593, \n",
      "pos: 0.129, \n",
      "compound: -0.9984, \n",
      "neg: 0.356, \n",
      "neu: 0.574, \n",
      "pos: 0.07, \n",
      "compound: -0.991, \n",
      "neg: 0.211, \n",
      "neu: 0.734, \n",
      "pos: 0.054, \n",
      "compound: -0.9837, \n",
      "neg: 0.212, \n",
      "neu: 0.678, \n",
      "pos: 0.11, \n",
      "compound: -0.9927, \n",
      "neg: 0.25, \n",
      "neu: 0.64, \n",
      "pos: 0.11, \n",
      "compound: -0.9953, \n",
      "neg: 0.288, \n",
      "neu: 0.616, \n",
      "pos: 0.096, \n",
      "compound: -0.9872, \n",
      "neg: 0.255, \n",
      "neu: 0.608, \n",
      "pos: 0.137, \n",
      "compound: -0.9966, \n",
      "neg: 0.288, \n",
      "neu: 0.657, \n",
      "pos: 0.055, \n",
      "compound: -0.997, \n",
      "neg: 0.27, \n",
      "neu: 0.663, \n",
      "pos: 0.067, \n",
      "compound: -0.9953, \n",
      "neg: 0.279, \n",
      "neu: 0.632, \n",
      "pos: 0.089, \n",
      "compound: -0.9923, \n",
      "neg: 0.266, \n",
      "neu: 0.598, \n",
      "pos: 0.136, \n",
      "compound: -0.9899, \n",
      "neg: 0.243, \n",
      "neu: 0.678, \n",
      "pos: 0.079, \n",
      "compound: -0.995, \n",
      "neg: 0.268, \n",
      "neu: 0.677, \n",
      "pos: 0.055, \n",
      "compound: -0.9969, \n",
      "neg: 0.304, \n",
      "neu: 0.585, \n",
      "pos: 0.111, \n",
      "compound: -0.926, \n",
      "neg: 0.166, \n",
      "neu: 0.713, \n",
      "pos: 0.121, \n",
      "compound: -0.997, \n",
      "neg: 0.268, \n",
      "neu: 0.65, \n",
      "pos: 0.083, \n",
      "compound: -0.9933, \n",
      "neg: 0.292, \n",
      "neu: 0.629, \n",
      "pos: 0.079, \n",
      "compound: -0.8934, \n",
      "neg: 0.176, \n",
      "neu: 0.677, \n",
      "pos: 0.147, \n",
      "compound: -0.9967, \n",
      "neg: 0.264, \n",
      "neu: 0.642, \n",
      "pos: 0.094, \n",
      "compound: -0.9948, \n",
      "neg: 0.295, \n",
      "neu: 0.624, \n",
      "pos: 0.081, \n",
      "compound: -0.9977, \n",
      "neg: 0.294, \n",
      "neu: 0.633, \n",
      "pos: 0.074, \n",
      "compound: -0.9887, \n",
      "neg: 0.213, \n",
      "neu: 0.703, \n",
      "pos: 0.084, \n",
      "compound: -0.996, \n",
      "neg: 0.276, \n",
      "neu: 0.652, \n",
      "pos: 0.072, \n",
      "compound: -0.9965, \n",
      "neg: 0.263, \n",
      "neu: 0.666, \n",
      "pos: 0.071, \n",
      "compound: -0.9843, \n",
      "neg: 0.214, \n",
      "neu: 0.674, \n",
      "pos: 0.112, \n",
      "compound: -0.6527, \n",
      "neg: 0.173, \n",
      "neu: 0.667, \n",
      "pos: 0.16, \n",
      "compound: -0.9753, \n",
      "neg: 0.177, \n",
      "neu: 0.72, \n",
      "pos: 0.102, \n",
      "compound: -0.9565, \n",
      "neg: 0.17, \n",
      "neu: 0.714, \n",
      "pos: 0.116, \n",
      "compound: -0.9981, \n",
      "neg: 0.32, \n",
      "neu: 0.603, \n",
      "pos: 0.077, \n",
      "compound: -0.9962, \n",
      "neg: 0.249, \n",
      "neu: 0.689, \n",
      "pos: 0.062, \n",
      "compound: -0.9935, \n",
      "neg: 0.262, \n",
      "neu: 0.646, \n",
      "pos: 0.092, \n",
      "compound: -0.9886, \n",
      "neg: 0.228, \n",
      "neu: 0.645, \n",
      "pos: 0.128, \n",
      "compound: -0.9974, \n",
      "neg: 0.323, \n",
      "neu: 0.607, \n",
      "pos: 0.07, \n",
      "compound: -0.9819, \n",
      "neg: 0.201, \n",
      "neu: 0.686, \n",
      "pos: 0.113, \n",
      "compound: -0.9493, \n",
      "neg: 0.194, \n",
      "neu: 0.659, \n",
      "pos: 0.147, \n",
      "compound: -0.9788, \n",
      "neg: 0.212, \n",
      "neu: 0.642, \n",
      "pos: 0.146, \n",
      "compound: 0.9496, \n",
      "neg: 0.142, \n",
      "neu: 0.655, \n",
      "pos: 0.203, \n",
      "compound: -0.9966, \n",
      "neg: 0.296, \n",
      "neu: 0.646, \n",
      "pos: 0.058, \n",
      "compound: -0.9922, \n",
      "neg: 0.241, \n",
      "neu: 0.632, \n",
      "pos: 0.127, \n",
      "compound: -0.9942, \n",
      "neg: 0.289, \n",
      "neu: 0.621, \n",
      "pos: 0.089, \n",
      "compound: -0.9633, \n",
      "neg: 0.204, \n",
      "neu: 0.648, \n",
      "pos: 0.149, \n",
      "compound: -0.9961, \n",
      "neg: 0.271, \n",
      "neu: 0.67, \n",
      "pos: 0.059, \n",
      "compound: -0.9922, \n",
      "neg: 0.271, \n",
      "neu: 0.615, \n",
      "pos: 0.114, \n",
      "compound: -0.8807, \n",
      "neg: 0.175, \n",
      "neu: 0.677, \n",
      "pos: 0.147, \n",
      "compound: -0.9708, \n",
      "neg: 0.201, \n",
      "neu: 0.648, \n",
      "pos: 0.151, \n",
      "compound: -0.989, \n",
      "neg: 0.228, \n",
      "neu: 0.649, \n",
      "pos: 0.124, \n",
      "compound: -0.991, \n",
      "neg: 0.254, \n",
      "neu: 0.62, \n",
      "pos: 0.126, \n",
      "compound: -0.9794, \n",
      "neg: 0.195, \n",
      "neu: 0.715, \n",
      "pos: 0.09, \n",
      "compound: -0.9959, \n",
      "neg: 0.288, \n",
      "neu: 0.613, \n",
      "pos: 0.099, \n",
      "compound: -0.992, \n",
      "neg: 0.238, \n",
      "neu: 0.645, \n",
      "pos: 0.117, \n",
      "compound: -0.9986, \n",
      "neg: 0.356, \n",
      "neu: 0.57, \n",
      "pos: 0.073, \n",
      "compound: -0.9886, \n",
      "neg: 0.219, \n",
      "neu: 0.697, \n",
      "pos: 0.084, \n",
      "compound: -0.9935, \n",
      "neg: 0.246, \n",
      "neu: 0.632, \n",
      "pos: 0.122, \n",
      "compound: -0.9957, \n",
      "neg: 0.232, \n",
      "neu: 0.713, \n",
      "pos: 0.056, \n",
      "compound: -0.9979, \n",
      "neg: 0.292, \n",
      "neu: 0.643, \n",
      "pos: 0.064, \n",
      "compound: -0.9963, \n",
      "neg: 0.291, \n",
      "neu: 0.645, \n",
      "pos: 0.064, \n",
      "compound: -0.995, \n",
      "neg: 0.247, \n",
      "neu: 0.663, \n",
      "pos: 0.09, \n",
      "compound: -0.9559, \n",
      "neg: 0.17, \n",
      "neu: 0.717, \n",
      "pos: 0.114, \n",
      "compound: -0.9062, \n",
      "neg: 0.173, \n",
      "neu: 0.674, \n",
      "pos: 0.153, \n",
      "compound: -0.9911, \n",
      "neg: 0.255, \n",
      "neu: 0.625, \n",
      "pos: 0.12, \n",
      "compound: -0.9932, \n",
      "neg: 0.246, \n",
      "neu: 0.672, \n",
      "pos: 0.082, \n",
      "compound: -0.9812, \n",
      "neg: 0.238, \n",
      "neu: 0.602, \n",
      "pos: 0.16, \n",
      "compound: -0.9783, \n",
      "neg: 0.176, \n",
      "neu: 0.723, \n",
      "pos: 0.101, \n",
      "compound: -0.9888, \n",
      "neg: 0.306, \n",
      "neu: 0.539, \n",
      "pos: 0.156, \n",
      "compound: -0.9955, \n",
      "neg: 0.27, \n",
      "neu: 0.65, \n",
      "pos: 0.079, \n",
      "compound: -0.8813, \n",
      "neg: 0.136, \n",
      "neu: 0.766, \n",
      "pos: 0.098, \n",
      "compound: -0.9744, \n",
      "neg: 0.218, \n",
      "neu: 0.644, \n",
      "pos: 0.138, \n",
      "compound: -0.9744, \n",
      "neg: 0.207, \n",
      "neu: 0.683, \n",
      "pos: 0.11, \n",
      "compound: -0.9834, \n",
      "neg: 0.224, \n",
      "neu: 0.636, \n",
      "pos: 0.14, \n",
      "compound: -0.9623, \n",
      "neg: 0.223, \n",
      "neu: 0.626, \n",
      "pos: 0.15, \n",
      "compound: -0.9972, \n",
      "neg: 0.299, \n",
      "neu: 0.603, \n",
      "pos: 0.098, \n",
      "compound: -0.9955, \n",
      "neg: 0.264, \n",
      "neu: 0.645, \n",
      "pos: 0.092, \n",
      "compound: -0.995, \n",
      "neg: 0.271, \n",
      "neu: 0.625, \n",
      "pos: 0.104, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.9921, \n",
      "neg: 0.203, \n",
      "neu: 0.705, \n",
      "pos: 0.091, \n",
      "compound: -0.9948, \n",
      "neg: 0.258, \n",
      "neu: 0.609, \n",
      "pos: 0.133, \n",
      "compound: -0.9947, \n",
      "neg: 0.23, \n",
      "neu: 0.662, \n",
      "pos: 0.107, \n",
      "compound: -0.9883, \n",
      "neg: 0.193, \n",
      "neu: 0.72, \n",
      "pos: 0.087, \n",
      "compound: -0.9735, \n",
      "neg: 0.185, \n",
      "neu: 0.717, \n",
      "pos: 0.098, \n",
      "compound: -0.9972, \n",
      "neg: 0.254, \n",
      "neu: 0.67, \n",
      "pos: 0.076, \n",
      "compound: -0.9702, \n",
      "neg: 0.195, \n",
      "neu: 0.698, \n",
      "pos: 0.107, \n",
      "compound: -0.994, \n",
      "neg: 0.241, \n",
      "neu: 0.67, \n",
      "pos: 0.089, \n",
      "compound: -0.9666, \n",
      "neg: 0.211, \n",
      "neu: 0.641, \n",
      "pos: 0.148, \n",
      "compound: -0.9969, \n",
      "neg: 0.266, \n",
      "neu: 0.676, \n",
      "pos: 0.058, \n",
      "compound: -0.9964, \n",
      "neg: 0.291, \n",
      "neu: 0.644, \n",
      "pos: 0.065, \n",
      "compound: -0.9815, \n",
      "neg: 0.214, \n",
      "neu: 0.624, \n",
      "pos: 0.162, \n",
      "compound: -0.9169, \n",
      "neg: 0.156, \n",
      "neu: 0.724, \n",
      "pos: 0.12, \n",
      "compound: -0.9915, \n",
      "neg: 0.204, \n",
      "neu: 0.73, \n",
      "pos: 0.066, \n",
      "compound: -0.9972, \n",
      "neg: 0.313, \n",
      "neu: 0.579, \n",
      "pos: 0.108, \n",
      "compound: -0.9882, \n",
      "neg: 0.272, \n",
      "neu: 0.588, \n",
      "pos: 0.141, \n",
      "compound: -0.9956, \n",
      "neg: 0.289, \n",
      "neu: 0.554, \n",
      "pos: 0.158, \n",
      "compound: -0.9898, \n",
      "neg: 0.226, \n",
      "neu: 0.639, \n",
      "pos: 0.135, \n",
      "compound: -0.9844, \n",
      "neg: 0.205, \n",
      "neu: 0.688, \n",
      "pos: 0.107, \n",
      "compound: -0.9955, \n",
      "neg: 0.254, \n",
      "neu: 0.647, \n",
      "pos: 0.099, \n",
      "compound: -0.984, \n",
      "neg: 0.198, \n",
      "neu: 0.713, \n",
      "pos: 0.089, \n",
      "compound: -0.9841, \n",
      "neg: 0.215, \n",
      "neu: 0.648, \n",
      "pos: 0.136, \n",
      "compound: -0.9822, \n",
      "neg: 0.183, \n",
      "neu: 0.74, \n",
      "pos: 0.077, \n",
      "compound: -0.9967, \n",
      "neg: 0.275, \n",
      "neu: 0.669, \n",
      "pos: 0.056, \n",
      "compound: -0.9928, \n",
      "neg: 0.207, \n",
      "neu: 0.716, \n",
      "pos: 0.077, \n",
      "compound: -0.9937, \n",
      "neg: 0.258, \n",
      "neu: 0.644, \n",
      "pos: 0.099, \n",
      "compound: -0.9964, \n",
      "neg: 0.321, \n",
      "neu: 0.614, \n",
      "pos: 0.065, \n",
      "compound: -0.9371, \n",
      "neg: 0.157, \n",
      "neu: 0.737, \n",
      "pos: 0.106, \n",
      "compound: -0.9953, \n",
      "neg: 0.268, \n",
      "neu: 0.655, \n",
      "pos: 0.078, \n",
      "compound: -0.997, \n",
      "neg: 0.273, \n",
      "neu: 0.617, \n",
      "pos: 0.11, \n",
      "compound: -0.9956, \n",
      "neg: 0.262, \n",
      "neu: 0.659, \n",
      "pos: 0.078, \n",
      "compound: -0.9933, \n",
      "neg: 0.27, \n",
      "neu: 0.635, \n",
      "pos: 0.095, \n",
      "compound: -0.9961, \n",
      "neg: 0.304, \n",
      "neu: 0.585, \n",
      "pos: 0.111, \n",
      "compound: -0.9859, \n",
      "neg: 0.188, \n",
      "neu: 0.713, \n",
      "pos: 0.098, \n",
      "compound: -0.9925, \n",
      "neg: 0.275, \n",
      "neu: 0.604, \n",
      "pos: 0.121, \n",
      "compound: -0.9623, \n",
      "neg: 0.166, \n",
      "neu: 0.726, \n",
      "pos: 0.108, \n",
      "compound: -0.9864, \n",
      "neg: 0.193, \n",
      "neu: 0.702, \n",
      "pos: 0.105, \n",
      "compound: -0.9973, \n",
      "neg: 0.269, \n",
      "neu: 0.628, \n",
      "pos: 0.102, \n",
      "compound: -0.9971, \n",
      "neg: 0.351, \n",
      "neu: 0.583, \n",
      "pos: 0.066, \n",
      "compound: -0.9712, \n",
      "neg: 0.154, \n",
      "neu: 0.758, \n",
      "pos: 0.089, \n",
      "compound: -0.9917, \n",
      "neg: 0.227, \n",
      "neu: 0.67, \n",
      "pos: 0.103, \n",
      "compound: -0.9982, \n",
      "neg: 0.345, \n",
      "neu: 0.594, \n",
      "pos: 0.061, \n",
      "compound: -0.9955, \n",
      "neg: 0.247, \n",
      "neu: 0.685, \n",
      "pos: 0.068, \n",
      "compound: -0.9966, \n",
      "neg: 0.291, \n",
      "neu: 0.625, \n",
      "pos: 0.084, \n",
      "compound: -0.9797, \n",
      "neg: 0.184, \n",
      "neu: 0.698, \n",
      "pos: 0.118, \n",
      "compound: -0.9931, \n",
      "neg: 0.223, \n",
      "neu: 0.675, \n",
      "pos: 0.101, \n",
      "compound: -0.9943, \n",
      "neg: 0.23, \n",
      "neu: 0.687, \n",
      "pos: 0.083, \n",
      "compound: -0.9955, \n",
      "neg: 0.288, \n",
      "neu: 0.645, \n",
      "pos: 0.067, \n",
      "compound: -0.9974, \n",
      "neg: 0.305, \n",
      "neu: 0.585, \n",
      "pos: 0.111, \n",
      "compound: -0.9945, \n",
      "neg: 0.259, \n",
      "neu: 0.683, \n",
      "pos: 0.058, \n",
      "compound: -0.985, \n",
      "neg: 0.245, \n",
      "neu: 0.604, \n",
      "pos: 0.151, \n",
      "compound: -0.9951, \n",
      "neg: 0.26, \n",
      "neu: 0.649, \n",
      "pos: 0.091, \n",
      "compound: -0.9974, \n",
      "neg: 0.325, \n",
      "neu: 0.611, \n",
      "pos: 0.064, \n",
      "compound: -0.9921, \n",
      "neg: 0.244, \n",
      "neu: 0.685, \n",
      "pos: 0.07, \n",
      "compound: -0.994, \n",
      "neg: 0.271, \n",
      "neu: 0.635, \n",
      "pos: 0.094, \n",
      "compound: -0.9872, \n",
      "neg: 0.254, \n",
      "neu: 0.6, \n",
      "pos: 0.146, \n",
      "compound: -0.9871, \n",
      "neg: 0.203, \n",
      "neu: 0.7, \n",
      "pos: 0.097, \n",
      "compound: -0.996, \n",
      "neg: 0.296, \n",
      "neu: 0.567, \n",
      "pos: 0.137, \n",
      "compound: -0.9967, \n",
      "neg: 0.254, \n",
      "neu: 0.696, \n",
      "pos: 0.05, \n",
      "compound: -0.9956, \n",
      "neg: 0.268, \n",
      "neu: 0.651, \n",
      "pos: 0.081, \n",
      "compound: -0.9814, \n",
      "neg: 0.172, \n",
      "neu: 0.748, \n",
      "pos: 0.08, \n",
      "compound: -0.9954, \n",
      "neg: 0.246, \n",
      "neu: 0.704, \n",
      "pos: 0.05, \n",
      "compound: -0.9947, \n",
      "neg: 0.275, \n",
      "neu: 0.622, \n",
      "pos: 0.103, \n",
      "compound: -0.9955, \n",
      "neg: 0.252, \n",
      "neu: 0.694, \n",
      "pos: 0.054, \n",
      "compound: -0.969, \n",
      "neg: 0.181, \n",
      "neu: 0.699, \n",
      "pos: 0.12, \n",
      "compound: -0.9973, \n",
      "neg: 0.347, \n",
      "neu: 0.577, \n",
      "pos: 0.076, \n",
      "compound: -0.9928, \n",
      "neg: 0.255, \n",
      "neu: 0.602, \n",
      "pos: 0.143, \n",
      "compound: -0.9967, \n",
      "neg: 0.265, \n",
      "neu: 0.683, \n",
      "pos: 0.052, \n",
      "compound: -0.9949, \n",
      "neg: 0.277, \n",
      "neu: 0.601, \n",
      "pos: 0.122, \n",
      "compound: -0.9963, \n",
      "neg: 0.348, \n",
      "neu: 0.56, \n",
      "pos: 0.092, \n",
      "compound: -0.9874, \n",
      "neg: 0.239, \n",
      "neu: 0.651, \n",
      "pos: 0.11, \n",
      "compound: -0.9962, \n",
      "neg: 0.294, \n",
      "neu: 0.609, \n",
      "pos: 0.097, \n",
      "compound: -0.9932, \n",
      "neg: 0.255, \n",
      "neu: 0.628, \n",
      "pos: 0.116, \n",
      "compound: -0.9814, \n",
      "neg: 0.223, \n",
      "neu: 0.679, \n",
      "pos: 0.099, \n",
      "compound: -0.9847, \n",
      "neg: 0.209, \n",
      "neu: 0.67, \n",
      "pos: 0.121, \n",
      "compound: -0.9964, \n",
      "neg: 0.264, \n",
      "neu: 0.649, \n",
      "pos: 0.087, \n",
      "compound: -0.9934, \n",
      "neg: 0.261, \n",
      "neu: 0.617, \n",
      "pos: 0.122, \n",
      "compound: -0.9001, \n",
      "neg: 0.179, \n",
      "neu: 0.668, \n",
      "pos: 0.153, \n",
      "compound: -0.975, \n",
      "neg: 0.206, \n",
      "neu: 0.685, \n",
      "pos: 0.109, \n",
      "compound: -0.9953, \n",
      "neg: 0.29, \n",
      "neu: 0.576, \n",
      "pos: 0.133, \n",
      "compound: -0.9968, \n",
      "neg: 0.28, \n",
      "neu: 0.659, \n",
      "pos: 0.061, \n",
      "compound: -0.9719, \n",
      "neg: 0.206, \n",
      "neu: 0.682, \n",
      "pos: 0.113, \n",
      "compound: -0.9756, \n",
      "neg: 0.201, \n",
      "neu: 0.659, \n",
      "pos: 0.14, \n",
      "compound: -0.9957, \n",
      "neg: 0.271, \n",
      "neu: 0.66, \n",
      "pos: 0.069, \n",
      "compound: -0.9934, \n",
      "neg: 0.265, \n",
      "neu: 0.617, \n",
      "pos: 0.118, \n",
      "compound: -0.9777, \n",
      "neg: 0.182, \n",
      "neu: 0.69, \n",
      "pos: 0.127, \n",
      "compound: -0.9946, \n",
      "neg: 0.205, \n",
      "neu: 0.697, \n",
      "pos: 0.098, \n",
      "compound: -0.9905, \n",
      "neg: 0.24, \n",
      "neu: 0.642, \n",
      "pos: 0.117, \n",
      "compound: -0.9819, \n",
      "neg: 0.213, \n",
      "neu: 0.653, \n",
      "pos: 0.134, \n",
      "compound: -0.9931, \n",
      "neg: 0.255, \n",
      "neu: 0.655, \n",
      "pos: 0.09, \n",
      "compound: -0.9974, \n",
      "neg: 0.312, \n",
      "neu: 0.637, \n",
      "pos: 0.051, \n",
      "compound: -0.9799, \n",
      "neg: 0.23, \n",
      "neu: 0.634, \n",
      "pos: 0.135, \n",
      "compound: -0.7184, \n",
      "neg: 0.133, \n",
      "neu: 0.741, \n",
      "pos: 0.126, \n",
      "compound: -0.9943, \n",
      "neg: 0.244, \n",
      "neu: 0.674, \n",
      "pos: 0.082, \n",
      "compound: -0.9578, \n",
      "neg: 0.172, \n",
      "neu: 0.724, \n",
      "pos: 0.104, \n",
      "compound: -0.9951, \n",
      "neg: 0.297, \n",
      "neu: 0.589, \n",
      "pos: 0.113, \n",
      "compound: -0.997, \n",
      "neg: 0.278, \n",
      "neu: 0.655, \n",
      "pos: 0.067, \n",
      "compound: -0.9825, \n",
      "neg: 0.227, \n",
      "neu: 0.653, \n",
      "pos: 0.12, \n",
      "compound: -0.978, \n",
      "neg: 0.202, \n",
      "neu: 0.689, \n",
      "pos: 0.109, \n",
      "compound: -0.9923, \n",
      "neg: 0.257, \n",
      "neu: 0.644, \n",
      "pos: 0.099, \n",
      "compound: -0.995, \n",
      "neg: 0.277, \n",
      "neu: 0.646, \n",
      "pos: 0.077, \n",
      "compound: -0.994, \n",
      "neg: 0.261, \n",
      "neu: 0.652, \n",
      "pos: 0.087, \n",
      "compound: -0.9747, \n",
      "neg: 0.187, \n",
      "neu: 0.713, \n",
      "pos: 0.1, \n",
      "compound: -0.848, \n",
      "neg: 0.192, \n",
      "neu: 0.65, \n",
      "pos: 0.158, \n",
      "compound: -0.9757, \n",
      "neg: 0.194, \n",
      "neu: 0.683, \n",
      "pos: 0.123, \n",
      "compound: -0.9957, \n",
      "neg: 0.282, \n",
      "neu: 0.64, \n",
      "pos: 0.078, \n",
      "compound: -0.9957, \n",
      "neg: 0.264, \n",
      "neu: 0.597, \n",
      "pos: 0.139, \n",
      "compound: -0.9843, \n",
      "neg: 0.18, \n",
      "neu: 0.735, \n",
      "pos: 0.085, \n",
      "compound: -0.9922, \n",
      "neg: 0.271, \n",
      "neu: 0.626, \n",
      "pos: 0.103, \n",
      "compound: -0.9836, \n",
      "neg: 0.21, \n",
      "neu: 0.668, \n",
      "pos: 0.123, \n",
      "compound: -0.9874, \n",
      "neg: 0.21, \n",
      "neu: 0.681, \n",
      "pos: 0.109, \n",
      "compound: -0.9855, \n",
      "neg: 0.203, \n",
      "neu: 0.707, \n",
      "pos: 0.09, \n",
      "compound: -0.9933, \n",
      "neg: 0.241, \n",
      "neu: 0.646, \n",
      "pos: 0.112, \n",
      "compound: -0.9833, \n",
      "neg: 0.226, \n",
      "neu: 0.696, \n",
      "pos: 0.078, \n",
      "compound: -0.9904, \n",
      "neg: 0.222, \n",
      "neu: 0.654, \n",
      "pos: 0.124, \n",
      "compound: -0.9951, \n",
      "neg: 0.276, \n",
      "neu: 0.627, \n",
      "pos: 0.097, \n",
      "compound: -0.9932, \n",
      "neg: 0.223, \n",
      "neu: 0.693, \n",
      "pos: 0.083, \n",
      "compound: -0.9879, \n",
      "neg: 0.198, \n",
      "neu: 0.703, \n",
      "pos: 0.099, \n",
      "compound: -0.9766, \n",
      "neg: 0.216, \n",
      "neu: 0.635, \n",
      "pos: 0.15, \n",
      "compound: -0.9929, \n",
      "neg: 0.227, \n",
      "neu: 0.675, \n",
      "pos: 0.098, \n",
      "compound: -0.9946, \n",
      "neg: 0.239, \n",
      "neu: 0.674, \n",
      "pos: 0.088, \n",
      "compound: -0.9844, \n",
      "neg: 0.225, \n",
      "neu: 0.636, \n",
      "pos: 0.139, \n",
      "compound: -0.9905, \n",
      "neg: 0.258, \n",
      "neu: 0.621, \n",
      "pos: 0.122, \n",
      "compound: -0.6003, \n",
      "neg: 0.147, \n",
      "neu: 0.717, \n",
      "pos: 0.136, \n",
      "compound: -0.9982, \n",
      "neg: 0.272, \n",
      "neu: 0.661, \n",
      "pos: 0.067, \n",
      "compound: -0.9493, \n",
      "neg: 0.192, \n",
      "neu: 0.661, \n",
      "pos: 0.147, \n",
      "compound: -0.9925, \n",
      "neg: 0.256, \n",
      "neu: 0.601, \n",
      "pos: 0.144, \n",
      "compound: -0.9964, \n",
      "neg: 0.254, \n",
      "neu: 0.687, \n",
      "pos: 0.059, \n",
      "compound: -0.9983, \n",
      "neg: 0.299, \n",
      "neu: 0.648, \n",
      "pos: 0.054, \n",
      "compound: -0.9941, \n",
      "neg: 0.244, \n",
      "neu: 0.68, \n",
      "pos: 0.076, \n",
      "compound: -0.9892, \n",
      "neg: 0.205, \n",
      "neu: 0.696, \n",
      "pos: 0.099, \n",
      "compound: -0.9971, \n",
      "neg: 0.274, \n",
      "neu: 0.651, \n",
      "pos: 0.075, \n",
      "compound: -0.9941, \n",
      "neg: 0.234, \n",
      "neu: 0.699, \n",
      "pos: 0.067, \n",
      "compound: -0.9968, \n",
      "neg: 0.272, \n",
      "neu: 0.651, \n",
      "pos: 0.076, \n",
      "compound: -0.993, \n",
      "neg: 0.272, \n",
      "neu: 0.583, \n",
      "pos: 0.145, \n",
      "compound: -0.988, \n",
      "neg: 0.247, \n",
      "neu: 0.645, \n",
      "pos: 0.108, \n",
      "compound: -0.9924, \n",
      "neg: 0.219, \n",
      "neu: 0.718, \n",
      "pos: 0.063, \n",
      "compound: -0.9912, \n",
      "neg: 0.263, \n",
      "neu: 0.626, \n",
      "pos: 0.111, \n",
      "compound: -0.9944, \n",
      "neg: 0.309, \n",
      "neu: 0.614, \n",
      "pos: 0.077, \n",
      "compound: -0.9979, \n",
      "neg: 0.335, \n",
      "neu: 0.575, \n",
      "pos: 0.091, \n",
      "compound: -0.9948, \n",
      "neg: 0.256, \n",
      "neu: 0.663, \n",
      "pos: 0.081, \n",
      "compound: -0.9633, \n",
      "neg: 0.224, \n",
      "neu: 0.634, \n",
      "pos: 0.141, \n",
      "compound: -0.9953, \n",
      "neg: 0.252, \n",
      "neu: 0.661, \n",
      "pos: 0.087, \n",
      "compound: -0.9948, \n",
      "neg: 0.224, \n",
      "neu: 0.736, \n",
      "pos: 0.04, \n",
      "compound: -0.9918, \n",
      "neg: 0.223, \n",
      "neu: 0.715, \n",
      "pos: 0.062, \n",
      "compound: -0.9674, \n",
      "neg: 0.186, \n",
      "neu: 0.687, \n",
      "pos: 0.127, \n",
      "compound: -0.9831, \n",
      "neg: 0.193, \n",
      "neu: 0.758, \n",
      "pos: 0.049, \n",
      "compound: -0.9874, \n",
      "neg: 0.213, \n",
      "neu: 0.691, \n",
      "pos: 0.096, \n",
      "compound: -0.9576, \n",
      "neg: 0.189, \n",
      "neu: 0.694, \n",
      "pos: 0.117, \n",
      "compound: -0.9801, \n",
      "neg: 0.154, \n",
      "neu: 0.784, \n",
      "pos: 0.061, \n",
      "compound: -0.986, \n",
      "neg: 0.196, \n",
      "neu: 0.712, \n",
      "pos: 0.091, \n",
      "compound: -0.9914, \n",
      "neg: 0.239, \n",
      "neu: 0.661, \n",
      "pos: 0.1, \n",
      "compound: -0.9881, \n",
      "neg: 0.198, \n",
      "neu: 0.694, \n",
      "pos: 0.108, \n",
      "compound: -0.9968, \n",
      "neg: 0.284, \n",
      "neu: 0.603, \n",
      "pos: 0.113, \n",
      "compound: -0.9914, \n",
      "neg: 0.231, \n",
      "neu: 0.659, \n",
      "pos: 0.11, \n",
      "compound: -0.9686, \n",
      "neg: 0.186, \n",
      "neu: 0.677, \n",
      "pos: 0.137, \n",
      "compound: -0.9986, \n",
      "neg: 0.319, \n",
      "neu: 0.616, \n",
      "pos: 0.065, \n",
      "compound: -0.9967, \n",
      "neg: 0.259, \n",
      "neu: 0.66, \n",
      "pos: 0.081, \n",
      "compound: -0.9904, \n",
      "neg: 0.204, \n",
      "neu: 0.745, \n",
      "pos: 0.051, \n",
      "compound: -0.9801, \n",
      "neg: 0.173, \n",
      "neu: 0.734, \n",
      "pos: 0.092, \n",
      "compound: -0.9682, \n",
      "neg: 0.215, \n",
      "neu: 0.632, \n",
      "pos: 0.153, \n",
      "compound: -0.9956, \n",
      "neg: 0.285, \n",
      "neu: 0.639, \n",
      "pos: 0.076, \n",
      "compound: -0.9866, \n",
      "neg: 0.225, \n",
      "neu: 0.654, \n",
      "pos: 0.121, \n",
      "compound: -0.9951, \n",
      "neg: 0.252, \n",
      "neu: 0.665, \n",
      "pos: 0.083, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.9879, \n",
      "neg: 0.208, \n",
      "neu: 0.672, \n",
      "pos: 0.12, \n",
      "compound: -0.9509, \n",
      "neg: 0.192, \n",
      "neu: 0.678, \n",
      "pos: 0.13, \n",
      "compound: -0.9941, \n",
      "neg: 0.265, \n",
      "neu: 0.632, \n",
      "pos: 0.103, \n",
      "compound: -0.9855, \n",
      "neg: 0.228, \n",
      "neu: 0.68, \n",
      "pos: 0.092, \n",
      "compound: -0.9937, \n",
      "neg: 0.26, \n",
      "neu: 0.626, \n",
      "pos: 0.114, \n",
      "compound: -0.9939, \n",
      "neg: 0.231, \n",
      "neu: 0.679, \n",
      "pos: 0.089, \n",
      "compound: -0.9958, \n",
      "neg: 0.274, \n",
      "neu: 0.642, \n",
      "pos: 0.084, \n",
      "compound: -0.9917, \n",
      "neg: 0.233, \n",
      "neu: 0.663, \n",
      "pos: 0.104, \n",
      "compound: -0.9924, \n",
      "neg: 0.23, \n",
      "neu: 0.661, \n",
      "pos: 0.109, \n",
      "compound: -0.9958, \n",
      "neg: 0.266, \n",
      "neu: 0.656, \n",
      "pos: 0.078, \n",
      "compound: -0.9935, \n",
      "neg: 0.249, \n",
      "neu: 0.641, \n",
      "pos: 0.11, \n",
      "compound: -0.9983, \n",
      "neg: 0.296, \n",
      "neu: 0.63, \n",
      "pos: 0.074, \n",
      "compound: -0.9694, \n",
      "neg: 0.172, \n",
      "neu: 0.713, \n",
      "pos: 0.115, \n",
      "compound: -0.9985, \n",
      "neg: 0.334, \n",
      "neu: 0.597, \n",
      "pos: 0.069, \n",
      "compound: -0.9948, \n",
      "neg: 0.259, \n",
      "neu: 0.615, \n",
      "pos: 0.126, \n",
      "compound: -0.9929, \n",
      "neg: 0.242, \n",
      "neu: 0.643, \n",
      "pos: 0.115, \n",
      "compound: -0.9962, \n",
      "neg: 0.299, \n",
      "neu: 0.593, \n",
      "pos: 0.108, \n",
      "compound: -0.9937, \n",
      "neg: 0.225, \n",
      "neu: 0.692, \n",
      "pos: 0.083, \n",
      "compound: -0.9599, \n",
      "neg: 0.219, \n",
      "neu: 0.618, \n",
      "pos: 0.163, \n",
      "compound: -0.9882, \n",
      "neg: 0.258, \n",
      "neu: 0.59, \n",
      "pos: 0.152, \n",
      "compound: -0.9954, \n",
      "neg: 0.262, \n",
      "neu: 0.644, \n",
      "pos: 0.094, \n",
      "compound: -0.9915, \n",
      "neg: 0.228, \n",
      "neu: 0.666, \n",
      "pos: 0.106, \n",
      "compound: -0.9856, \n",
      "neg: 0.226, \n",
      "neu: 0.65, \n",
      "pos: 0.124, \n",
      "compound: -0.9865, \n",
      "neg: 0.193, \n",
      "neu: 0.703, \n",
      "pos: 0.104, \n",
      "compound: -0.9946, \n",
      "neg: 0.218, \n",
      "neu: 0.705, \n",
      "pos: 0.077, \n",
      "compound: -0.9923, \n",
      "neg: 0.22, \n",
      "neu: 0.717, \n",
      "pos: 0.063, \n",
      "compound: -0.9968, \n",
      "neg: 0.29, \n",
      "neu: 0.664, \n",
      "pos: 0.047, \n",
      "compound: -0.987, \n",
      "neg: 0.205, \n",
      "neu: 0.701, \n",
      "pos: 0.094, \n",
      "compound: -0.9914, \n",
      "neg: 0.258, \n",
      "neu: 0.643, \n",
      "pos: 0.099, \n",
      "compound: -0.9978, \n",
      "neg: 0.337, \n",
      "neu: 0.585, \n",
      "pos: 0.078, \n",
      "compound: -0.9964, \n",
      "neg: 0.267, \n",
      "neu: 0.652, \n",
      "pos: 0.081, \n",
      "compound: -0.9961, \n",
      "neg: 0.266, \n",
      "neu: 0.637, \n",
      "pos: 0.097, \n",
      "compound: -0.9966, \n",
      "neg: 0.235, \n",
      "neu: 0.715, \n",
      "pos: 0.049, \n",
      "compound: -0.9718, \n",
      "neg: 0.165, \n",
      "neu: 0.735, \n",
      "pos: 0.099, \n",
      "compound: -0.9978, \n",
      "neg: 0.308, \n",
      "neu: 0.632, \n",
      "pos: 0.06, \n",
      "compound: -0.9958, \n",
      "neg: 0.263, \n",
      "neu: 0.669, \n",
      "pos: 0.068, \n",
      "compound: -0.9941, \n",
      "neg: 0.272, \n",
      "neu: 0.622, \n",
      "pos: 0.105, \n",
      "compound: -0.9716, \n",
      "neg: 0.163, \n",
      "neu: 0.74, \n",
      "pos: 0.097, \n",
      "compound: -0.9988, \n",
      "neg: 0.355, \n",
      "neu: 0.566, \n",
      "pos: 0.079, \n",
      "compound: -0.9866, \n",
      "neg: 0.235, \n",
      "neu: 0.631, \n",
      "pos: 0.134, \n",
      "compound: -0.979, \n",
      "neg: 0.188, \n",
      "neu: 0.716, \n",
      "pos: 0.095, \n",
      "compound: -0.9918, \n",
      "neg: 0.218, \n",
      "neu: 0.719, \n",
      "pos: 0.062, \n",
      "compound: -0.9963, \n",
      "neg: 0.3, \n",
      "neu: 0.628, \n",
      "pos: 0.072, \n",
      "compound: -0.9976, \n",
      "neg: 0.32, \n",
      "neu: 0.605, \n",
      "pos: 0.075, \n",
      "compound: -0.9883, \n",
      "neg: 0.235, \n",
      "neu: 0.635, \n",
      "pos: 0.13, \n",
      "compound: -0.9664, \n",
      "neg: 0.193, \n",
      "neu: 0.685, \n",
      "pos: 0.122, \n",
      "compound: -0.9973, \n",
      "neg: 0.327, \n",
      "neu: 0.592, \n",
      "pos: 0.081, \n",
      "compound: -0.9935, \n",
      "neg: 0.279, \n",
      "neu: 0.606, \n",
      "pos: 0.116, \n",
      "compound: -0.9595, \n",
      "neg: 0.184, \n",
      "neu: 0.735, \n",
      "pos: 0.081, \n",
      "compound: -0.996, \n",
      "neg: 0.303, \n",
      "neu: 0.625, \n",
      "pos: 0.072, \n",
      "compound: -0.9643, \n",
      "neg: 0.196, \n",
      "neu: 0.677, \n",
      "pos: 0.126, \n",
      "compound: -0.995, \n",
      "neg: 0.283, \n",
      "neu: 0.614, \n",
      "pos: 0.104, \n",
      "compound: -0.9978, \n",
      "neg: 0.282, \n",
      "neu: 0.669, \n",
      "pos: 0.049, \n",
      "compound: -0.9957, \n",
      "neg: 0.274, \n",
      "neu: 0.64, \n",
      "pos: 0.086, \n",
      "compound: -0.9959, \n",
      "neg: 0.296, \n",
      "neu: 0.584, \n",
      "pos: 0.12, \n",
      "compound: -0.8834, \n",
      "neg: 0.157, \n",
      "neu: 0.716, \n",
      "pos: 0.127, \n",
      "compound: -0.991, \n",
      "neg: 0.255, \n",
      "neu: 0.659, \n",
      "pos: 0.086, \n",
      "compound: -0.9908, \n",
      "neg: 0.238, \n",
      "neu: 0.648, \n",
      "pos: 0.114, \n",
      "compound: -0.8519, \n",
      "neg: 0.176, \n",
      "neu: 0.684, \n",
      "pos: 0.14, \n",
      "compound: -0.9945, \n",
      "neg: 0.24, \n",
      "neu: 0.658, \n",
      "pos: 0.102, \n",
      "compound: -0.9932, \n",
      "neg: 0.206, \n",
      "neu: 0.712, \n",
      "pos: 0.082, \n",
      "compound: -0.9968, \n",
      "neg: 0.29, \n",
      "neu: 0.622, \n",
      "pos: 0.089, \n",
      "compound: -0.9744, \n",
      "neg: 0.187, \n",
      "neu: 0.713, \n",
      "pos: 0.1, \n",
      "compound: -0.9971, \n",
      "neg: 0.283, \n",
      "neu: 0.609, \n",
      "pos: 0.108, \n",
      "compound: -0.9726, \n",
      "neg: 0.22, \n",
      "neu: 0.625, \n",
      "pos: 0.155, \n",
      "compound: -0.9916, \n",
      "neg: 0.233, \n",
      "neu: 0.638, \n",
      "pos: 0.128, \n",
      "compound: -0.9967, \n",
      "neg: 0.292, \n",
      "neu: 0.617, \n",
      "pos: 0.09, \n",
      "compound: -0.9968, \n",
      "neg: 0.278, \n",
      "neu: 0.665, \n",
      "pos: 0.057, \n",
      "compound: -0.8271, \n",
      "neg: 0.189, \n",
      "neu: 0.635, \n",
      "pos: 0.176, \n",
      "compound: -0.9928, \n",
      "neg: 0.238, \n",
      "neu: 0.651, \n",
      "pos: 0.111, \n",
      "compound: -0.997, \n",
      "neg: 0.249, \n",
      "neu: 0.706, \n",
      "pos: 0.045, \n",
      "compound: -0.9954, \n",
      "neg: 0.266, \n",
      "neu: 0.649, \n",
      "pos: 0.084, \n",
      "compound: -0.9949, \n",
      "neg: 0.262, \n",
      "neu: 0.647, \n",
      "pos: 0.091, \n",
      "compound: -0.9487, \n",
      "neg: 0.182, \n",
      "neu: 0.703, \n",
      "pos: 0.115, \n",
      "compound: -0.9969, \n",
      "neg: 0.262, \n",
      "neu: 0.645, \n",
      "pos: 0.093, \n",
      "compound: -0.991, \n",
      "neg: 0.252, \n",
      "neu: 0.633, \n",
      "pos: 0.115, \n",
      "compound: -0.9954, \n",
      "neg: 0.257, \n",
      "neu: 0.682, \n",
      "pos: 0.062, \n",
      "compound: -0.9959, \n",
      "neg: 0.271, \n",
      "neu: 0.659, \n",
      "pos: 0.07, \n",
      "compound: -0.9935, \n",
      "neg: 0.264, \n",
      "neu: 0.584, \n",
      "pos: 0.152, \n",
      "compound: -0.994, \n",
      "neg: 0.264, \n",
      "neu: 0.637, \n",
      "pos: 0.1, \n",
      "compound: -0.9951, \n",
      "neg: 0.241, \n",
      "neu: 0.71, \n",
      "pos: 0.048, \n",
      "compound: -0.9906, \n",
      "neg: 0.229, \n",
      "neu: 0.658, \n",
      "pos: 0.113, \n",
      "compound: -0.9891, \n",
      "neg: 0.199, \n",
      "neu: 0.71, \n",
      "pos: 0.091, \n",
      "compound: -0.9565, \n",
      "neg: 0.144, \n",
      "neu: 0.766, \n",
      "pos: 0.09, \n",
      "compound: -0.9451, \n",
      "neg: 0.156, \n",
      "neu: 0.721, \n",
      "pos: 0.123, \n",
      "compound: -0.988, \n",
      "neg: 0.192, \n",
      "neu: 0.728, \n",
      "pos: 0.079, \n",
      "compound: -0.9978, \n",
      "neg: 0.306, \n",
      "neu: 0.595, \n",
      "pos: 0.099, \n",
      "compound: -0.9935, \n",
      "neg: 0.258, \n",
      "neu: 0.608, \n",
      "pos: 0.134, \n",
      "compound: -0.9957, \n",
      "neg: 0.305, \n",
      "neu: 0.554, \n",
      "pos: 0.142, \n",
      "compound: -0.9955, \n",
      "neg: 0.238, \n",
      "neu: 0.69, \n",
      "pos: 0.072, \n",
      "compound: -0.9976, \n",
      "neg: 0.333, \n",
      "neu: 0.558, \n",
      "pos: 0.109, \n",
      "compound: -0.9953, \n",
      "neg: 0.238, \n",
      "neu: 0.642, \n",
      "pos: 0.121, \n",
      "compound: -0.9986, \n",
      "neg: 0.315, \n",
      "neu: 0.625, \n",
      "pos: 0.06, \n",
      "compound: -0.9978, \n",
      "neg: 0.347, \n",
      "neu: 0.554, \n",
      "pos: 0.1, \n",
      "compound: -0.9967, \n",
      "neg: 0.255, \n",
      "neu: 0.678, \n",
      "pos: 0.067, \n",
      "compound: -0.9973, \n",
      "neg: 0.275, \n",
      "neu: 0.674, \n",
      "pos: 0.051, \n",
      "compound: -0.9961, \n",
      "neg: 0.259, \n",
      "neu: 0.638, \n",
      "pos: 0.103, \n",
      "compound: -0.9945, \n",
      "neg: 0.263, \n",
      "neu: 0.594, \n",
      "pos: 0.144, \n",
      "compound: -0.992, \n",
      "neg: 0.234, \n",
      "neu: 0.663, \n",
      "pos: 0.103, \n",
      "compound: -0.9951, \n",
      "neg: 0.265, \n",
      "neu: 0.62, \n",
      "pos: 0.115, \n",
      "compound: -0.9818, \n",
      "neg: 0.161, \n",
      "neu: 0.763, \n",
      "pos: 0.076, \n",
      "compound: -0.99, \n",
      "neg: 0.242, \n",
      "neu: 0.656, \n",
      "pos: 0.102, \n",
      "compound: -0.9946, \n",
      "neg: 0.261, \n",
      "neu: 0.663, \n",
      "pos: 0.076, \n",
      "compound: -0.9981, \n",
      "neg: 0.329, \n",
      "neu: 0.598, \n",
      "pos: 0.073, \n",
      "compound: -0.9941, \n",
      "neg: 0.275, \n",
      "neu: 0.62, \n",
      "pos: 0.105, \n",
      "compound: -0.9931, \n",
      "neg: 0.264, \n",
      "neu: 0.655, \n",
      "pos: 0.081, \n",
      "compound: -0.9974, \n",
      "neg: 0.279, \n",
      "neu: 0.665, \n",
      "pos: 0.057, \n",
      "compound: -0.9942, \n",
      "neg: 0.266, \n",
      "neu: 0.634, \n",
      "pos: 0.1, \n",
      "compound: -0.9801, \n",
      "neg: 0.186, \n",
      "neu: 0.747, \n",
      "pos: 0.067, \n",
      "compound: -0.9951, \n",
      "neg: 0.263, \n",
      "neu: 0.656, \n",
      "pos: 0.081, \n",
      "compound: -0.9937, \n",
      "neg: 0.244, \n",
      "neu: 0.671, \n",
      "pos: 0.085, \n",
      "compound: -0.992, \n",
      "neg: 0.257, \n",
      "neu: 0.629, \n",
      "pos: 0.114, \n",
      "compound: -0.988, \n",
      "neg: 0.235, \n",
      "neu: 0.708, \n",
      "pos: 0.057, \n",
      "compound: -0.9977, \n",
      "neg: 0.302, \n",
      "neu: 0.628, \n",
      "pos: 0.07, \n",
      "compound: -0.9986, \n",
      "neg: 0.327, \n",
      "neu: 0.606, \n",
      "pos: 0.066, \n",
      "compound: -0.9917, \n",
      "neg: 0.22, \n",
      "neu: 0.679, \n",
      "pos: 0.101, \n",
      "compound: -0.9979, \n",
      "neg: 0.33, \n",
      "neu: 0.545, \n",
      "pos: 0.125, \n",
      "compound: -0.9939, \n",
      "neg: 0.222, \n",
      "neu: 0.654, \n",
      "pos: 0.125, \n",
      "compound: -0.9928, \n",
      "neg: 0.219, \n",
      "neu: 0.697, \n",
      "pos: 0.084, \n",
      "compound: -0.9985, \n",
      "neg: 0.329, \n",
      "neu: 0.609, \n",
      "pos: 0.061, \n",
      "compound: -0.9949, \n",
      "neg: 0.24, \n",
      "neu: 0.648, \n",
      "pos: 0.112, \n",
      "compound: -0.9972, \n",
      "neg: 0.298, \n",
      "neu: 0.627, \n",
      "pos: 0.075, \n",
      "compound: -0.9957, \n",
      "neg: 0.315, \n",
      "neu: 0.622, \n",
      "pos: 0.063, \n",
      "compound: -0.9961, \n",
      "neg: 0.287, \n",
      "neu: 0.604, \n",
      "pos: 0.108, \n",
      "compound: -0.9914, \n",
      "neg: 0.267, \n",
      "neu: 0.586, \n",
      "pos: 0.147, \n",
      "compound: -0.9939, \n",
      "neg: 0.25, \n",
      "neu: 0.65, \n",
      "pos: 0.1, \n",
      "compound: -0.9964, \n",
      "neg: 0.281, \n",
      "neu: 0.633, \n",
      "pos: 0.086, \n",
      "compound: -0.9967, \n",
      "neg: 0.297, \n",
      "neu: 0.591, \n",
      "pos: 0.112, \n",
      "compound: -0.9936, \n",
      "neg: 0.226, \n",
      "neu: 0.652, \n",
      "pos: 0.122, \n",
      "compound: -0.993, \n",
      "neg: 0.268, \n",
      "neu: 0.586, \n",
      "pos: 0.145, \n",
      "compound: -0.9961, \n",
      "neg: 0.257, \n",
      "neu: 0.669, \n",
      "pos: 0.074, \n",
      "compound: -0.984, \n",
      "neg: 0.23, \n",
      "neu: 0.639, \n",
      "pos: 0.131, \n",
      "compound: -0.9897, \n",
      "neg: 0.266, \n",
      "neu: 0.665, \n",
      "pos: 0.069, \n",
      "compound: -0.9903, \n",
      "neg: 0.221, \n",
      "neu: 0.672, \n",
      "pos: 0.107, \n",
      "compound: -0.9864, \n",
      "neg: 0.232, \n",
      "neu: 0.625, \n",
      "pos: 0.143, \n",
      "compound: -0.9877, \n",
      "neg: 0.225, \n",
      "neu: 0.661, \n",
      "pos: 0.114, \n",
      "compound: -0.9963, \n",
      "neg: 0.269, \n",
      "neu: 0.634, \n",
      "pos: 0.097, \n",
      "compound: -0.9888, \n",
      "neg: 0.223, \n",
      "neu: 0.662, \n",
      "pos: 0.115, \n",
      "compound: -0.9938, \n",
      "neg: 0.249, \n",
      "neu: 0.647, \n",
      "pos: 0.104, \n",
      "compound: -0.9875, \n",
      "neg: 0.21, \n",
      "neu: 0.689, \n",
      "pos: 0.101, \n",
      "compound: -0.9923, \n",
      "neg: 0.242, \n",
      "neu: 0.647, \n",
      "pos: 0.112, \n",
      "compound: -0.9891, \n",
      "neg: 0.182, \n",
      "neu: 0.731, \n",
      "pos: 0.087, \n",
      "compound: -0.9661, \n",
      "neg: 0.165, \n",
      "neu: 0.746, \n",
      "pos: 0.089, \n",
      "compound: -0.9517, \n",
      "neg: 0.162, \n",
      "neu: 0.731, \n",
      "pos: 0.107, \n",
      "compound: -0.9964, \n",
      "neg: 0.285, \n",
      "neu: 0.626, \n",
      "pos: 0.089, \n",
      "compound: -0.9904, \n",
      "neg: 0.208, \n",
      "neu: 0.698, \n",
      "pos: 0.094, \n",
      "compound: -0.9274, \n",
      "neg: 0.196, \n",
      "neu: 0.63, \n",
      "pos: 0.174, \n",
      "compound: -0.998, \n",
      "neg: 0.361, \n",
      "neu: 0.596, \n",
      "pos: 0.043, \n",
      "compound: -0.9712, \n",
      "neg: 0.165, \n",
      "neu: 0.722, \n",
      "pos: 0.112, \n",
      "compound: -0.9971, \n",
      "neg: 0.275, \n",
      "neu: 0.658, \n",
      "pos: 0.066, \n",
      "compound: -0.9871, \n",
      "neg: 0.215, \n",
      "neu: 0.692, \n",
      "pos: 0.093, \n",
      "compound: -0.997, \n",
      "neg: 0.308, \n",
      "neu: 0.648, \n",
      "pos: 0.044, \n",
      "compound: -0.9934, \n",
      "neg: 0.246, \n",
      "neu: 0.672, \n",
      "pos: 0.082, \n",
      "compound: -0.9716, \n",
      "neg: 0.225, \n",
      "neu: 0.623, \n",
      "pos: 0.152, \n",
      "compound: -0.994, \n",
      "neg: 0.255, \n",
      "neu: 0.677, \n",
      "pos: 0.067, \n",
      "compound: -0.9973, \n",
      "neg: 0.272, \n",
      "neu: 0.665, \n",
      "pos: 0.062, \n",
      "compound: -0.9929, \n",
      "neg: 0.223, \n",
      "neu: 0.706, \n",
      "pos: 0.071, \n",
      "compound: -0.987, \n",
      "neg: 0.247, \n",
      "neu: 0.595, \n",
      "pos: 0.157, \n",
      "compound: -0.9955, \n",
      "neg: 0.272, \n",
      "neu: 0.623, \n",
      "pos: 0.105, \n",
      "compound: -0.9978, \n",
      "neg: 0.313, \n",
      "neu: 0.593, \n",
      "pos: 0.094, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.997, \n",
      "neg: 0.317, \n",
      "neu: 0.632, \n",
      "pos: 0.051, \n",
      "compound: -0.9921, \n",
      "neg: 0.252, \n",
      "neu: 0.639, \n",
      "pos: 0.109, \n",
      "compound: 0.5423, \n",
      "neg: 0.131, \n",
      "neu: 0.735, \n",
      "pos: 0.134, \n",
      "compound: -0.9982, \n",
      "neg: 0.331, \n",
      "neu: 0.61, \n",
      "pos: 0.059, \n",
      "compound: -0.99, \n",
      "neg: 0.24, \n",
      "neu: 0.633, \n",
      "pos: 0.128, \n",
      "compound: -0.9861, \n",
      "neg: 0.199, \n",
      "neu: 0.713, \n",
      "pos: 0.087, \n",
      "compound: -0.9738, \n",
      "neg: 0.212, \n",
      "neu: 0.642, \n",
      "pos: 0.146, \n",
      "compound: -0.995, \n",
      "neg: 0.236, \n",
      "neu: 0.699, \n",
      "pos: 0.065, \n",
      "compound: -0.9958, \n",
      "neg: 0.274, \n",
      "neu: 0.598, \n",
      "pos: 0.127, \n",
      "compound: -0.9888, \n",
      "neg: 0.2, \n",
      "neu: 0.697, \n",
      "pos: 0.103, \n",
      "compound: -0.6369, \n",
      "neg: 0.165, \n",
      "neu: 0.676, \n",
      "pos: 0.159, \n",
      "compound: -0.9939, \n",
      "neg: 0.245, \n",
      "neu: 0.642, \n",
      "pos: 0.113, \n",
      "compound: -0.9976, \n",
      "neg: 0.335, \n",
      "neu: 0.563, \n",
      "pos: 0.103, \n",
      "compound: -0.9972, \n",
      "neg: 0.288, \n",
      "neu: 0.611, \n",
      "pos: 0.102, \n",
      "compound: -0.9963, \n",
      "neg: 0.276, \n",
      "neu: 0.637, \n",
      "pos: 0.088, \n",
      "compound: -0.9965, \n",
      "neg: 0.235, \n",
      "neu: 0.703, \n",
      "pos: 0.062, \n",
      "compound: -0.9916, \n",
      "neg: 0.225, \n",
      "neu: 0.689, \n",
      "pos: 0.087, \n",
      "compound: -0.992, \n",
      "neg: 0.248, \n",
      "neu: 0.643, \n",
      "pos: 0.109, \n",
      "compound: -0.9945, \n",
      "neg: 0.227, \n",
      "neu: 0.697, \n",
      "pos: 0.076, \n",
      "compound: -0.9853, \n",
      "neg: 0.201, \n",
      "neu: 0.691, \n",
      "pos: 0.108, \n",
      "compound: -0.9819, \n",
      "neg: 0.236, \n",
      "neu: 0.634, \n",
      "pos: 0.13, \n",
      "compound: -0.9967, \n",
      "neg: 0.256, \n",
      "neu: 0.676, \n",
      "pos: 0.068, \n",
      "compound: -0.9959, \n",
      "neg: 0.314, \n",
      "neu: 0.607, \n",
      "pos: 0.079, \n",
      "compound: -0.9935, \n",
      "neg: 0.227, \n",
      "neu: 0.702, \n",
      "pos: 0.071, \n",
      "compound: -0.9903, \n",
      "neg: 0.218, \n",
      "neu: 0.714, \n",
      "pos: 0.068, \n",
      "compound: -0.946, \n",
      "neg: 0.208, \n",
      "neu: 0.644, \n",
      "pos: 0.149, \n",
      "compound: -0.9899, \n",
      "neg: 0.233, \n",
      "neu: 0.68, \n",
      "pos: 0.087, \n",
      "compound: -0.9945, \n",
      "neg: 0.237, \n",
      "neu: 0.681, \n",
      "pos: 0.082, \n",
      "compound: -0.9914, \n",
      "neg: 0.231, \n",
      "neu: 0.667, \n",
      "pos: 0.102, \n",
      "compound: -0.9538, \n",
      "neg: 0.196, \n",
      "neu: 0.664, \n",
      "pos: 0.14, \n",
      "compound: -0.5106, \n",
      "neg: 0.167, \n",
      "neu: 0.663, \n",
      "pos: 0.17, \n",
      "compound: -0.9868, \n",
      "neg: 0.228, \n",
      "neu: 0.646, \n",
      "pos: 0.126, \n",
      "compound: -0.9962, \n",
      "neg: 0.292, \n",
      "neu: 0.62, \n",
      "pos: 0.088, \n",
      "compound: -0.9904, \n",
      "neg: 0.24, \n",
      "neu: 0.655, \n",
      "pos: 0.105, \n",
      "compound: -0.9973, \n",
      "neg: 0.327, \n",
      "neu: 0.541, \n",
      "pos: 0.132, \n",
      "compound: -0.9692, \n",
      "neg: 0.251, \n",
      "neu: 0.544, \n",
      "pos: 0.205, \n",
      "compound: -0.9973, \n",
      "neg: 0.33, \n",
      "neu: 0.604, \n",
      "pos: 0.067, \n",
      "compound: -0.9954, \n",
      "neg: 0.283, \n",
      "neu: 0.651, \n",
      "pos: 0.066, \n",
      "compound: -0.9933, \n",
      "neg: 0.229, \n",
      "neu: 0.675, \n",
      "pos: 0.096, \n",
      "compound: -0.9951, \n",
      "neg: 0.247, \n",
      "neu: 0.656, \n",
      "pos: 0.096, \n",
      "compound: -0.9979, \n",
      "neg: 0.325, \n",
      "neu: 0.577, \n",
      "pos: 0.098, \n",
      "compound: -0.9987, \n",
      "neg: 0.386, \n",
      "neu: 0.565, \n",
      "pos: 0.05, \n",
      "compound: -0.991, \n",
      "neg: 0.283, \n",
      "neu: 0.615, \n",
      "pos: 0.102, \n",
      "compound: -0.9526, \n",
      "neg: 0.158, \n",
      "neu: 0.728, \n",
      "pos: 0.114, \n",
      "compound: -0.9958, \n",
      "neg: 0.26, \n",
      "neu: 0.657, \n",
      "pos: 0.083, \n",
      "compound: -0.9799, \n",
      "neg: 0.227, \n",
      "neu: 0.636, \n",
      "pos: 0.137, \n",
      "compound: -0.9932, \n",
      "neg: 0.245, \n",
      "neu: 0.628, \n",
      "pos: 0.127, \n",
      "compound: -0.9938, \n",
      "neg: 0.273, \n",
      "neu: 0.607, \n",
      "pos: 0.12, \n",
      "compound: -0.9893, \n",
      "neg: 0.248, \n",
      "neu: 0.652, \n",
      "pos: 0.1, \n",
      "compound: -0.9965, \n",
      "neg: 0.281, \n",
      "neu: 0.643, \n",
      "pos: 0.076, \n",
      "compound: -0.9909, \n",
      "neg: 0.273, \n",
      "neu: 0.589, \n",
      "pos: 0.138, \n",
      "compound: -0.9987, \n",
      "neg: 0.379, \n",
      "neu: 0.604, \n",
      "pos: 0.017, \n",
      "compound: -0.9618, \n",
      "neg: 0.187, \n",
      "neu: 0.684, \n",
      "pos: 0.129, \n",
      "compound: -0.9595, \n",
      "neg: 0.194, \n",
      "neu: 0.666, \n",
      "pos: 0.14, \n",
      "compound: -0.9954, \n",
      "neg: 0.244, \n",
      "neu: 0.685, \n",
      "pos: 0.072, \n",
      "compound: -0.9984, \n",
      "neg: 0.346, \n",
      "neu: 0.583, \n",
      "pos: 0.071, \n",
      "compound: -0.9565, \n",
      "neg: 0.143, \n",
      "neu: 0.773, \n",
      "pos: 0.084, \n",
      "compound: -0.9494, \n",
      "neg: 0.159, \n",
      "neu: 0.741, \n",
      "pos: 0.1, \n",
      "compound: -0.9931, \n",
      "neg: 0.258, \n",
      "neu: 0.626, \n",
      "pos: 0.117, \n",
      "compound: -0.9973, \n",
      "neg: 0.295, \n",
      "neu: 0.61, \n",
      "pos: 0.095, \n",
      "compound: -0.9834, \n",
      "neg: 0.205, \n",
      "neu: 0.673, \n",
      "pos: 0.122, \n",
      "compound: -0.9978, \n",
      "neg: 0.305, \n",
      "neu: 0.625, \n",
      "pos: 0.07, \n",
      "compound: -0.9883, \n",
      "neg: 0.203, \n",
      "neu: 0.693, \n",
      "pos: 0.104, \n",
      "compound: -0.998, \n",
      "neg: 0.326, \n",
      "neu: 0.581, \n",
      "pos: 0.094, \n",
      "compound: -0.9895, \n",
      "neg: 0.241, \n",
      "neu: 0.65, \n",
      "pos: 0.108, \n",
      "compound: -0.9979, \n",
      "neg: 0.304, \n",
      "neu: 0.613, \n",
      "pos: 0.083, \n",
      "compound: -0.9952, \n",
      "neg: 0.281, \n",
      "neu: 0.641, \n",
      "pos: 0.078, \n",
      "compound: -0.9952, \n",
      "neg: 0.306, \n",
      "neu: 0.598, \n",
      "pos: 0.096, \n",
      "compound: -0.9909, \n",
      "neg: 0.267, \n",
      "neu: 0.592, \n",
      "pos: 0.141, \n",
      "compound: -0.8992, \n",
      "neg: 0.15, \n",
      "neu: 0.758, \n",
      "pos: 0.093, \n",
      "compound: -0.4809, \n",
      "neg: 0.152, \n",
      "neu: 0.712, \n",
      "pos: 0.136, \n",
      "compound: -0.6486, \n",
      "neg: 0.157, \n",
      "neu: 0.694, \n",
      "pos: 0.149, \n",
      "compound: -0.9965, \n",
      "neg: 0.273, \n",
      "neu: 0.674, \n",
      "pos: 0.052, \n",
      "compound: -0.9879, \n",
      "neg: 0.223, \n",
      "neu: 0.676, \n",
      "pos: 0.101, \n",
      "compound: -0.9739, \n",
      "neg: 0.214, \n",
      "neu: 0.659, \n",
      "pos: 0.127, \n",
      "compound: -0.9886, \n",
      "neg: 0.221, \n",
      "neu: 0.668, \n",
      "pos: 0.111, \n",
      "compound: -0.9769, \n",
      "neg: 0.177, \n",
      "neu: 0.734, \n",
      "pos: 0.089, \n",
      "compound: -0.9945, \n",
      "neg: 0.232, \n",
      "neu: 0.679, \n",
      "pos: 0.09, \n",
      "compound: -0.9947, \n",
      "neg: 0.287, \n",
      "neu: 0.571, \n",
      "pos: 0.141, \n",
      "compound: -0.9886, \n",
      "neg: 0.211, \n",
      "neu: 0.721, \n",
      "pos: 0.068, \n",
      "compound: -0.9958, \n",
      "neg: 0.327, \n",
      "neu: 0.587, \n",
      "pos: 0.086, \n",
      "compound: -0.9477, \n",
      "neg: 0.193, \n",
      "neu: 0.658, \n",
      "pos: 0.149, \n",
      "compound: -0.9783, \n",
      "neg: 0.223, \n",
      "neu: 0.632, \n",
      "pos: 0.145, \n",
      "compound: -0.9903, \n",
      "neg: 0.214, \n",
      "neu: 0.709, \n",
      "pos: 0.077, \n",
      "compound: -0.9957, \n",
      "neg: 0.25, \n",
      "neu: 0.676, \n",
      "pos: 0.074, \n",
      "compound: -0.9552, \n",
      "neg: 0.202, \n",
      "neu: 0.662, \n",
      "pos: 0.136, \n",
      "compound: -0.9959, \n",
      "neg: 0.257, \n",
      "neu: 0.641, \n",
      "pos: 0.102, \n",
      "compound: -0.9694, \n",
      "neg: 0.169, \n",
      "neu: 0.754, \n",
      "pos: 0.077, \n",
      "compound: -0.4767, \n",
      "neg: 0.153, \n",
      "neu: 0.708, \n",
      "pos: 0.138, \n",
      "compound: -0.8074, \n",
      "neg: 0.199, \n",
      "neu: 0.624, \n",
      "pos: 0.177, \n",
      "compound: -0.9712, \n",
      "neg: 0.212, \n",
      "neu: 0.636, \n",
      "pos: 0.152, \n",
      "compound: -0.9966, \n",
      "neg: 0.276, \n",
      "neu: 0.67, \n",
      "pos: 0.054, \n",
      "compound: -0.9935, \n",
      "neg: 0.245, \n",
      "neu: 0.683, \n",
      "pos: 0.073, \n",
      "compound: 0.8555, \n",
      "neg: 0.134, \n",
      "neu: 0.695, \n",
      "pos: 0.171, \n",
      "compound: 0.8898, \n",
      "neg: 0.146, \n",
      "neu: 0.674, \n",
      "pos: 0.18, \n",
      "compound: -0.9934, \n",
      "neg: 0.253, \n",
      "neu: 0.672, \n",
      "pos: 0.075, \n",
      "compound: -0.9976, \n",
      "neg: 0.311, \n",
      "neu: 0.636, \n",
      "pos: 0.053, \n",
      "compound: -0.996, \n",
      "neg: 0.266, \n",
      "neu: 0.627, \n",
      "pos: 0.107, \n",
      "compound: -0.9947, \n",
      "neg: 0.233, \n",
      "neu: 0.682, \n",
      "pos: 0.085, \n",
      "compound: -0.9944, \n",
      "neg: 0.231, \n",
      "neu: 0.672, \n",
      "pos: 0.098, \n",
      "compound: -0.9943, \n",
      "neg: 0.25, \n",
      "neu: 0.66, \n",
      "pos: 0.09, \n",
      "compound: -0.996, \n",
      "neg: 0.262, \n",
      "neu: 0.66, \n",
      "pos: 0.078, \n",
      "compound: -0.9941, \n",
      "neg: 0.245, \n",
      "neu: 0.645, \n",
      "pos: 0.11, \n",
      "compound: -0.991, \n",
      "neg: 0.234, \n",
      "neu: 0.69, \n",
      "pos: 0.076, \n",
      "compound: -0.9957, \n",
      "neg: 0.232, \n",
      "neu: 0.67, \n",
      "pos: 0.097, \n",
      "compound: -0.9896, \n",
      "neg: 0.23, \n",
      "neu: 0.652, \n",
      "pos: 0.118, \n",
      "compound: -0.9951, \n",
      "neg: 0.25, \n",
      "neu: 0.633, \n",
      "pos: 0.117, \n",
      "compound: -0.9963, \n",
      "neg: 0.295, \n",
      "neu: 0.633, \n",
      "pos: 0.072, \n",
      "compound: -0.9738, \n",
      "neg: 0.184, \n",
      "neu: 0.676, \n",
      "pos: 0.14, \n",
      "compound: -0.9947, \n",
      "neg: 0.252, \n",
      "neu: 0.674, \n",
      "pos: 0.074, \n",
      "compound: -0.9796, \n",
      "neg: 0.183, \n",
      "neu: 0.706, \n",
      "pos: 0.112, \n",
      "compound: -0.9924, \n",
      "neg: 0.232, \n",
      "neu: 0.66, \n",
      "pos: 0.108, \n",
      "compound: -0.9623, \n",
      "neg: 0.168, \n",
      "neu: 0.708, \n",
      "pos: 0.125, \n",
      "compound: -0.996, \n",
      "neg: 0.245, \n",
      "neu: 0.649, \n",
      "pos: 0.106, \n",
      "compound: -0.9969, \n",
      "neg: 0.273, \n",
      "neu: 0.644, \n",
      "pos: 0.082, \n",
      "compound: -0.9898, \n",
      "neg: 0.195, \n",
      "neu: 0.729, \n",
      "pos: 0.076, \n",
      "compound: -0.9942, \n",
      "neg: 0.266, \n",
      "neu: 0.622, \n",
      "pos: 0.112, \n",
      "compound: -0.9951, \n",
      "neg: 0.253, \n",
      "neu: 0.673, \n",
      "pos: 0.074, \n",
      "compound: -0.9896, \n",
      "neg: 0.226, \n",
      "neu: 0.683, \n",
      "pos: 0.091, \n",
      "compound: -0.9966, \n",
      "neg: 0.283, \n",
      "neu: 0.653, \n",
      "pos: 0.064, \n",
      "compound: -0.9958, \n",
      "neg: 0.239, \n",
      "neu: 0.694, \n",
      "pos: 0.067, \n",
      "compound: -0.9976, \n",
      "neg: 0.325, \n",
      "neu: 0.621, \n",
      "pos: 0.054, \n",
      "compound: -0.9968, \n",
      "neg: 0.301, \n",
      "neu: 0.581, \n",
      "pos: 0.118, \n",
      "compound: -0.9961, \n",
      "neg: 0.258, \n",
      "neu: 0.639, \n",
      "pos: 0.103, \n",
      "compound: -0.9941, \n",
      "neg: 0.245, \n",
      "neu: 0.64, \n",
      "pos: 0.116, \n",
      "compound: -0.9881, \n",
      "neg: 0.25, \n",
      "neu: 0.654, \n",
      "pos: 0.096, \n",
      "compound: -0.9001, \n",
      "neg: 0.19, \n",
      "neu: 0.668, \n",
      "pos: 0.143, \n",
      "compound: -0.9961, \n",
      "neg: 0.232, \n",
      "neu: 0.698, \n",
      "pos: 0.07, \n",
      "compound: -0.9932, \n",
      "neg: 0.296, \n",
      "neu: 0.576, \n",
      "pos: 0.129, \n",
      "compound: -0.9703, \n",
      "neg: 0.206, \n",
      "neu: 0.665, \n",
      "pos: 0.129, \n",
      "compound: -0.9771, \n",
      "neg: 0.205, \n",
      "neu: 0.702, \n",
      "pos: 0.093, \n",
      "compound: -0.9849, \n",
      "neg: 0.23, \n",
      "neu: 0.637, \n",
      "pos: 0.133, \n",
      "compound: -0.9735, \n",
      "neg: 0.202, \n",
      "neu: 0.681, \n",
      "pos: 0.116, \n",
      "compound: -0.988, \n",
      "neg: 0.228, \n",
      "neu: 0.674, \n",
      "pos: 0.098, \n",
      "compound: -0.996, \n",
      "neg: 0.311, \n",
      "neu: 0.58, \n",
      "pos: 0.109, \n",
      "compound: -0.9854, \n",
      "neg: 0.224, \n",
      "neu: 0.627, \n",
      "pos: 0.149, \n",
      "compound: -0.9221, \n",
      "neg: 0.149, \n",
      "neu: 0.768, \n",
      "pos: 0.083, \n",
      "compound: -0.9979, \n",
      "neg: 0.312, \n",
      "neu: 0.589, \n",
      "pos: 0.098, \n",
      "compound: -0.8625, \n",
      "neg: 0.142, \n",
      "neu: 0.747, \n",
      "pos: 0.111, \n",
      "compound: -0.9929, \n",
      "neg: 0.23, \n",
      "neu: 0.671, \n",
      "pos: 0.099, \n",
      "compound: -0.9723, \n",
      "neg: 0.186, \n",
      "neu: 0.691, \n",
      "pos: 0.123, \n",
      "compound: -0.9966, \n",
      "neg: 0.282, \n",
      "neu: 0.631, \n",
      "pos: 0.087, \n",
      "compound: -0.994, \n",
      "neg: 0.252, \n",
      "neu: 0.676, \n",
      "pos: 0.072, \n",
      "compound: -0.9985, \n",
      "neg: 0.406, \n",
      "neu: 0.548, \n",
      "pos: 0.046, \n",
      "compound: -0.9951, \n",
      "neg: 0.264, \n",
      "neu: 0.679, \n",
      "pos: 0.058, \n",
      "compound: -0.9867, \n",
      "neg: 0.21, \n",
      "neu: 0.676, \n",
      "pos: 0.115, \n",
      "compound: -0.9826, \n",
      "neg: 0.2, \n",
      "neu: 0.677, \n",
      "pos: 0.123, \n",
      "compound: -0.9852, \n",
      "neg: 0.203, \n",
      "neu: 0.687, \n",
      "pos: 0.11, \n",
      "compound: -0.9943, \n",
      "neg: 0.245, \n",
      "neu: 0.68, \n",
      "pos: 0.076, \n",
      "compound: -0.9913, \n",
      "neg: 0.247, \n",
      "neu: 0.652, \n",
      "pos: 0.101, \n",
      "compound: -0.9941, \n",
      "neg: 0.234, \n",
      "neu: 0.7, \n",
      "pos: 0.066, \n",
      "compound: -0.9833, \n",
      "neg: 0.232, \n",
      "neu: 0.648, \n",
      "pos: 0.12, \n",
      "compound: -0.9957, \n",
      "neg: 0.251, \n",
      "neu: 0.653, \n",
      "pos: 0.096, \n",
      "compound: -0.9694, \n",
      "neg: 0.191, \n",
      "neu: 0.661, \n",
      "pos: 0.148, \n",
      "compound: 0.9712, \n",
      "neg: 0.125, \n",
      "neu: 0.67, \n",
      "pos: 0.205, \n",
      "compound: -0.991, \n",
      "neg: 0.216, \n",
      "neu: 0.703, \n",
      "pos: 0.08, \n",
      "compound: -0.802, \n",
      "neg: 0.202, \n",
      "neu: 0.636, \n",
      "pos: 0.162, \n",
      "compound: -0.9882, \n",
      "neg: 0.194, \n",
      "neu: 0.723, \n",
      "pos: 0.083, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: 0.1779, \n",
      "neg: 0.212, \n",
      "neu: 0.591, \n",
      "pos: 0.197, \n",
      "compound: -0.9325, \n",
      "neg: 0.175, \n",
      "neu: 0.688, \n",
      "pos: 0.137, \n",
      "compound: -0.9943, \n",
      "neg: 0.255, \n",
      "neu: 0.664, \n",
      "pos: 0.082, \n",
      "compound: -0.9908, \n",
      "neg: 0.216, \n",
      "neu: 0.677, \n",
      "pos: 0.107, \n",
      "compound: -0.9975, \n",
      "neg: 0.299, \n",
      "neu: 0.646, \n",
      "pos: 0.055, \n",
      "compound: -0.9942, \n",
      "neg: 0.206, \n",
      "neu: 0.717, \n",
      "pos: 0.077, \n",
      "compound: -0.9922, \n",
      "neg: 0.26, \n",
      "neu: 0.63, \n",
      "pos: 0.11, \n",
      "compound: -0.9949, \n",
      "neg: 0.234, \n",
      "neu: 0.683, \n",
      "pos: 0.083, \n",
      "compound: -0.8591, \n",
      "neg: 0.144, \n",
      "neu: 0.735, \n",
      "pos: 0.121, \n",
      "compound: -0.9578, \n",
      "neg: 0.194, \n",
      "neu: 0.663, \n",
      "pos: 0.143, \n",
      "compound: -0.9878, \n",
      "neg: 0.22, \n",
      "neu: 0.669, \n",
      "pos: 0.111, \n",
      "compound: -0.9786, \n",
      "neg: 0.233, \n",
      "neu: 0.644, \n",
      "pos: 0.123, \n",
      "compound: -0.9892, \n",
      "neg: 0.184, \n",
      "neu: 0.742, \n",
      "pos: 0.074, \n",
      "compound: -0.9901, \n",
      "neg: 0.18, \n",
      "neu: 0.721, \n",
      "pos: 0.099, \n",
      "compound: -0.8957, \n",
      "neg: 0.157, \n",
      "neu: 0.714, \n",
      "pos: 0.128, \n",
      "compound: -0.9973, \n",
      "neg: 0.296, \n",
      "neu: 0.624, \n",
      "pos: 0.08, \n",
      "compound: -0.9975, \n",
      "neg: 0.338, \n",
      "neu: 0.594, \n",
      "pos: 0.069, \n",
      "compound: -0.9869, \n",
      "neg: 0.188, \n",
      "neu: 0.741, \n",
      "pos: 0.071, \n",
      "compound: -0.9941, \n",
      "neg: 0.217, \n",
      "neu: 0.721, \n",
      "pos: 0.063, \n",
      "compound: -0.9501, \n",
      "neg: 0.182, \n",
      "neu: 0.697, \n",
      "pos: 0.121, \n",
      "compound: -0.9442, \n",
      "neg: 0.192, \n",
      "neu: 0.655, \n",
      "pos: 0.153, \n",
      "compound: -0.9888, \n",
      "neg: 0.204, \n",
      "neu: 0.677, \n",
      "pos: 0.119, \n",
      "compound: -0.9949, \n",
      "neg: 0.27, \n",
      "neu: 0.626, \n",
      "pos: 0.104, \n",
      "compound: -0.9983, \n",
      "neg: 0.369, \n",
      "neu: 0.564, \n",
      "pos: 0.067, \n",
      "compound: -0.9876, \n",
      "neg: 0.189, \n",
      "neu: 0.718, \n",
      "pos: 0.093, \n",
      "compound: -0.9931, \n",
      "neg: 0.242, \n",
      "neu: 0.653, \n",
      "pos: 0.104, \n",
      "compound: -0.9848, \n",
      "neg: 0.213, \n",
      "neu: 0.66, \n",
      "pos: 0.127, \n",
      "compound: -0.7717, \n",
      "neg: 0.162, \n",
      "neu: 0.704, \n",
      "pos: 0.134, \n",
      "compound: -0.9892, \n",
      "neg: 0.221, \n",
      "neu: 0.653, \n",
      "pos: 0.127, \n",
      "compound: -0.9941, \n",
      "neg: 0.252, \n",
      "neu: 0.641, \n",
      "pos: 0.107, \n",
      "compound: -0.9875, \n",
      "neg: 0.25, \n",
      "neu: 0.599, \n",
      "pos: 0.152, \n",
      "compound: -0.9945, \n",
      "neg: 0.245, \n",
      "neu: 0.635, \n",
      "pos: 0.12, \n",
      "compound: -0.9963, \n",
      "neg: 0.253, \n",
      "neu: 0.654, \n",
      "pos: 0.093, \n",
      "compound: -0.9962, \n",
      "neg: 0.239, \n",
      "neu: 0.69, \n",
      "pos: 0.07, \n",
      "compound: -0.9966, \n",
      "neg: 0.257, \n",
      "neu: 0.661, \n",
      "pos: 0.083, \n",
      "compound: -0.9877, \n",
      "neg: 0.211, \n",
      "neu: 0.679, \n",
      "pos: 0.111, \n",
      "compound: -0.9845, \n",
      "neg: 0.208, \n",
      "neu: 0.683, \n",
      "pos: 0.109, \n",
      "compound: -0.9968, \n",
      "neg: 0.283, \n",
      "neu: 0.645, \n",
      "pos: 0.072, \n",
      "compound: -0.9781, \n",
      "neg: 0.238, \n",
      "neu: 0.629, \n",
      "pos: 0.133, \n",
      "compound: -0.9638, \n",
      "neg: 0.136, \n",
      "neu: 0.788, \n",
      "pos: 0.075, \n",
      "compound: -0.9089, \n",
      "neg: 0.147, \n",
      "neu: 0.725, \n",
      "pos: 0.127, \n",
      "compound: -0.9669, \n",
      "neg: 0.205, \n",
      "neu: 0.681, \n",
      "pos: 0.114, \n",
      "compound: -0.9941, \n",
      "neg: 0.247, \n",
      "neu: 0.664, \n",
      "pos: 0.089, \n",
      "compound: -0.9965, \n",
      "neg: 0.27, \n",
      "neu: 0.65, \n",
      "pos: 0.08, \n",
      "compound: -0.9844, \n",
      "neg: 0.231, \n",
      "neu: 0.668, \n",
      "pos: 0.102, \n",
      "compound: -0.9729, \n",
      "neg: 0.219, \n",
      "neu: 0.615, \n",
      "pos: 0.166, \n",
      "compound: -0.9887, \n",
      "neg: 0.223, \n",
      "neu: 0.671, \n",
      "pos: 0.106, \n",
      "compound: -0.9855, \n",
      "neg: 0.191, \n",
      "neu: 0.711, \n",
      "pos: 0.098, \n",
      "compound: -0.996, \n",
      "neg: 0.294, \n",
      "neu: 0.607, \n",
      "pos: 0.099, \n",
      "compound: -0.9978, \n",
      "neg: 0.314, \n",
      "neu: 0.605, \n",
      "pos: 0.081, \n",
      "compound: -0.996, \n",
      "neg: 0.248, \n",
      "neu: 0.673, \n",
      "pos: 0.079, \n",
      "compound: -0.9884, \n",
      "neg: 0.202, \n",
      "neu: 0.688, \n",
      "pos: 0.11, \n",
      "compound: -0.9971, \n",
      "neg: 0.315, \n",
      "neu: 0.601, \n",
      "pos: 0.084, \n",
      "compound: -0.9949, \n",
      "neg: 0.246, \n",
      "neu: 0.684, \n",
      "pos: 0.07, \n",
      "compound: -0.9402, \n",
      "neg: 0.161, \n",
      "neu: 0.728, \n",
      "pos: 0.111, \n",
      "compound: -0.9952, \n",
      "neg: 0.286, \n",
      "neu: 0.574, \n",
      "pos: 0.14, \n",
      "compound: -0.9909, \n",
      "neg: 0.221, \n",
      "neu: 0.692, \n",
      "pos: 0.087, \n",
      "compound: -0.9944, \n",
      "neg: 0.229, \n",
      "neu: 0.699, \n",
      "pos: 0.073, \n",
      "compound: -0.9944, \n",
      "neg: 0.235, \n",
      "neu: 0.707, \n",
      "pos: 0.058, \n",
      "compound: -0.9913, \n",
      "neg: 0.238, \n",
      "neu: 0.639, \n",
      "pos: 0.123, \n",
      "compound: -0.991, \n",
      "neg: 0.237, \n",
      "neu: 0.651, \n",
      "pos: 0.112, \n",
      "compound: -0.9931, \n",
      "neg: 0.258, \n",
      "neu: 0.61, \n",
      "pos: 0.131, \n",
      "compound: -0.9971, \n",
      "neg: 0.297, \n",
      "neu: 0.573, \n",
      "pos: 0.13, \n",
      "compound: -0.9801, \n",
      "neg: 0.208, \n",
      "neu: 0.661, \n",
      "pos: 0.131, \n",
      "compound: -0.9918, \n",
      "neg: 0.206, \n",
      "neu: 0.72, \n",
      "pos: 0.073, \n",
      "compound: -0.9657, \n",
      "neg: 0.197, \n",
      "neu: 0.679, \n",
      "pos: 0.124, \n",
      "compound: -0.995, \n",
      "neg: 0.265, \n",
      "neu: 0.648, \n",
      "pos: 0.087, \n",
      "compound: -0.9959, \n",
      "neg: 0.236, \n",
      "neu: 0.717, \n",
      "pos: 0.047, \n",
      "compound: -0.9949, \n",
      "neg: 0.264, \n",
      "neu: 0.63, \n",
      "pos: 0.106, \n",
      "compound: -0.9968, \n",
      "neg: 0.291, \n",
      "neu: 0.656, \n",
      "pos: 0.053, \n",
      "compound: -0.988, \n",
      "neg: 0.205, \n",
      "neu: 0.691, \n",
      "pos: 0.104, \n",
      "compound: -0.9971, \n",
      "neg: 0.275, \n",
      "neu: 0.658, \n",
      "pos: 0.067, \n",
      "compound: -0.9793, \n",
      "neg: 0.192, \n",
      "neu: 0.682, \n",
      "pos: 0.127, \n",
      "compound: -0.9923, \n",
      "neg: 0.222, \n",
      "neu: 0.692, \n",
      "pos: 0.086, \n",
      "compound: -0.9954, \n",
      "neg: 0.233, \n",
      "neu: 0.703, \n",
      "pos: 0.064, \n",
      "compound: -0.9925, \n",
      "neg: 0.216, \n",
      "neu: 0.724, \n",
      "pos: 0.06, \n",
      "compound: -0.9981, \n",
      "neg: 0.314, \n",
      "neu: 0.62, \n",
      "pos: 0.066, \n",
      "compound: -0.9792, \n",
      "neg: 0.205, \n",
      "neu: 0.667, \n",
      "pos: 0.129, \n",
      "compound: -0.9933, \n",
      "neg: 0.262, \n",
      "neu: 0.602, \n",
      "pos: 0.136, \n",
      "compound: -0.9431, \n",
      "neg: 0.219, \n",
      "neu: 0.587, \n",
      "pos: 0.194, \n",
      "compound: -0.9678, \n",
      "neg: 0.2, \n",
      "neu: 0.655, \n",
      "pos: 0.145, \n",
      "compound: -0.9808, \n",
      "neg: 0.194, \n",
      "neu: 0.675, \n",
      "pos: 0.131, \n",
      "compound: -0.9946, \n",
      "neg: 0.242, \n",
      "neu: 0.672, \n",
      "pos: 0.086, \n",
      "compound: -0.9905, \n",
      "neg: 0.236, \n",
      "neu: 0.621, \n",
      "pos: 0.143, \n",
      "compound: -0.9936, \n",
      "neg: 0.239, \n",
      "neu: 0.724, \n",
      "pos: 0.037, \n",
      "compound: -0.9726, \n",
      "neg: 0.2, \n",
      "neu: 0.66, \n",
      "pos: 0.139, \n",
      "compound: -0.9958, \n",
      "neg: 0.257, \n",
      "neu: 0.635, \n",
      "pos: 0.108, \n",
      "compound: -0.9953, \n",
      "neg: 0.265, \n",
      "neu: 0.661, \n",
      "pos: 0.074, \n",
      "compound: -0.9948, \n",
      "neg: 0.239, \n",
      "neu: 0.668, \n",
      "pos: 0.093, \n",
      "compound: -0.9951, \n",
      "neg: 0.293, \n",
      "neu: 0.578, \n",
      "pos: 0.129, \n",
      "compound: -0.9944, \n",
      "neg: 0.252, \n",
      "neu: 0.654, \n",
      "pos: 0.093, \n",
      "compound: -0.9894, \n",
      "neg: 0.238, \n",
      "neu: 0.646, \n",
      "pos: 0.117, \n",
      "compound: -0.9823, \n",
      "neg: 0.202, \n",
      "neu: 0.688, \n",
      "pos: 0.111, \n",
      "compound: -0.9492, \n",
      "neg: 0.168, \n",
      "neu: 0.711, \n",
      "pos: 0.121, \n",
      "compound: -0.9818, \n",
      "neg: 0.15, \n",
      "neu: 0.804, \n",
      "pos: 0.046, \n",
      "compound: -0.9727, \n",
      "neg: 0.163, \n",
      "neu: 0.757, \n",
      "pos: 0.081, \n",
      "compound: -0.9747, \n",
      "neg: 0.171, \n",
      "neu: 0.738, \n",
      "pos: 0.091, \n",
      "compound: -0.981, \n",
      "neg: 0.21, \n",
      "neu: 0.655, \n",
      "pos: 0.135, \n",
      "compound: -0.9867, \n",
      "neg: 0.205, \n",
      "neu: 0.692, \n",
      "pos: 0.103, \n",
      "compound: -0.9953, \n",
      "neg: 0.27, \n",
      "neu: 0.66, \n",
      "pos: 0.07, \n",
      "compound: -0.9944, \n",
      "neg: 0.246, \n",
      "neu: 0.714, \n",
      "pos: 0.04, \n",
      "compound: -0.9935, \n",
      "neg: 0.252, \n",
      "neu: 0.648, \n",
      "pos: 0.1, \n",
      "compound: -0.9854, \n",
      "neg: 0.193, \n",
      "neu: 0.73, \n",
      "pos: 0.076, \n",
      "compound: -0.296, \n",
      "neg: 0.1, \n",
      "neu: 0.804, \n",
      "pos: 0.096, \n",
      "compound: -0.9899, \n",
      "neg: 0.223, \n",
      "neu: 0.704, \n",
      "pos: 0.073, \n",
      "compound: -0.9952, \n",
      "neg: 0.268, \n",
      "neu: 0.672, \n",
      "pos: 0.06, \n",
      "compound: -0.9578, \n",
      "neg: 0.19, \n",
      "neu: 0.698, \n",
      "pos: 0.111, \n",
      "compound: -0.9869, \n",
      "neg: 0.203, \n",
      "neu: 0.673, \n",
      "pos: 0.124, \n",
      "compound: -0.9552, \n",
      "neg: 0.149, \n",
      "neu: 0.748, \n",
      "pos: 0.103, \n",
      "compound: -0.9812, \n",
      "neg: 0.166, \n",
      "neu: 0.74, \n",
      "pos: 0.093, \n",
      "compound: -0.9779, \n",
      "neg: 0.183, \n",
      "neu: 0.736, \n",
      "pos: 0.08, \n",
      "compound: -0.9927, \n",
      "neg: 0.263, \n",
      "neu: 0.639, \n",
      "pos: 0.098, \n",
      "compound: -0.9945, \n",
      "neg: 0.231, \n",
      "neu: 0.678, \n",
      "pos: 0.091, \n",
      "compound: -0.9918, \n",
      "neg: 0.233, \n",
      "neu: 0.668, \n",
      "pos: 0.099, \n",
      "compound: -0.9888, \n",
      "neg: 0.203, \n",
      "neu: 0.745, \n",
      "pos: 0.052, \n",
      "compound: -0.9692, \n",
      "neg: 0.185, \n",
      "neu: 0.722, \n",
      "pos: 0.093, \n",
      "compound: -0.9895, \n",
      "neg: 0.231, \n",
      "neu: 0.668, \n",
      "pos: 0.1, \n",
      "compound: -0.9938, \n",
      "neg: 0.203, \n",
      "neu: 0.727, \n",
      "pos: 0.069, \n",
      "compound: -0.9856, \n",
      "neg: 0.174, \n",
      "neu: 0.761, \n",
      "pos: 0.065, \n",
      "compound: -0.9939, \n",
      "neg: 0.208, \n",
      "neu: 0.764, \n",
      "pos: 0.028, \n",
      "compound: -0.99, \n",
      "neg: 0.214, \n",
      "neu: 0.704, \n",
      "pos: 0.082, \n",
      "compound: -0.994, \n",
      "neg: 0.25, \n",
      "neu: 0.658, \n",
      "pos: 0.092, \n",
      "compound: -0.9628, \n",
      "neg: 0.142, \n",
      "neu: 0.768, \n",
      "pos: 0.09, \n",
      "compound: -0.9967, \n",
      "neg: 0.269, \n",
      "neu: 0.623, \n",
      "pos: 0.107, \n",
      "compound: -0.9674, \n",
      "neg: 0.186, \n",
      "neu: 0.684, \n",
      "pos: 0.13, \n",
      "compound: -0.8221, \n",
      "neg: 0.137, \n",
      "neu: 0.747, \n",
      "pos: 0.115, \n",
      "compound: -0.9825, \n",
      "neg: 0.206, \n",
      "neu: 0.675, \n",
      "pos: 0.119, \n",
      "compound: -0.9872, \n",
      "neg: 0.229, \n",
      "neu: 0.664, \n",
      "pos: 0.107, \n",
      "compound: -0.6124, \n",
      "neg: 0.138, \n",
      "neu: 0.746, \n",
      "pos: 0.116, \n",
      "compound: -0.9975, \n",
      "neg: 0.272, \n",
      "neu: 0.645, \n",
      "pos: 0.083, \n",
      "compound: -0.9909, \n",
      "neg: 0.223, \n",
      "neu: 0.682, \n",
      "pos: 0.095, \n",
      "compound: -0.9946, \n",
      "neg: 0.241, \n",
      "neu: 0.704, \n",
      "pos: 0.055, \n",
      "compound: -0.9949, \n",
      "neg: 0.265, \n",
      "neu: 0.651, \n",
      "pos: 0.084, \n",
      "compound: -0.9928, \n",
      "neg: 0.208, \n",
      "neu: 0.744, \n",
      "pos: 0.048, \n",
      "compound: -0.9764, \n",
      "neg: 0.211, \n",
      "neu: 0.681, \n",
      "pos: 0.108, \n",
      "compound: -0.9729, \n",
      "neg: 0.215, \n",
      "neu: 0.646, \n",
      "pos: 0.139, \n",
      "compound: -0.9931, \n",
      "neg: 0.238, \n",
      "neu: 0.683, \n",
      "pos: 0.079, \n",
      "compound: -0.9963, \n",
      "neg: 0.282, \n",
      "neu: 0.638, \n",
      "pos: 0.08, \n",
      "compound: -0.9947, \n",
      "neg: 0.292, \n",
      "neu: 0.583, \n",
      "pos: 0.124, \n",
      "compound: -0.9834, \n",
      "neg: 0.165, \n",
      "neu: 0.796, \n",
      "pos: 0.039, \n",
      "compound: -0.9949, \n",
      "neg: 0.258, \n",
      "neu: 0.671, \n",
      "pos: 0.071, \n",
      "compound: -0.9952, \n",
      "neg: 0.251, \n",
      "neu: 0.689, \n",
      "pos: 0.06, \n",
      "compound: -0.9747, \n",
      "neg: 0.18, \n",
      "neu: 0.731, \n",
      "pos: 0.088, \n",
      "compound: -0.9583, \n",
      "neg: 0.153, \n",
      "neu: 0.77, \n",
      "pos: 0.077, \n",
      "compound: -0.9826, \n",
      "neg: 0.184, \n",
      "neu: 0.744, \n",
      "pos: 0.072, \n",
      "compound: -0.9864, \n",
      "neg: 0.231, \n",
      "neu: 0.626, \n",
      "pos: 0.143, \n",
      "compound: -0.9967, \n",
      "neg: 0.29, \n",
      "neu: 0.647, \n",
      "pos: 0.063, \n",
      "compound: -0.9835, \n",
      "neg: 0.178, \n",
      "neu: 0.738, \n",
      "pos: 0.084, \n",
      "compound: -0.9922, \n",
      "neg: 0.23, \n",
      "neu: 0.694, \n",
      "pos: 0.076, \n",
      "compound: -0.9805, \n",
      "neg: 0.209, \n",
      "neu: 0.659, \n",
      "pos: 0.132, \n",
      "compound: -0.8971, \n",
      "neg: 0.167, \n",
      "neu: 0.71, \n",
      "pos: 0.123, \n",
      "compound: -0.9938, \n",
      "neg: 0.253, \n",
      "neu: 0.669, \n",
      "pos: 0.078, \n",
      "compound: -0.9954, \n",
      "neg: 0.28, \n",
      "neu: 0.586, \n",
      "pos: 0.134, \n",
      "compound: -0.9911, \n",
      "neg: 0.194, \n",
      "neu: 0.747, \n",
      "pos: 0.059, \n",
      "compound: -0.9881, \n",
      "neg: 0.243, \n",
      "neu: 0.638, \n",
      "pos: 0.118, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.9933, \n",
      "neg: 0.245, \n",
      "neu: 0.677, \n",
      "pos: 0.078, \n",
      "compound: -0.9908, \n",
      "neg: 0.29, \n",
      "neu: 0.57, \n",
      "pos: 0.14, \n",
      "compound: -0.9808, \n",
      "neg: 0.173, \n",
      "neu: 0.744, \n",
      "pos: 0.083, \n",
      "compound: -0.9898, \n",
      "neg: 0.21, \n",
      "neu: 0.698, \n",
      "pos: 0.092, \n",
      "compound: -0.9246, \n",
      "neg: 0.15, \n",
      "neu: 0.746, \n",
      "pos: 0.104, \n",
      "compound: -0.4005, \n",
      "neg: 0.134, \n",
      "neu: 0.733, \n",
      "pos: 0.132, \n",
      "compound: -0.9952, \n",
      "neg: 0.244, \n",
      "neu: 0.676, \n",
      "pos: 0.081, \n",
      "compound: -0.9859, \n",
      "neg: 0.219, \n",
      "neu: 0.668, \n",
      "pos: 0.113, \n",
      "compound: -0.9915, \n",
      "neg: 0.219, \n",
      "neu: 0.659, \n",
      "pos: 0.122, \n",
      "compound: -0.9783, \n",
      "neg: 0.18, \n",
      "neu: 0.721, \n",
      "pos: 0.099, \n",
      "compound: -0.9846, \n",
      "neg: 0.169, \n",
      "neu: 0.763, \n",
      "pos: 0.068, \n",
      "compound: -0.9965, \n",
      "neg: 0.295, \n",
      "neu: 0.648, \n",
      "pos: 0.057, \n",
      "compound: -0.9887, \n",
      "neg: 0.198, \n",
      "neu: 0.749, \n",
      "pos: 0.053, \n",
      "compound: -0.7356, \n",
      "neg: 0.174, \n",
      "neu: 0.675, \n",
      "pos: 0.151, \n",
      "compound: -0.969, \n",
      "neg: 0.194, \n",
      "neu: 0.676, \n",
      "pos: 0.13, \n",
      "compound: -0.9951, \n",
      "neg: 0.292, \n",
      "neu: 0.57, \n",
      "pos: 0.138, \n",
      "compound: -0.9774, \n",
      "neg: 0.195, \n",
      "neu: 0.683, \n",
      "pos: 0.122, \n",
      "compound: -0.979, \n",
      "neg: 0.179, \n",
      "neu: 0.731, \n",
      "pos: 0.09, \n",
      "compound: -0.9928, \n",
      "neg: 0.241, \n",
      "neu: 0.691, \n",
      "pos: 0.068, \n",
      "compound: -0.9914, \n",
      "neg: 0.228, \n",
      "neu: 0.672, \n",
      "pos: 0.1, \n",
      "compound: -0.9875, \n",
      "neg: 0.252, \n",
      "neu: 0.584, \n",
      "pos: 0.164, \n",
      "compound: -0.9864, \n",
      "neg: 0.197, \n",
      "neu: 0.72, \n",
      "pos: 0.083, \n",
      "compound: -0.9926, \n",
      "neg: 0.216, \n",
      "neu: 0.711, \n",
      "pos: 0.073, \n",
      "compound: -0.9961, \n",
      "neg: 0.272, \n",
      "neu: 0.684, \n",
      "pos: 0.044, \n",
      "compound: -0.9902, \n",
      "neg: 0.21, \n",
      "neu: 0.697, \n",
      "pos: 0.094, \n",
      "compound: -0.9977, \n",
      "neg: 0.353, \n",
      "neu: 0.59, \n",
      "pos: 0.057, \n",
      "compound: -0.9808, \n",
      "neg: 0.199, \n",
      "neu: 0.712, \n",
      "pos: 0.088, \n",
      "compound: -0.9893, \n",
      "neg: 0.229, \n",
      "neu: 0.661, \n",
      "pos: 0.11, \n",
      "compound: -0.9908, \n",
      "neg: 0.221, \n",
      "neu: 0.681, \n",
      "pos: 0.098, \n",
      "compound: -0.9965, \n",
      "neg: 0.29, \n",
      "neu: 0.667, \n",
      "pos: 0.044, \n",
      "compound: -0.9201, \n",
      "neg: 0.159, \n",
      "neu: 0.719, \n",
      "pos: 0.122, \n",
      "compound: -0.9917, \n",
      "neg: 0.268, \n",
      "neu: 0.638, \n",
      "pos: 0.094, \n",
      "compound: -0.9854, \n",
      "neg: 0.211, \n",
      "neu: 0.7, \n",
      "pos: 0.09, \n",
      "compound: -0.9698, \n",
      "neg: 0.164, \n",
      "neu: 0.734, \n",
      "pos: 0.102, \n",
      "compound: -0.9954, \n",
      "neg: 0.246, \n",
      "neu: 0.694, \n",
      "pos: 0.061, \n",
      "compound: -0.988, \n",
      "neg: 0.231, \n",
      "neu: 0.673, \n",
      "pos: 0.096, \n",
      "compound: -0.9945, \n",
      "neg: 0.253, \n",
      "neu: 0.666, \n",
      "pos: 0.081, \n",
      "compound: -0.9985, \n",
      "neg: 0.351, \n",
      "neu: 0.61, \n",
      "pos: 0.039, \n",
      "compound: -0.9837, \n",
      "neg: 0.246, \n",
      "neu: 0.626, \n",
      "pos: 0.128, \n",
      "compound: -0.9977, \n",
      "neg: 0.336, \n",
      "neu: 0.62, \n",
      "pos: 0.044, \n",
      "compound: -0.998, \n",
      "neg: 0.32, \n",
      "neu: 0.642, \n",
      "pos: 0.038, \n",
      "compound: -0.9879, \n",
      "neg: 0.229, \n",
      "neu: 0.668, \n",
      "pos: 0.103, \n",
      "compound: -0.9814, \n",
      "neg: 0.189, \n",
      "neu: 0.748, \n",
      "pos: 0.064, \n",
      "compound: -0.296, \n",
      "neg: 0.172, \n",
      "neu: 0.676, \n",
      "pos: 0.152, \n",
      "compound: -0.9825, \n",
      "neg: 0.238, \n",
      "neu: 0.636, \n",
      "pos: 0.126, \n",
      "compound: -0.9979, \n",
      "neg: 0.334, \n",
      "neu: 0.625, \n",
      "pos: 0.041, \n",
      "compound: -0.994, \n",
      "neg: 0.26, \n",
      "neu: 0.645, \n",
      "pos: 0.094, \n",
      "compound: -0.995, \n",
      "neg: 0.244, \n",
      "neu: 0.7, \n",
      "pos: 0.056, \n",
      "compound: -0.9812, \n",
      "neg: 0.169, \n",
      "neu: 0.736, \n",
      "pos: 0.095, \n",
      "compound: -0.9981, \n",
      "neg: 0.289, \n",
      "neu: 0.682, \n",
      "pos: 0.029, \n",
      "compound: -0.9933, \n",
      "neg: 0.277, \n",
      "neu: 0.624, \n",
      "pos: 0.1, \n",
      "compound: -0.9842, \n",
      "neg: 0.231, \n",
      "neu: 0.708, \n",
      "pos: 0.061, \n",
      "compound: -0.9957, \n",
      "neg: 0.251, \n",
      "neu: 0.67, \n",
      "pos: 0.079, \n",
      "compound: -0.9801, \n",
      "neg: 0.207, \n",
      "neu: 0.672, \n",
      "pos: 0.12, \n",
      "compound: 0.9513, \n",
      "neg: 0.123, \n",
      "neu: 0.68, \n",
      "pos: 0.197, \n",
      "compound: -0.9732, \n",
      "neg: 0.18, \n",
      "neu: 0.7, \n",
      "pos: 0.12, \n",
      "compound: -0.9891, \n",
      "neg: 0.194, \n",
      "neu: 0.738, \n",
      "pos: 0.068, \n",
      "compound: -0.9871, \n",
      "neg: 0.225, \n",
      "neu: 0.662, \n",
      "pos: 0.113, \n",
      "compound: -0.993, \n",
      "neg: 0.234, \n",
      "neu: 0.67, \n",
      "pos: 0.096, \n",
      "compound: -0.9902, \n",
      "neg: 0.222, \n",
      "neu: 0.694, \n",
      "pos: 0.083, \n",
      "compound: -0.997, \n",
      "neg: 0.294, \n",
      "neu: 0.618, \n",
      "pos: 0.088, \n",
      "compound: -0.9962, \n",
      "neg: 0.284, \n",
      "neu: 0.631, \n",
      "pos: 0.085, \n",
      "compound: -0.9592, \n",
      "neg: 0.171, \n",
      "neu: 0.738, \n",
      "pos: 0.091, \n",
      "compound: -0.9904, \n",
      "neg: 0.248, \n",
      "neu: 0.652, \n",
      "pos: 0.1, \n",
      "compound: -0.9939, \n",
      "neg: 0.217, \n",
      "neu: 0.708, \n",
      "pos: 0.075, \n",
      "compound: -0.9948, \n",
      "neg: 0.267, \n",
      "neu: 0.665, \n",
      "pos: 0.068, \n",
      "compound: -0.9954, \n",
      "neg: 0.283, \n",
      "neu: 0.643, \n",
      "pos: 0.074, \n",
      "compound: -0.9393, \n",
      "neg: 0.183, \n",
      "neu: 0.67, \n",
      "pos: 0.147, \n",
      "compound: -0.9902, \n",
      "neg: 0.269, \n",
      "neu: 0.617, \n",
      "pos: 0.113, \n",
      "compound: -0.9837, \n",
      "neg: 0.206, \n",
      "neu: 0.703, \n",
      "pos: 0.092, \n",
      "compound: -0.9899, \n",
      "neg: 0.213, \n",
      "neu: 0.69, \n",
      "pos: 0.097, \n",
      "compound: -0.9956, \n",
      "neg: 0.25, \n",
      "neu: 0.689, \n",
      "pos: 0.061, \n",
      "compound: -0.9821, \n",
      "neg: 0.174, \n",
      "neu: 0.755, \n",
      "pos: 0.071, \n",
      "compound: -0.34, \n",
      "neg: 0.165, \n",
      "neu: 0.686, \n",
      "pos: 0.149, \n",
      "compound: -0.9771, \n",
      "neg: 0.223, \n",
      "neu: 0.655, \n",
      "pos: 0.122, \n",
      "compound: -0.9926, \n",
      "neg: 0.254, \n",
      "neu: 0.64, \n",
      "pos: 0.107, \n",
      "compound: -0.9769, \n",
      "neg: 0.161, \n",
      "neu: 0.755, \n",
      "pos: 0.084, \n",
      "compound: -0.9042, \n",
      "neg: 0.162, \n",
      "neu: 0.685, \n",
      "pos: 0.152, \n",
      "compound: -0.9925, \n",
      "neg: 0.23, \n",
      "neu: 0.685, \n",
      "pos: 0.085, \n",
      "compound: -0.9902, \n",
      "neg: 0.193, \n",
      "neu: 0.729, \n",
      "pos: 0.078, \n",
      "compound: -0.9391, \n",
      "neg: 0.199, \n",
      "neu: 0.639, \n",
      "pos: 0.162, \n",
      "compound: -0.988, \n",
      "neg: 0.225, \n",
      "neu: 0.663, \n",
      "pos: 0.113, \n",
      "compound: -0.9787, \n",
      "neg: 0.215, \n",
      "neu: 0.684, \n",
      "pos: 0.101, \n",
      "compound: -0.2732, \n",
      "neg: 0.171, \n",
      "neu: 0.649, \n",
      "pos: 0.179, \n",
      "compound: -0.9313, \n",
      "neg: 0.183, \n",
      "neu: 0.677, \n",
      "pos: 0.14, \n",
      "compound: -0.7579, \n",
      "neg: 0.166, \n",
      "neu: 0.672, \n",
      "pos: 0.162, \n",
      "compound: -0.9935, \n",
      "neg: 0.253, \n",
      "neu: 0.651, \n",
      "pos: 0.097, \n",
      "compound: -0.9779, \n",
      "neg: 0.172, \n",
      "neu: 0.72, \n",
      "pos: 0.107, \n",
      "compound: -0.9442, \n",
      "neg: 0.132, \n",
      "neu: 0.783, \n",
      "pos: 0.085, \n",
      "compound: -0.9678, \n",
      "neg: 0.192, \n",
      "neu: 0.672, \n",
      "pos: 0.136, \n",
      "compound: -0.9712, \n",
      "neg: 0.196, \n",
      "neu: 0.693, \n",
      "pos: 0.111, \n",
      "compound: -0.9887, \n",
      "neg: 0.205, \n",
      "neu: 0.705, \n",
      "pos: 0.089, \n",
      "compound: -0.9929, \n",
      "neg: 0.255, \n",
      "neu: 0.646, \n",
      "pos: 0.099, \n",
      "compound: -0.9902, \n",
      "neg: 0.213, \n",
      "neu: 0.675, \n",
      "pos: 0.112, \n",
      "compound: -0.9887, \n",
      "neg: 0.189, \n",
      "neu: 0.732, \n",
      "pos: 0.079, \n",
      "compound: -0.995, \n",
      "neg: 0.278, \n",
      "neu: 0.619, \n",
      "pos: 0.103, \n",
      "compound: -0.9747, \n",
      "neg: 0.179, \n",
      "neu: 0.732, \n",
      "pos: 0.088, \n",
      "compound: -0.9966, \n",
      "neg: 0.33, \n",
      "neu: 0.611, \n",
      "pos: 0.059, \n",
      "compound: -0.9922, \n",
      "neg: 0.225, \n",
      "neu: 0.668, \n",
      "pos: 0.106, \n",
      "compound: 0.9551, \n",
      "neg: 0.101, \n",
      "neu: 0.734, \n",
      "pos: 0.165, \n",
      "compound: -0.9859, \n",
      "neg: 0.207, \n",
      "neu: 0.705, \n",
      "pos: 0.088, \n",
      "compound: -0.9729, \n",
      "neg: 0.212, \n",
      "neu: 0.662, \n",
      "pos: 0.126, \n",
      "compound: -0.9642, \n",
      "neg: 0.203, \n",
      "neu: 0.645, \n",
      "pos: 0.152, \n",
      "compound: -0.9313, \n",
      "neg: 0.188, \n",
      "neu: 0.662, \n",
      "pos: 0.15, \n",
      "compound: -0.9934, \n",
      "neg: 0.277, \n",
      "neu: 0.612, \n",
      "pos: 0.111, \n",
      "compound: -0.9969, \n",
      "neg: 0.283, \n",
      "neu: 0.632, \n",
      "pos: 0.085, \n",
      "compound: -0.9942, \n",
      "neg: 0.288, \n",
      "neu: 0.633, \n",
      "pos: 0.079, \n",
      "compound: -0.128, \n",
      "neg: 0.175, \n",
      "neu: 0.64, \n",
      "pos: 0.185, \n",
      "compound: 0.9818, \n",
      "neg: 0.124, \n",
      "neu: 0.668, \n",
      "pos: 0.208, \n",
      "compound: -0.9905, \n",
      "neg: 0.202, \n",
      "neu: 0.75, \n",
      "pos: 0.048, \n",
      "compound: -0.986, \n",
      "neg: 0.171, \n",
      "neu: 0.762, \n",
      "pos: 0.067, \n",
      "compound: -0.9659, \n",
      "neg: 0.154, \n",
      "neu: 0.774, \n",
      "pos: 0.073, \n",
      "compound: -0.9502, \n",
      "neg: 0.169, \n",
      "neu: 0.732, \n",
      "pos: 0.098, \n",
      "compound: -0.991, \n",
      "neg: 0.251, \n",
      "neu: 0.632, \n",
      "pos: 0.118, \n",
      "compound: -0.9954, \n",
      "neg: 0.264, \n",
      "neu: 0.647, \n",
      "pos: 0.089, \n",
      "compound: -0.9943, \n",
      "neg: 0.207, \n",
      "neu: 0.734, \n",
      "pos: 0.059, \n",
      "compound: -0.9931, \n",
      "neg: 0.25, \n",
      "neu: 0.649, \n",
      "pos: 0.1, \n",
      "compound: -0.7579, \n",
      "neg: 0.141, \n",
      "neu: 0.74, \n",
      "pos: 0.118, \n",
      "compound: -0.9924, \n",
      "neg: 0.26, \n",
      "neu: 0.647, \n",
      "pos: 0.093, \n",
      "compound: -0.959, \n",
      "neg: 0.158, \n",
      "neu: 0.751, \n",
      "pos: 0.091, \n",
      "compound: -0.9919, \n",
      "neg: 0.22, \n",
      "neu: 0.701, \n",
      "pos: 0.078, \n",
      "compound: -0.9729, \n",
      "neg: 0.207, \n",
      "neu: 0.685, \n",
      "pos: 0.108, \n",
      "compound: -0.9969, \n",
      "neg: 0.29, \n",
      "neu: 0.637, \n",
      "pos: 0.073, \n",
      "compound: -0.9829, \n",
      "neg: 0.206, \n",
      "neu: 0.694, \n",
      "pos: 0.1, \n",
      "compound: -0.9983, \n",
      "neg: 0.318, \n",
      "neu: 0.632, \n",
      "pos: 0.05, \n",
      "compound: -0.9952, \n",
      "neg: 0.236, \n",
      "neu: 0.692, \n",
      "pos: 0.072, \n",
      "compound: -0.988, \n",
      "neg: 0.224, \n",
      "neu: 0.7, \n",
      "pos: 0.075, \n",
      "compound: -0.9917, \n",
      "neg: 0.255, \n",
      "neu: 0.611, \n",
      "pos: 0.134, \n",
      "compound: -0.9943, \n",
      "neg: 0.256, \n",
      "neu: 0.654, \n",
      "pos: 0.091, \n",
      "compound: -0.9962, \n",
      "neg: 0.271, \n",
      "neu: 0.648, \n",
      "pos: 0.081, \n",
      "compound: -0.9716, \n",
      "neg: 0.188, \n",
      "neu: 0.707, \n",
      "pos: 0.104, \n",
      "compound: -0.4767, \n",
      "neg: 0.157, \n",
      "neu: 0.699, \n",
      "pos: 0.144, \n",
      "compound: -0.996, \n",
      "neg: 0.212, \n",
      "neu: 0.749, \n",
      "pos: 0.038, \n",
      "compound: -0.9962, \n",
      "neg: 0.234, \n",
      "neu: 0.708, \n",
      "pos: 0.058, \n",
      "compound: -0.9957, \n",
      "neg: 0.268, \n",
      "neu: 0.643, \n",
      "pos: 0.089, \n",
      "compound: -0.9945, \n",
      "neg: 0.255, \n",
      "neu: 0.637, \n",
      "pos: 0.107, \n",
      "compound: -0.99, \n",
      "neg: 0.224, \n",
      "neu: 0.682, \n",
      "pos: 0.095, \n",
      "compound: -0.9973, \n",
      "neg: 0.302, \n",
      "neu: 0.603, \n",
      "pos: 0.094, \n",
      "compound: -0.9937, \n",
      "neg: 0.208, \n",
      "neu: 0.717, \n",
      "pos: 0.075, \n",
      "compound: -0.9831, \n",
      "neg: 0.209, \n",
      "neu: 0.66, \n",
      "pos: 0.131, \n",
      "compound: -0.9937, \n",
      "neg: 0.227, \n",
      "neu: 0.685, \n",
      "pos: 0.088, \n",
      "compound: -0.9979, \n",
      "neg: 0.352, \n",
      "neu: 0.57, \n",
      "pos: 0.079, \n",
      "compound: -0.9965, \n",
      "neg: 0.304, \n",
      "neu: 0.638, \n",
      "pos: 0.058, \n",
      "compound: -0.9974, \n",
      "neg: 0.293, \n",
      "neu: 0.618, \n",
      "pos: 0.089, \n",
      "compound: -0.9906, \n",
      "neg: 0.226, \n",
      "neu: 0.64, \n",
      "pos: 0.134, \n",
      "compound: -0.9921, \n",
      "neg: 0.226, \n",
      "neu: 0.685, \n",
      "pos: 0.089, \n",
      "compound: -0.9915, \n",
      "neg: 0.261, \n",
      "neu: 0.608, \n",
      "pos: 0.131, \n",
      "compound: -0.9914, \n",
      "neg: 0.213, \n",
      "neu: 0.742, \n",
      "pos: 0.046, \n",
      "compound: -0.992, \n",
      "neg: 0.264, \n",
      "neu: 0.586, \n",
      "pos: 0.15, \n",
      "compound: -0.9942, \n",
      "neg: 0.281, \n",
      "neu: 0.632, \n",
      "pos: 0.087, \n",
      "compound: -0.9908, \n",
      "neg: 0.236, \n",
      "neu: 0.663, \n",
      "pos: 0.101, \n",
      "compound: -0.9578, \n",
      "neg: 0.16, \n",
      "neu: 0.751, \n",
      "pos: 0.089, \n"
     ]
    }
   ],
   "source": [
    "replacement_vader_train = df_clean_train.clean.apply(get_vader_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.9933, \n",
      "neg: 0.247, \n",
      "neu: 0.626, \n",
      "pos: 0.126, \n",
      "compound: -0.9974, \n",
      "neg: 0.277, \n",
      "neu: 0.633, \n",
      "pos: 0.09, \n",
      "compound: -0.9935, \n",
      "neg: 0.24, \n",
      "neu: 0.696, \n",
      "pos: 0.065, \n",
      "compound: -0.9958, \n",
      "neg: 0.262, \n",
      "neu: 0.648, \n",
      "pos: 0.091, \n",
      "compound: -0.9985, \n",
      "neg: 0.393, \n",
      "neu: 0.52, \n",
      "pos: 0.087, \n",
      "compound: -0.9976, \n",
      "neg: 0.306, \n",
      "neu: 0.625, \n",
      "pos: 0.069, \n",
      "compound: -0.9957, \n",
      "neg: 0.275, \n",
      "neu: 0.619, \n",
      "pos: 0.106, \n",
      "compound: -0.9956, \n",
      "neg: 0.299, \n",
      "neu: 0.586, \n",
      "pos: 0.115, \n",
      "compound: -0.9987, \n",
      "neg: 0.348, \n",
      "neu: 0.585, \n",
      "pos: 0.067, \n",
      "compound: -0.1027, \n",
      "neg: 0.136, \n",
      "neu: 0.73, \n",
      "pos: 0.134, \n",
      "compound: -0.996, \n",
      "neg: 0.31, \n",
      "neu: 0.543, \n",
      "pos: 0.147, \n",
      "compound: -0.9382, \n",
      "neg: 0.177, \n",
      "neu: 0.693, \n",
      "pos: 0.129, \n",
      "compound: -0.9955, \n",
      "neg: 0.262, \n",
      "neu: 0.647, \n",
      "pos: 0.091, \n",
      "compound: -0.9975, \n",
      "neg: 0.278, \n",
      "neu: 0.68, \n",
      "pos: 0.042, \n",
      "compound: -0.9739, \n",
      "neg: 0.214, \n",
      "neu: 0.64, \n",
      "pos: 0.146, \n",
      "compound: -0.991, \n",
      "neg: 0.239, \n",
      "neu: 0.647, \n",
      "pos: 0.115, \n",
      "compound: -0.9944, \n",
      "neg: 0.302, \n",
      "neu: 0.576, \n",
      "pos: 0.122, \n",
      "compound: -0.9764, \n",
      "neg: 0.19, \n",
      "neu: 0.701, \n",
      "pos: 0.108, \n",
      "compound: -0.9952, \n",
      "neg: 0.279, \n",
      "neu: 0.644, \n",
      "pos: 0.077, \n",
      "compound: -0.9875, \n",
      "neg: 0.174, \n",
      "neu: 0.781, \n",
      "pos: 0.045, \n",
      "compound: -0.9913, \n",
      "neg: 0.214, \n",
      "neu: 0.653, \n",
      "pos: 0.132, \n",
      "compound: -0.9831, \n",
      "neg: 0.193, \n",
      "neu: 0.716, \n",
      "pos: 0.092, \n",
      "compound: -0.9948, \n",
      "neg: 0.288, \n",
      "neu: 0.634, \n",
      "pos: 0.078, \n",
      "compound: -0.25, \n",
      "neg: 0.167, \n",
      "neu: 0.662, \n",
      "pos: 0.171, \n",
      "compound: -0.9468, \n",
      "neg: 0.148, \n",
      "neu: 0.745, \n",
      "pos: 0.107, \n",
      "compound: -0.992, \n",
      "neg: 0.261, \n",
      "neu: 0.632, \n",
      "pos: 0.106, \n",
      "compound: -0.9899, \n",
      "neg: 0.268, \n",
      "neu: 0.584, \n",
      "pos: 0.149, \n",
      "compound: -0.9922, \n",
      "neg: 0.195, \n",
      "neu: 0.758, \n",
      "pos: 0.047, \n",
      "compound: -0.9889, \n",
      "neg: 0.223, \n",
      "neu: 0.707, \n",
      "pos: 0.07, \n",
      "compound: -0.9977, \n",
      "neg: 0.306, \n",
      "neu: 0.63, \n",
      "pos: 0.064, \n",
      "compound: -0.9953, \n",
      "neg: 0.266, \n",
      "neu: 0.647, \n",
      "pos: 0.087, \n",
      "compound: -0.9956, \n",
      "neg: 0.271, \n",
      "neu: 0.648, \n",
      "pos: 0.081, \n",
      "compound: -0.0258, \n",
      "neg: 0.175, \n",
      "neu: 0.648, \n",
      "pos: 0.177, \n",
      "compound: -0.9945, \n",
      "neg: 0.237, \n",
      "neu: 0.678, \n",
      "pos: 0.085, \n",
      "compound: -0.9901, \n",
      "neg: 0.215, \n",
      "neu: 0.698, \n",
      "pos: 0.087, \n",
      "compound: -0.9915, \n",
      "neg: 0.25, \n",
      "neu: 0.646, \n",
      "pos: 0.104, \n",
      "compound: -0.9545, \n",
      "neg: 0.177, \n",
      "neu: 0.692, \n",
      "pos: 0.131, \n",
      "compound: -0.9974, \n",
      "neg: 0.326, \n",
      "neu: 0.621, \n",
      "pos: 0.053, \n",
      "compound: -0.765, \n",
      "neg: 0.128, \n",
      "neu: 0.753, \n",
      "pos: 0.119, \n",
      "compound: -0.9888, \n",
      "neg: 0.217, \n",
      "neu: 0.682, \n",
      "pos: 0.1, \n",
      "compound: -0.6124, \n",
      "neg: 0.168, \n",
      "neu: 0.682, \n",
      "pos: 0.15, \n",
      "compound: -0.9955, \n",
      "neg: 0.238, \n",
      "neu: 0.676, \n",
      "pos: 0.086, \n",
      "compound: -0.9966, \n",
      "neg: 0.246, \n",
      "neu: 0.661, \n",
      "pos: 0.093, \n",
      "compound: -0.9961, \n",
      "neg: 0.264, \n",
      "neu: 0.646, \n",
      "pos: 0.09, \n",
      "compound: -0.9974, \n",
      "neg: 0.309, \n",
      "neu: 0.609, \n",
      "pos: 0.082, \n",
      "compound: -0.9565, \n",
      "neg: 0.195, \n",
      "neu: 0.652, \n",
      "pos: 0.153, \n",
      "compound: -0.91, \n",
      "neg: 0.206, \n",
      "neu: 0.638, \n",
      "pos: 0.156, \n",
      "compound: -0.9932, \n",
      "neg: 0.247, \n",
      "neu: 0.626, \n",
      "pos: 0.126, \n",
      "compound: -0.9887, \n",
      "neg: 0.23, \n",
      "neu: 0.645, \n",
      "pos: 0.126, \n",
      "compound: -0.9879, \n",
      "neg: 0.213, \n",
      "neu: 0.686, \n",
      "pos: 0.101, \n",
      "compound: -0.379, \n",
      "neg: 0.106, \n",
      "neu: 0.781, \n",
      "pos: 0.113, \n",
      "compound: -0.9545, \n",
      "neg: 0.212, \n",
      "neu: 0.64, \n",
      "pos: 0.147, \n",
      "compound: -0.8228, \n",
      "neg: 0.174, \n",
      "neu: 0.675, \n",
      "pos: 0.151, \n",
      "compound: -0.9953, \n",
      "neg: 0.224, \n",
      "neu: 0.702, \n",
      "pos: 0.073, \n",
      "compound: -0.9834, \n",
      "neg: 0.208, \n",
      "neu: 0.718, \n",
      "pos: 0.075, \n",
      "compound: 0.8126, \n",
      "neg: 0.124, \n",
      "neu: 0.725, \n",
      "pos: 0.15, \n",
      "compound: -0.9663, \n",
      "neg: 0.18, \n",
      "neu: 0.703, \n",
      "pos: 0.118, \n",
      "compound: -0.9881, \n",
      "neg: 0.21, \n",
      "neu: 0.695, \n",
      "pos: 0.095, \n",
      "compound: -0.9837, \n",
      "neg: 0.182, \n",
      "neu: 0.722, \n",
      "pos: 0.096, \n",
      "compound: -0.9977, \n",
      "neg: 0.308, \n",
      "neu: 0.633, \n",
      "pos: 0.06, \n",
      "compound: -0.9899, \n",
      "neg: 0.199, \n",
      "neu: 0.723, \n",
      "pos: 0.078, \n",
      "compound: -0.926, \n",
      "neg: 0.188, \n",
      "neu: 0.662, \n",
      "pos: 0.15, \n",
      "compound: -0.9975, \n",
      "neg: 0.281, \n",
      "neu: 0.652, \n",
      "pos: 0.067, \n",
      "compound: -0.9735, \n",
      "neg: 0.197, \n",
      "neu: 0.687, \n",
      "pos: 0.115, \n",
      "compound: -0.9965, \n",
      "neg: 0.287, \n",
      "neu: 0.606, \n",
      "pos: 0.107, \n",
      "compound: -0.986, \n",
      "neg: 0.198, \n",
      "neu: 0.715, \n",
      "pos: 0.087, \n",
      "compound: -0.9896, \n",
      "neg: 0.211, \n",
      "neu: 0.703, \n",
      "pos: 0.086, \n",
      "compound: -0.9842, \n",
      "neg: 0.176, \n",
      "neu: 0.731, \n",
      "pos: 0.093, \n",
      "compound: -0.9847, \n",
      "neg: 0.196, \n",
      "neu: 0.724, \n",
      "pos: 0.08, \n",
      "compound: -0.9741, \n",
      "neg: 0.187, \n",
      "neu: 0.685, \n",
      "pos: 0.129, \n",
      "compound: -0.9967, \n",
      "neg: 0.257, \n",
      "neu: 0.668, \n",
      "pos: 0.075, \n",
      "compound: -0.9756, \n",
      "neg: 0.167, \n",
      "neu: 0.742, \n",
      "pos: 0.092, \n",
      "compound: -0.9779, \n",
      "neg: 0.167, \n",
      "neu: 0.744, \n",
      "pos: 0.09, \n",
      "compound: -0.993, \n",
      "neg: 0.227, \n",
      "neu: 0.687, \n",
      "pos: 0.086, \n",
      "compound: -0.9877, \n",
      "neg: 0.161, \n",
      "neu: 0.783, \n",
      "pos: 0.057, \n",
      "compound: -0.9747, \n",
      "neg: 0.177, \n",
      "neu: 0.716, \n",
      "pos: 0.107, \n",
      "compound: -0.9819, \n",
      "neg: 0.17, \n",
      "neu: 0.726, \n",
      "pos: 0.104, \n",
      "compound: -0.9855, \n",
      "neg: 0.191, \n",
      "neu: 0.708, \n",
      "pos: 0.101, \n",
      "compound: -0.9864, \n",
      "neg: 0.22, \n",
      "neu: 0.683, \n",
      "pos: 0.098, \n",
      "compound: -0.9337, \n",
      "neg: 0.154, \n",
      "neu: 0.718, \n",
      "pos: 0.127, \n",
      "compound: -0.9761, \n",
      "neg: 0.202, \n",
      "neu: 0.674, \n",
      "pos: 0.123, \n",
      "compound: -0.9886, \n",
      "neg: 0.228, \n",
      "neu: 0.669, \n",
      "pos: 0.102, \n",
      "compound: -0.9911, \n",
      "neg: 0.189, \n",
      "neu: 0.765, \n",
      "pos: 0.046, \n",
      "compound: -0.9935, \n",
      "neg: 0.198, \n",
      "neu: 0.739, \n",
      "pos: 0.063, \n",
      "compound: -0.9904, \n",
      "neg: 0.25, \n",
      "neu: 0.624, \n",
      "pos: 0.125, \n",
      "compound: -0.9878, \n",
      "neg: 0.22, \n",
      "neu: 0.682, \n",
      "pos: 0.098, \n",
      "compound: -0.9925, \n",
      "neg: 0.226, \n",
      "neu: 0.723, \n",
      "pos: 0.051, \n",
      "compound: -0.9287, \n",
      "neg: 0.16, \n",
      "neu: 0.731, \n",
      "pos: 0.109, \n",
      "compound: -0.9666, \n",
      "neg: 0.184, \n",
      "neu: 0.674, \n",
      "pos: 0.142, \n",
      "compound: -0.9906, \n",
      "neg: 0.202, \n",
      "neu: 0.735, \n",
      "pos: 0.063, \n",
      "compound: -0.9853, \n",
      "neg: 0.174, \n",
      "neu: 0.749, \n",
      "pos: 0.077, \n",
      "compound: -0.9926, \n",
      "neg: 0.231, \n",
      "neu: 0.688, \n",
      "pos: 0.082, \n",
      "compound: -0.9964, \n",
      "neg: 0.242, \n",
      "neu: 0.681, \n",
      "pos: 0.077, \n",
      "compound: -0.997, \n",
      "neg: 0.318, \n",
      "neu: 0.562, \n",
      "pos: 0.12, \n",
      "compound: -0.9939, \n",
      "neg: 0.221, \n",
      "neu: 0.656, \n",
      "pos: 0.123, \n",
      "compound: -0.9903, \n",
      "neg: 0.217, \n",
      "neu: 0.669, \n",
      "pos: 0.114, \n",
      "compound: -0.1298, \n",
      "neg: 0.114, \n",
      "neu: 0.754, \n",
      "pos: 0.132, \n",
      "compound: -0.4703, \n",
      "neg: 0.116, \n",
      "neu: 0.759, \n",
      "pos: 0.125, \n",
      "compound: -0.9912, \n",
      "neg: 0.212, \n",
      "neu: 0.699, \n",
      "pos: 0.089, \n",
      "compound: -0.9961, \n",
      "neg: 0.291, \n",
      "neu: 0.594, \n",
      "pos: 0.115, \n",
      "compound: -0.985, \n",
      "neg: 0.217, \n",
      "neu: 0.668, \n",
      "pos: 0.115, \n",
      "compound: -0.9875, \n",
      "neg: 0.204, \n",
      "neu: 0.672, \n",
      "pos: 0.124, \n",
      "compound: -0.9972, \n",
      "neg: 0.275, \n",
      "neu: 0.689, \n",
      "pos: 0.036, \n",
      "compound: -0.8743, \n",
      "neg: 0.18, \n",
      "neu: 0.659, \n",
      "pos: 0.16, \n",
      "compound: -0.9796, \n",
      "neg: 0.193, \n",
      "neu: 0.694, \n",
      "pos: 0.114, \n",
      "compound: -0.9382, \n",
      "neg: 0.15, \n",
      "neu: 0.737, \n",
      "pos: 0.113, \n",
      "compound: -0.9674, \n",
      "neg: 0.171, \n",
      "neu: 0.729, \n",
      "pos: 0.1, \n",
      "compound: 0.1793, \n",
      "neg: 0.114, \n",
      "neu: 0.766, \n",
      "pos: 0.12, \n",
      "compound: -0.994, \n",
      "neg: 0.232, \n",
      "neu: 0.652, \n",
      "pos: 0.116, \n",
      "compound: -0.9719, \n",
      "neg: 0.183, \n",
      "neu: 0.714, \n",
      "pos: 0.103, \n",
      "compound: -0.9274, \n",
      "neg: 0.173, \n",
      "neu: 0.686, \n",
      "pos: 0.141, \n",
      "compound: -0.9903, \n",
      "neg: 0.232, \n",
      "neu: 0.637, \n",
      "pos: 0.131, \n",
      "compound: -0.9845, \n",
      "neg: 0.211, \n",
      "neu: 0.691, \n",
      "pos: 0.099, \n",
      "compound: -0.9927, \n",
      "neg: 0.24, \n",
      "neu: 0.647, \n",
      "pos: 0.113, \n",
      "compound: -0.9788, \n",
      "neg: 0.189, \n",
      "neu: 0.724, \n",
      "pos: 0.087, \n",
      "compound: -0.9118, \n",
      "neg: 0.164, \n",
      "neu: 0.706, \n",
      "pos: 0.129, \n",
      "compound: -0.9914, \n",
      "neg: 0.201, \n",
      "neu: 0.71, \n",
      "pos: 0.089, \n",
      "compound: -0.9612, \n",
      "neg: 0.194, \n",
      "neu: 0.664, \n",
      "pos: 0.141, \n",
      "compound: -0.9895, \n",
      "neg: 0.235, \n",
      "neu: 0.643, \n",
      "pos: 0.122, \n",
      "compound: -0.9081, \n",
      "neg: 0.122, \n",
      "neu: 0.793, \n",
      "pos: 0.085, \n",
      "compound: -0.9516, \n",
      "neg: 0.162, \n",
      "neu: 0.73, \n",
      "pos: 0.108, \n",
      "compound: -0.9926, \n",
      "neg: 0.239, \n",
      "neu: 0.708, \n",
      "pos: 0.053, \n",
      "compound: -0.9842, \n",
      "neg: 0.19, \n",
      "neu: 0.706, \n",
      "pos: 0.104, \n",
      "compound: -0.9902, \n",
      "neg: 0.212, \n",
      "neu: 0.697, \n",
      "pos: 0.091, \n",
      "compound: -0.996, \n",
      "neg: 0.263, \n",
      "neu: 0.641, \n",
      "pos: 0.096, \n",
      "compound: -0.9874, \n",
      "neg: 0.212, \n",
      "neu: 0.661, \n",
      "pos: 0.127, \n",
      "compound: -0.9705, \n",
      "neg: 0.191, \n",
      "neu: 0.682, \n",
      "pos: 0.127, \n",
      "compound: -0.9969, \n",
      "neg: 0.28, \n",
      "neu: 0.641, \n",
      "pos: 0.078, \n",
      "compound: -0.7783, \n",
      "neg: 0.159, \n",
      "neu: 0.7, \n",
      "pos: 0.142, \n",
      "compound: -0.9929, \n",
      "neg: 0.251, \n",
      "neu: 0.679, \n",
      "pos: 0.071, \n",
      "compound: -0.9744, \n",
      "neg: 0.216, \n",
      "neu: 0.64, \n",
      "pos: 0.145, \n",
      "compound: -0.9934, \n",
      "neg: 0.242, \n",
      "neu: 0.669, \n",
      "pos: 0.089, \n",
      "compound: -0.0516, \n",
      "neg: 0.174, \n",
      "neu: 0.637, \n",
      "pos: 0.189, \n",
      "compound: -0.9886, \n",
      "neg: 0.219, \n",
      "neu: 0.673, \n",
      "pos: 0.108, \n",
      "compound: -0.42, \n",
      "neg: 0.178, \n",
      "neu: 0.642, \n",
      "pos: 0.179, \n",
      "compound: -0.997, \n",
      "neg: 0.281, \n",
      "neu: 0.62, \n",
      "pos: 0.099, \n",
      "compound: -0.9944, \n",
      "neg: 0.306, \n",
      "neu: 0.571, \n",
      "pos: 0.124, \n",
      "compound: -0.9886, \n",
      "neg: 0.205, \n",
      "neu: 0.695, \n",
      "pos: 0.1, \n",
      "compound: -0.9858, \n",
      "neg: 0.168, \n",
      "neu: 0.755, \n",
      "pos: 0.076, \n",
      "compound: -0.994, \n",
      "neg: 0.207, \n",
      "neu: 0.727, \n",
      "pos: 0.067, \n",
      "compound: -0.9834, \n",
      "neg: 0.172, \n",
      "neu: 0.739, \n",
      "pos: 0.09, \n",
      "compound: -0.9959, \n",
      "neg: 0.242, \n",
      "neu: 0.693, \n",
      "pos: 0.064, \n",
      "compound: -0.994, \n",
      "neg: 0.227, \n",
      "neu: 0.718, \n",
      "pos: 0.055, \n",
      "compound: -0.993, \n",
      "neg: 0.201, \n",
      "neu: 0.729, \n",
      "pos: 0.071, \n",
      "compound: -0.9818, \n",
      "neg: 0.193, \n",
      "neu: 0.693, \n",
      "pos: 0.114, \n",
      "compound: -0.9888, \n",
      "neg: 0.232, \n",
      "neu: 0.645, \n",
      "pos: 0.123, \n",
      "compound: -0.9977, \n",
      "neg: 0.307, \n",
      "neu: 0.627, \n",
      "pos: 0.067, \n",
      "compound: -0.9943, \n",
      "neg: 0.265, \n",
      "neu: 0.616, \n",
      "pos: 0.119, \n",
      "compound: -0.9963, \n",
      "neg: 0.263, \n",
      "neu: 0.662, \n",
      "pos: 0.074, \n",
      "compound: -0.9729, \n",
      "neg: 0.193, \n",
      "neu: 0.657, \n",
      "pos: 0.15, \n",
      "compound: -0.997, \n",
      "neg: 0.249, \n",
      "neu: 0.68, \n",
      "pos: 0.072, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.9657, \n",
      "neg: 0.231, \n",
      "neu: 0.603, \n",
      "pos: 0.167, \n",
      "compound: -0.993, \n",
      "neg: 0.227, \n",
      "neu: 0.666, \n",
      "pos: 0.107, \n",
      "compound: -0.9846, \n",
      "neg: 0.214, \n",
      "neu: 0.694, \n",
      "pos: 0.092, \n",
      "compound: -0.9559, \n",
      "neg: 0.144, \n",
      "neu: 0.757, \n",
      "pos: 0.099, \n",
      "compound: -0.9859, \n",
      "neg: 0.203, \n",
      "neu: 0.698, \n",
      "pos: 0.099, \n",
      "compound: -0.9938, \n",
      "neg: 0.254, \n",
      "neu: 0.666, \n",
      "pos: 0.08, \n",
      "compound: -0.9908, \n",
      "neg: 0.207, \n",
      "neu: 0.732, \n",
      "pos: 0.061, \n",
      "compound: -0.6864, \n",
      "neg: 0.156, \n",
      "neu: 0.704, \n",
      "pos: 0.14, \n",
      "compound: -0.9705, \n",
      "neg: 0.205, \n",
      "neu: 0.643, \n",
      "pos: 0.152, \n",
      "compound: -0.9735, \n",
      "neg: 0.205, \n",
      "neu: 0.619, \n",
      "pos: 0.176, \n",
      "compound: -0.9909, \n",
      "neg: 0.239, \n",
      "neu: 0.669, \n",
      "pos: 0.092, \n",
      "compound: -0.9776, \n",
      "neg: 0.227, \n",
      "neu: 0.62, \n",
      "pos: 0.153, \n",
      "compound: -0.9869, \n",
      "neg: 0.202, \n",
      "neu: 0.693, \n",
      "pos: 0.105, \n",
      "compound: -0.9962, \n",
      "neg: 0.254, \n",
      "neu: 0.675, \n",
      "pos: 0.071, \n",
      "compound: -0.9853, \n",
      "neg: 0.162, \n",
      "neu: 0.787, \n",
      "pos: 0.051, \n",
      "compound: -0.9934, \n",
      "neg: 0.215, \n",
      "neu: 0.692, \n",
      "pos: 0.093, \n",
      "compound: -0.9509, \n",
      "neg: 0.176, \n",
      "neu: 0.69, \n",
      "pos: 0.134, \n",
      "compound: -0.9923, \n",
      "neg: 0.23, \n",
      "neu: 0.679, \n",
      "pos: 0.091, \n",
      "compound: -0.9559, \n",
      "neg: 0.186, \n",
      "neu: 0.681, \n",
      "pos: 0.133, \n",
      "compound: -0.9751, \n",
      "neg: 0.192, \n",
      "neu: 0.685, \n",
      "pos: 0.123, \n",
      "compound: -0.9921, \n",
      "neg: 0.213, \n",
      "neu: 0.69, \n",
      "pos: 0.098, \n",
      "compound: -0.4023, \n",
      "neg: 0.16, \n",
      "neu: 0.686, \n",
      "pos: 0.155, \n",
      "compound: -0.9915, \n",
      "neg: 0.234, \n",
      "neu: 0.641, \n",
      "pos: 0.126, \n",
      "compound: -0.9814, \n",
      "neg: 0.222, \n",
      "neu: 0.635, \n",
      "pos: 0.142, \n",
      "compound: -0.9538, \n",
      "neg: 0.215, \n",
      "neu: 0.619, \n",
      "pos: 0.166, \n",
      "compound: -0.9723, \n",
      "neg: 0.17, \n",
      "neu: 0.744, \n",
      "pos: 0.086, \n",
      "compound: -0.9705, \n",
      "neg: 0.227, \n",
      "neu: 0.603, \n",
      "pos: 0.17, \n",
      "compound: -0.9783, \n",
      "neg: 0.224, \n",
      "neu: 0.623, \n",
      "pos: 0.152, \n",
      "compound: -0.9732, \n",
      "neg: 0.197, \n",
      "neu: 0.705, \n",
      "pos: 0.098, \n",
      "compound: -0.9738, \n",
      "neg: 0.193, \n",
      "neu: 0.674, \n",
      "pos: 0.133, \n",
      "compound: -0.9779, \n",
      "neg: 0.173, \n",
      "neu: 0.75, \n",
      "pos: 0.077, \n",
      "compound: -0.9643, \n",
      "neg: 0.185, \n",
      "neu: 0.68, \n",
      "pos: 0.136, \n",
      "compound: -0.9971, \n",
      "neg: 0.286, \n",
      "neu: 0.657, \n",
      "pos: 0.057, \n",
      "compound: -0.9607, \n",
      "neg: 0.159, \n",
      "neu: 0.767, \n",
      "pos: 0.075, \n",
      "compound: -0.9371, \n",
      "neg: 0.205, \n",
      "neu: 0.642, \n",
      "pos: 0.153, \n",
      "compound: -0.9876, \n",
      "neg: 0.182, \n",
      "neu: 0.706, \n",
      "pos: 0.112, \n",
      "compound: -0.9859, \n",
      "neg: 0.206, \n",
      "neu: 0.678, \n",
      "pos: 0.116, \n",
      "compound: -0.9776, \n",
      "neg: 0.202, \n",
      "neu: 0.717, \n",
      "pos: 0.081, \n",
      "compound: -0.9974, \n",
      "neg: 0.281, \n",
      "neu: 0.656, \n",
      "pos: 0.062, \n",
      "compound: -0.9865, \n",
      "neg: 0.225, \n",
      "neu: 0.659, \n",
      "pos: 0.116, \n",
      "compound: -0.9907, \n",
      "neg: 0.202, \n",
      "neu: 0.71, \n",
      "pos: 0.088, \n",
      "compound: 0.4434, \n",
      "neg: 0.152, \n",
      "neu: 0.696, \n",
      "pos: 0.152, \n",
      "compound: -0.989, \n",
      "neg: 0.235, \n",
      "neu: 0.657, \n",
      "pos: 0.108, \n",
      "compound: -0.959, \n",
      "neg: 0.184, \n",
      "neu: 0.699, \n",
      "pos: 0.117, \n",
      "compound: -0.9933, \n",
      "neg: 0.229, \n",
      "neu: 0.695, \n",
      "pos: 0.076, \n",
      "compound: -0.9643, \n",
      "neg: 0.173, \n",
      "neu: 0.744, \n",
      "pos: 0.083, \n",
      "compound: -0.9922, \n",
      "neg: 0.227, \n",
      "neu: 0.636, \n",
      "pos: 0.137, \n",
      "compound: -0.9836, \n",
      "neg: 0.207, \n",
      "neu: 0.668, \n",
      "pos: 0.125, \n",
      "compound: -0.9628, \n",
      "neg: 0.23, \n",
      "neu: 0.621, \n",
      "pos: 0.149, \n",
      "compound: -0.9951, \n",
      "neg: 0.26, \n",
      "neu: 0.639, \n",
      "pos: 0.1, \n",
      "compound: -0.9846, \n",
      "neg: 0.192, \n",
      "neu: 0.722, \n",
      "pos: 0.087, \n",
      "compound: -0.9873, \n",
      "neg: 0.188, \n",
      "neu: 0.709, \n",
      "pos: 0.102, \n",
      "compound: -0.9911, \n",
      "neg: 0.233, \n",
      "neu: 0.643, \n",
      "pos: 0.124, \n",
      "compound: -0.9971, \n",
      "neg: 0.287, \n",
      "neu: 0.629, \n",
      "pos: 0.084, \n",
      "compound: -0.9876, \n",
      "neg: 0.212, \n",
      "neu: 0.713, \n",
      "pos: 0.075, \n",
      "compound: -0.9864, \n",
      "neg: 0.203, \n",
      "neu: 0.702, \n",
      "pos: 0.095, \n",
      "compound: -0.9825, \n",
      "neg: 0.198, \n",
      "neu: 0.703, \n",
      "pos: 0.099, \n",
      "compound: -0.9538, \n",
      "neg: 0.18, \n",
      "neu: 0.677, \n",
      "pos: 0.143, \n",
      "compound: -0.9904, \n",
      "neg: 0.22, \n",
      "neu: 0.696, \n",
      "pos: 0.085, \n",
      "compound: -0.9781, \n",
      "neg: 0.223, \n",
      "neu: 0.668, \n",
      "pos: 0.109, \n",
      "compound: -0.9857, \n",
      "neg: 0.203, \n",
      "neu: 0.683, \n",
      "pos: 0.114, \n",
      "compound: -0.992, \n",
      "neg: 0.231, \n",
      "neu: 0.658, \n",
      "pos: 0.111, \n",
      "compound: -0.9847, \n",
      "neg: 0.206, \n",
      "neu: 0.694, \n",
      "pos: 0.1, \n",
      "compound: -0.9808, \n",
      "neg: 0.195, \n",
      "neu: 0.693, \n",
      "pos: 0.112, \n",
      "compound: -0.9943, \n",
      "neg: 0.263, \n",
      "neu: 0.649, \n",
      "pos: 0.088, \n",
      "compound: -0.9965, \n",
      "neg: 0.288, \n",
      "neu: 0.619, \n",
      "pos: 0.093, \n",
      "compound: -0.9484, \n",
      "neg: 0.167, \n",
      "neu: 0.72, \n",
      "pos: 0.113, \n",
      "compound: -0.9633, \n",
      "neg: 0.186, \n",
      "neu: 0.69, \n",
      "pos: 0.124, \n",
      "compound: -0.9967, \n",
      "neg: 0.264, \n",
      "neu: 0.701, \n",
      "pos: 0.035, \n",
      "compound: -0.9957, \n",
      "neg: 0.295, \n",
      "neu: 0.666, \n",
      "pos: 0.038, \n",
      "compound: -0.9963, \n",
      "neg: 0.333, \n",
      "neu: 0.51, \n",
      "pos: 0.157, \n",
      "compound: -0.9982, \n",
      "neg: 0.358, \n",
      "neu: 0.595, \n",
      "pos: 0.047, \n",
      "compound: -0.9986, \n",
      "neg: 0.359, \n",
      "neu: 0.589, \n",
      "pos: 0.052, \n",
      "compound: -0.9943, \n",
      "neg: 0.267, \n",
      "neu: 0.596, \n",
      "pos: 0.138, \n",
      "compound: -0.9939, \n",
      "neg: 0.266, \n",
      "neu: 0.631, \n",
      "pos: 0.103, \n",
      "compound: -0.9873, \n",
      "neg: 0.243, \n",
      "neu: 0.643, \n",
      "pos: 0.114, \n",
      "compound: -0.9872, \n",
      "neg: 0.232, \n",
      "neu: 0.684, \n",
      "pos: 0.084, \n",
      "compound: -0.9786, \n",
      "neg: 0.194, \n",
      "neu: 0.715, \n",
      "pos: 0.091, \n",
      "compound: -0.4745, \n",
      "neg: 0.123, \n",
      "neu: 0.758, \n",
      "pos: 0.119, \n",
      "compound: -0.9758, \n",
      "neg: 0.183, \n",
      "neu: 0.715, \n",
      "pos: 0.102, \n",
      "compound: -0.6369, \n",
      "neg: 0.155, \n",
      "neu: 0.703, \n",
      "pos: 0.142, \n",
      "compound: -0.9942, \n",
      "neg: 0.242, \n",
      "neu: 0.681, \n",
      "pos: 0.076, \n",
      "compound: -0.9904, \n",
      "neg: 0.238, \n",
      "neu: 0.643, \n",
      "pos: 0.119, \n",
      "compound: -0.9927, \n",
      "neg: 0.263, \n",
      "neu: 0.655, \n",
      "pos: 0.082, \n",
      "compound: -0.9952, \n",
      "neg: 0.224, \n",
      "neu: 0.696, \n",
      "pos: 0.08, \n",
      "compound: -0.9925, \n",
      "neg: 0.248, \n",
      "neu: 0.652, \n",
      "pos: 0.1, \n",
      "compound: -0.9963, \n",
      "neg: 0.278, \n",
      "neu: 0.625, \n",
      "pos: 0.097, \n",
      "compound: -0.9951, \n",
      "neg: 0.245, \n",
      "neu: 0.695, \n",
      "pos: 0.061, \n",
      "compound: -0.9922, \n",
      "neg: 0.203, \n",
      "neu: 0.76, \n",
      "pos: 0.036, \n",
      "compound: -0.9858, \n",
      "neg: 0.216, \n",
      "neu: 0.661, \n",
      "pos: 0.123, \n",
      "compound: -0.9468, \n",
      "neg: 0.163, \n",
      "neu: 0.719, \n",
      "pos: 0.118, \n",
      "compound: -0.9889, \n",
      "neg: 0.237, \n",
      "neu: 0.661, \n",
      "pos: 0.102, \n",
      "compound: -0.9847, \n",
      "neg: 0.202, \n",
      "neu: 0.718, \n",
      "pos: 0.08, \n",
      "compound: -0.9666, \n",
      "neg: 0.212, \n",
      "neu: 0.658, \n",
      "pos: 0.129, \n",
      "compound: -0.9944, \n",
      "neg: 0.28, \n",
      "neu: 0.653, \n",
      "pos: 0.067, \n",
      "compound: -0.994, \n",
      "neg: 0.243, \n",
      "neu: 0.653, \n",
      "pos: 0.104, \n",
      "compound: -0.9975, \n",
      "neg: 0.291, \n",
      "neu: 0.642, \n",
      "pos: 0.067, \n",
      "compound: -0.9953, \n",
      "neg: 0.238, \n",
      "neu: 0.718, \n",
      "pos: 0.044, \n",
      "compound: -0.9842, \n",
      "neg: 0.207, \n",
      "neu: 0.689, \n",
      "pos: 0.104, \n",
      "compound: -0.9875, \n",
      "neg: 0.25, \n",
      "neu: 0.621, \n",
      "pos: 0.128, \n",
      "compound: -0.9538, \n",
      "neg: 0.211, \n",
      "neu: 0.622, \n",
      "pos: 0.167, \n",
      "compound: -0.9853, \n",
      "neg: 0.182, \n",
      "neu: 0.77, \n",
      "pos: 0.048, \n",
      "compound: -0.9979, \n",
      "neg: 0.298, \n",
      "neu: 0.622, \n",
      "pos: 0.08, \n",
      "compound: -0.9973, \n",
      "neg: 0.333, \n",
      "neu: 0.605, \n",
      "pos: 0.061, \n",
      "compound: -0.9942, \n",
      "neg: 0.255, \n",
      "neu: 0.622, \n",
      "pos: 0.123, \n",
      "compound: -0.9882, \n",
      "neg: 0.205, \n",
      "neu: 0.704, \n",
      "pos: 0.091, \n",
      "compound: -0.9939, \n",
      "neg: 0.244, \n",
      "neu: 0.723, \n",
      "pos: 0.033, \n",
      "compound: -0.9661, \n",
      "neg: 0.22, \n",
      "neu: 0.651, \n",
      "pos: 0.129, \n",
      "compound: -0.9393, \n",
      "neg: 0.208, \n",
      "neu: 0.622, \n",
      "pos: 0.17, \n",
      "compound: -0.9952, \n",
      "neg: 0.275, \n",
      "neu: 0.672, \n",
      "pos: 0.054, \n",
      "compound: -0.9964, \n",
      "neg: 0.313, \n",
      "neu: 0.641, \n",
      "pos: 0.046, \n",
      "compound: -0.9933, \n",
      "neg: 0.298, \n",
      "neu: 0.565, \n",
      "pos: 0.137, \n",
      "compound: -0.9871, \n",
      "neg: 0.201, \n",
      "neu: 0.73, \n",
      "pos: 0.069, \n",
      "compound: -0.9682, \n",
      "neg: 0.135, \n",
      "neu: 0.779, \n",
      "pos: 0.086, \n",
      "compound: -0.9967, \n",
      "neg: 0.291, \n",
      "neu: 0.636, \n",
      "pos: 0.073, \n",
      "compound: -0.9955, \n",
      "neg: 0.247, \n",
      "neu: 0.684, \n",
      "pos: 0.069, \n",
      "compound: -0.9973, \n",
      "neg: 0.309, \n",
      "neu: 0.602, \n",
      "pos: 0.089, \n",
      "compound: -0.9955, \n",
      "neg: 0.264, \n",
      "neu: 0.657, \n",
      "pos: 0.079, \n",
      "compound: -0.7269, \n",
      "neg: 0.155, \n",
      "neu: 0.698, \n",
      "pos: 0.147, \n",
      "compound: -0.9876, \n",
      "neg: 0.261, \n",
      "neu: 0.606, \n",
      "pos: 0.133, \n",
      "compound: -0.9552, \n",
      "neg: 0.171, \n",
      "neu: 0.702, \n",
      "pos: 0.127, \n",
      "compound: -0.9643, \n",
      "neg: 0.167, \n",
      "neu: 0.714, \n",
      "pos: 0.119, \n",
      "compound: -0.9918, \n",
      "neg: 0.25, \n",
      "neu: 0.632, \n",
      "pos: 0.117, \n",
      "compound: -0.9729, \n",
      "neg: 0.161, \n",
      "neu: 0.732, \n",
      "pos: 0.107, \n",
      "compound: -0.9836, \n",
      "neg: 0.176, \n",
      "neu: 0.746, \n",
      "pos: 0.078, \n",
      "compound: -0.9846, \n",
      "neg: 0.221, \n",
      "neu: 0.661, \n",
      "pos: 0.118, \n",
      "compound: -0.9897, \n",
      "neg: 0.224, \n",
      "neu: 0.694, \n",
      "pos: 0.083, \n",
      "compound: -0.9943, \n",
      "neg: 0.276, \n",
      "neu: 0.64, \n",
      "pos: 0.084, \n",
      "compound: -0.9954, \n",
      "neg: 0.226, \n",
      "neu: 0.735, \n",
      "pos: 0.039, \n",
      "compound: -0.9786, \n",
      "neg: 0.167, \n",
      "neu: 0.753, \n",
      "pos: 0.08, \n",
      "compound: -0.9442, \n",
      "neg: 0.16, \n",
      "neu: 0.733, \n",
      "pos: 0.107, \n",
      "compound: -0.993, \n",
      "neg: 0.23, \n",
      "neu: 0.695, \n",
      "pos: 0.076, \n",
      "compound: -0.9942, \n",
      "neg: 0.261, \n",
      "neu: 0.657, \n",
      "pos: 0.082, \n",
      "compound: -0.9941, \n",
      "neg: 0.246, \n",
      "neu: 0.706, \n",
      "pos: 0.048, \n",
      "compound: -0.9917, \n",
      "neg: 0.216, \n",
      "neu: 0.705, \n",
      "pos: 0.079, \n",
      "compound: -0.9871, \n",
      "neg: 0.213, \n",
      "neu: 0.69, \n",
      "pos: 0.098, \n",
      "compound: -0.9943, \n",
      "neg: 0.265, \n",
      "neu: 0.635, \n",
      "pos: 0.101, \n",
      "compound: -0.9623, \n",
      "neg: 0.201, \n",
      "neu: 0.653, \n",
      "pos: 0.146, \n",
      "compound: -0.9953, \n",
      "neg: 0.228, \n",
      "neu: 0.705, \n",
      "pos: 0.066, \n",
      "compound: -0.994, \n",
      "neg: 0.247, \n",
      "neu: 0.639, \n",
      "pos: 0.113, \n",
      "compound: -0.9955, \n",
      "neg: 0.274, \n",
      "neu: 0.633, \n",
      "pos: 0.093, \n",
      "compound: -0.9816, \n",
      "neg: 0.18, \n",
      "neu: 0.727, \n",
      "pos: 0.093, \n",
      "compound: -0.9935, \n",
      "neg: 0.249, \n",
      "neu: 0.651, \n",
      "pos: 0.1, \n",
      "compound: -0.9962, \n",
      "neg: 0.266, \n",
      "neu: 0.676, \n",
      "pos: 0.057, \n",
      "compound: -0.8316, \n",
      "neg: 0.127, \n",
      "neu: 0.756, \n",
      "pos: 0.117, \n",
      "compound: -0.9938, \n",
      "neg: 0.228, \n",
      "neu: 0.699, \n",
      "pos: 0.073, \n",
      "compound: -0.986, \n",
      "neg: 0.22, \n",
      "neu: 0.661, \n",
      "pos: 0.118, \n",
      "compound: -0.9982, \n",
      "neg: 0.335, \n",
      "neu: 0.579, \n",
      "pos: 0.086, \n",
      "compound: -0.9941, \n",
      "neg: 0.27, \n",
      "neu: 0.628, \n",
      "pos: 0.102, \n",
      "compound: -0.994, \n",
      "neg: 0.234, \n",
      "neu: 0.68, \n",
      "pos: 0.086, \n",
      "compound: -0.9945, \n",
      "neg: 0.278, \n",
      "neu: 0.609, \n",
      "pos: 0.113, \n",
      "compound: -0.9698, \n",
      "neg: 0.158, \n",
      "neu: 0.779, \n",
      "pos: 0.064, \n",
      "compound: -0.979, \n",
      "neg: 0.16, \n",
      "neu: 0.756, \n",
      "pos: 0.084, \n",
      "compound: -0.9977, \n",
      "neg: 0.302, \n",
      "neu: 0.627, \n",
      "pos: 0.072, \n",
      "compound: -0.9933, \n",
      "neg: 0.255, \n",
      "neu: 0.678, \n",
      "pos: 0.067, \n",
      "compound: -0.9983, \n",
      "neg: 0.372, \n",
      "neu: 0.553, \n",
      "pos: 0.075, \n",
      "compound: -0.9942, \n",
      "neg: 0.263, \n",
      "neu: 0.626, \n",
      "pos: 0.111, \n",
      "compound: -0.9951, \n",
      "neg: 0.297, \n",
      "neu: 0.604, \n",
      "pos: 0.098, \n",
      "compound: -0.9823, \n",
      "neg: 0.185, \n",
      "neu: 0.71, \n",
      "pos: 0.105, \n",
      "compound: -0.991, \n",
      "neg: 0.219, \n",
      "neu: 0.715, \n",
      "pos: 0.066, \n",
      "compound: -0.9945, \n",
      "neg: 0.262, \n",
      "neu: 0.612, \n",
      "pos: 0.126, \n",
      "compound: -0.9915, \n",
      "neg: 0.227, \n",
      "neu: 0.667, \n",
      "pos: 0.106, \n",
      "compound: -0.9868, \n",
      "neg: 0.179, \n",
      "neu: 0.731, \n",
      "pos: 0.09, \n",
      "compound: -0.9902, \n",
      "neg: 0.185, \n",
      "neu: 0.758, \n",
      "pos: 0.058, \n",
      "compound: -0.9776, \n",
      "neg: 0.167, \n",
      "neu: 0.772, \n",
      "pos: 0.062, \n",
      "compound: -0.9559, \n",
      "neg: 0.168, \n",
      "neu: 0.778, \n",
      "pos: 0.054, \n",
      "compound: -0.9485, \n",
      "neg: 0.202, \n",
      "neu: 0.666, \n",
      "pos: 0.133, \n",
      "compound: -0.9392, \n",
      "neg: 0.172, \n",
      "neu: 0.706, \n",
      "pos: 0.122, \n",
      "compound: -0.9877, \n",
      "neg: 0.24, \n",
      "neu: 0.632, \n",
      "pos: 0.128, \n",
      "compound: -0.9794, \n",
      "neg: 0.186, \n",
      "neu: 0.726, \n",
      "pos: 0.087, \n",
      "compound: -0.9931, \n",
      "neg: 0.279, \n",
      "neu: 0.626, \n",
      "pos: 0.095, \n",
      "compound: -0.9941, \n",
      "neg: 0.221, \n",
      "neu: 0.721, \n",
      "pos: 0.058, \n",
      "compound: -0.9818, \n",
      "neg: 0.16, \n",
      "neu: 0.805, \n",
      "pos: 0.035, \n",
      "compound: -0.9938, \n",
      "neg: 0.24, \n",
      "neu: 0.651, \n",
      "pos: 0.109, \n",
      "compound: -0.9862, \n",
      "neg: 0.194, \n",
      "neu: 0.712, \n",
      "pos: 0.094, \n",
      "compound: -0.9864, \n",
      "neg: 0.225, \n",
      "neu: 0.662, \n",
      "pos: 0.113, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.9517, \n",
      "neg: 0.16, \n",
      "neu: 0.747, \n",
      "pos: 0.094, \n",
      "compound: -0.8957, \n",
      "neg: 0.202, \n",
      "neu: 0.629, \n",
      "pos: 0.168, \n",
      "compound: -0.9929, \n",
      "neg: 0.211, \n",
      "neu: 0.71, \n",
      "pos: 0.079, \n",
      "compound: -0.9952, \n",
      "neg: 0.298, \n",
      "neu: 0.613, \n",
      "pos: 0.089, \n",
      "compound: -0.9887, \n",
      "neg: 0.205, \n",
      "neu: 0.705, \n",
      "pos: 0.09, \n",
      "compound: -0.9821, \n",
      "neg: 0.205, \n",
      "neu: 0.669, \n",
      "pos: 0.126, \n",
      "compound: -0.9906, \n",
      "neg: 0.178, \n",
      "neu: 0.776, \n",
      "pos: 0.046, \n",
      "compound: -0.9943, \n",
      "neg: 0.234, \n",
      "neu: 0.704, \n",
      "pos: 0.062, \n",
      "compound: -0.9764, \n",
      "neg: 0.233, \n",
      "neu: 0.603, \n",
      "pos: 0.164, \n",
      "compound: -0.9968, \n",
      "neg: 0.297, \n",
      "neu: 0.626, \n",
      "pos: 0.076, \n",
      "compound: -0.9969, \n",
      "neg: 0.304, \n",
      "neu: 0.645, \n",
      "pos: 0.05, \n",
      "compound: -0.9949, \n",
      "neg: 0.23, \n",
      "neu: 0.712, \n",
      "pos: 0.058, \n",
      "compound: -0.8752, \n",
      "neg: 0.17, \n",
      "neu: 0.686, \n",
      "pos: 0.144, \n",
      "compound: -0.9957, \n",
      "neg: 0.275, \n",
      "neu: 0.626, \n",
      "pos: 0.099, \n",
      "compound: -0.959, \n",
      "neg: 0.158, \n",
      "neu: 0.738, \n",
      "pos: 0.104, \n",
      "compound: -0.992, \n",
      "neg: 0.199, \n",
      "neu: 0.733, \n",
      "pos: 0.068, \n",
      "compound: 0.8176, \n",
      "neg: 0.098, \n",
      "neu: 0.772, \n",
      "pos: 0.13, \n",
      "compound: -0.994, \n",
      "neg: 0.228, \n",
      "neu: 0.68, \n",
      "pos: 0.093, \n",
      "compound: -0.9726, \n",
      "neg: 0.152, \n",
      "neu: 0.761, \n",
      "pos: 0.088, \n",
      "compound: -0.9325, \n",
      "neg: 0.16, \n",
      "neu: 0.729, \n",
      "pos: 0.112, \n",
      "compound: -0.9951, \n",
      "neg: 0.268, \n",
      "neu: 0.644, \n",
      "pos: 0.088, \n",
      "compound: -0.9883, \n",
      "neg: 0.214, \n",
      "neu: 0.7, \n",
      "pos: 0.085, \n",
      "compound: -0.9969, \n",
      "neg: 0.277, \n",
      "neu: 0.647, \n",
      "pos: 0.076, \n",
      "compound: -0.9812, \n",
      "neg: 0.183, \n",
      "neu: 0.73, \n",
      "pos: 0.087, \n",
      "compound: -0.9971, \n",
      "neg: 0.278, \n",
      "neu: 0.646, \n",
      "pos: 0.076, \n",
      "compound: -0.9684, \n",
      "neg: 0.161, \n",
      "neu: 0.749, \n",
      "pos: 0.089, \n",
      "compound: -0.9941, \n",
      "neg: 0.215, \n",
      "neu: 0.692, \n",
      "pos: 0.093, \n",
      "compound: -0.9874, \n",
      "neg: 0.216, \n",
      "neu: 0.662, \n",
      "pos: 0.122, \n",
      "compound: -0.997, \n",
      "neg: 0.265, \n",
      "neu: 0.658, \n",
      "pos: 0.077, \n",
      "compound: -0.9974, \n",
      "neg: 0.307, \n",
      "neu: 0.606, \n",
      "pos: 0.087, \n",
      "compound: -0.93, \n",
      "neg: 0.173, \n",
      "neu: 0.696, \n",
      "pos: 0.131, \n",
      "compound: -0.9951, \n",
      "neg: 0.248, \n",
      "neu: 0.667, \n",
      "pos: 0.085, \n",
      "compound: -0.9908, \n",
      "neg: 0.209, \n",
      "neu: 0.711, \n",
      "pos: 0.079, \n",
      "compound: -0.9623, \n",
      "neg: 0.216, \n",
      "neu: 0.627, \n",
      "pos: 0.158, \n",
      "compound: -0.9842, \n",
      "neg: 0.206, \n",
      "neu: 0.667, \n",
      "pos: 0.127, \n",
      "compound: -0.9918, \n",
      "neg: 0.225, \n",
      "neu: 0.656, \n",
      "pos: 0.119, \n",
      "compound: -0.9851, \n",
      "neg: 0.245, \n",
      "neu: 0.604, \n",
      "pos: 0.152, \n",
      "compound: -0.9862, \n",
      "neg: 0.209, \n",
      "neu: 0.685, \n",
      "pos: 0.107, \n",
      "compound: -0.9948, \n",
      "neg: 0.259, \n",
      "neu: 0.679, \n",
      "pos: 0.061, \n",
      "compound: -0.9959, \n",
      "neg: 0.231, \n",
      "neu: 0.712, \n",
      "pos: 0.057, \n",
      "compound: -0.9956, \n",
      "neg: 0.289, \n",
      "neu: 0.62, \n",
      "pos: 0.092, \n",
      "compound: -0.9987, \n",
      "neg: 0.334, \n",
      "neu: 0.582, \n",
      "pos: 0.083, \n",
      "compound: -0.9967, \n",
      "neg: 0.282, \n",
      "neu: 0.611, \n",
      "pos: 0.107, \n",
      "compound: -0.9638, \n",
      "neg: 0.158, \n",
      "neu: 0.731, \n",
      "pos: 0.111, \n",
      "compound: -0.9921, \n",
      "neg: 0.251, \n",
      "neu: 0.634, \n",
      "pos: 0.115, \n",
      "compound: -0.8885, \n",
      "neg: 0.14, \n",
      "neu: 0.801, \n",
      "pos: 0.06, \n",
      "compound: -0.9509, \n",
      "neg: 0.216, \n",
      "neu: 0.639, \n",
      "pos: 0.144, \n",
      "compound: 0.25, \n",
      "neg: 0.146, \n",
      "neu: 0.692, \n",
      "pos: 0.162, \n",
      "compound: -0.9899, \n",
      "neg: 0.273, \n",
      "neu: 0.579, \n",
      "pos: 0.148, \n",
      "compound: -0.9971, \n",
      "neg: 0.305, \n",
      "neu: 0.597, \n",
      "pos: 0.097, \n",
      "compound: -0.9935, \n",
      "neg: 0.271, \n",
      "neu: 0.596, \n",
      "pos: 0.133, \n"
     ]
    }
   ],
   "source": [
    "replacement_vader_test = df_clean_test.clean.apply(get_vader_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.309</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.9972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.9899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.290</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.9942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.9485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.279</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.9883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos     com\n",
       "0  0.309  0.651  0.041 -0.9972\n",
       "1  0.300  0.609  0.090 -0.9899\n",
       "2  0.290  0.619  0.091 -0.9942\n",
       "3  0.196  0.700  0.104 -0.9485\n",
       "4  0.279  0.597  0.124 -0.9883"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df_vader_train = pd.DataFrame(list(replacement_vader_train),columns=['neg','neu','pos','com'])\n",
    "replacement_df_vader_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.247</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.9933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.277</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.9974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.240</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-0.9935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.262</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.9958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.393</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.9985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos     com\n",
       "0  0.247  0.626  0.126 -0.9933\n",
       "1  0.277  0.633  0.090 -0.9974\n",
       "2  0.240  0.696  0.065 -0.9935\n",
       "3  0.262  0.648  0.091 -0.9958\n",
       "4  0.393  0.520  0.087 -0.9985"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df_vader_test = pd.DataFrame(list(replacement_vader_test),columns=['neg','neu','pos','com'])\n",
    "replacement_df_vader_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vader_model = LogisticRegression()\n",
    "vader_LR = vader_model.fit(replacement_df_vader_train[['neg','neu','pos','com']],train_target3)\n",
    "vader_predictions = vader_LR.predict(replacement_df_vader_train[['neg','neu','pos','com']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1\n",
       "0   6  732\n",
       "1  10  863"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.539417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.541066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.988545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.699352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.539417\n",
       "precision  0.541066\n",
       "recall     0.988545\n",
       "f1         0.699352"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = vader_predictions\n",
    "y_test = train_target3\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(train_target3, vader_predictions))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_predictions_test = vader_LR.predict(replacement_df_vader_test[['neg','neu','pos','com']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1\n",
       "0  0  186\n",
       "1  1  191"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.505291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.506631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.994792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.671353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.505291\n",
       "precision  0.506631\n",
       "recall     0.994792\n",
       "f1         0.671353"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = vader_predictions_test\n",
    "y_test = test_target3\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(test_target3, vader_predictions_test))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_vader_model = XGBClassifier()\n",
    "XGB_vader = xgb_vader_model.fit(replacement_df_vader_train[['neg','neu','pos','com']],train_target3)\n",
    "XGB_vader_predictions = XGB_vader.predict(replacement_df_vader_train[['neg','neu','pos','com']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_vader_predictions_test = XGB_vader.predict(replacement_df_vader_test[['neg','neu','pos','com']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>683</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  683   55\n",
       "1   25  848"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.950341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.939092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.971363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.954955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.950341\n",
       "precision  0.939092\n",
       "recall     0.971363\n",
       "f1         0.954955"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = XGB_vader_predictions \n",
    "y_test = train_target3\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(train_target3, XGB_vader_predictions))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1\n",
       "0  72  114\n",
       "1  74  118"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.502646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.508621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.614583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.556604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.502646\n",
       "precision  0.508621\n",
       "recall     0.614583\n",
       "f1         0.556604"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = XGB_vader_predictions_test\n",
    "y_test = test_target3\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(test_target3, XGB_vader_predictions_test))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42, 0.58, 0.0, -0.9785]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_vader_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>georgia down russian warplane country brink wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will not america nato help will not help help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remember adorable year old sing open ceremony ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u s refuse israel weapon attack iran report ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expert admit legalise drug war south osetia pi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean\n",
       "0  georgia down russian warplane country brink wa...\n",
       "1  will not america nato help will not help help ...\n",
       "2  remember adorable year old sing open ceremony ...\n",
       "3    u s refuse israel weapon attack iran report ...\n",
       "4  expert admit legalise drug war south osetia pi..."
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using original dataset without cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vader_comp(sent):\n",
    "    # Polarity score returns dictionary\n",
    "    ss = sid.polarity_scores(sent)\n",
    "    return ss['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_data_pre(train,test,num_news):\n",
    "    replacement_comp_train = train.iloc[:,:num_news].applymap(lambda sent: get_vader_comp(sent[2:]))\n",
    "    \n",
    "    replacement_comp_test = test.iloc[:,:num_news].applymap(lambda sent: get_vader_comp(sent))\n",
    "    \n",
    "    return replacement_comp_train, replacement_comp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_comp_train, replacement_comp_test = original_data_pre(train3,test3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>Top9</th>\n",
       "      <th>Top10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>-0.7089</td>\n",
       "      <td>-0.9260</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>-0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8156</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>-0.1965</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>-0.3578</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.7845</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.6908</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>-0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.7184</td>\n",
       "      <td>-0.8074</td>\n",
       "      <td>-0.6369</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2023</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>-0.8689</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>-0.6369</td>\n",
       "      <td>0.7177</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>-0.6808</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Top1    Top2    Top3    Top4    Top5    Top6    Top7    Top8    Top9  \\\n",
       "0 -0.5994  0.0000 -0.3612 -0.7089 -0.9260  0.0000 -0.2732  0.2144 -0.5719   \n",
       "1  0.8156 -0.3182  0.4404 -0.1965  0.0000 -0.4939 -0.5106 -0.0772 -0.3578   \n",
       "2  0.0258  0.0000 -0.7845 -0.6124  0.0000 -0.6908 -0.5994 -0.5994  0.3400   \n",
       "3 -0.7184 -0.8074 -0.6369 -0.1280 -0.5106  0.0000  0.2960  0.0000  0.3612   \n",
       "4  0.2023 -0.5994  0.6808 -0.8689 -0.6124 -0.6369  0.7177 -0.4404 -0.6808   \n",
       "\n",
       "    Top10  \n",
       "0 -0.5994  \n",
       "1 -0.3400  \n",
       "2 -0.7650  \n",
       "3  0.0000  \n",
       "4 -0.3400  "
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_comp_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = list(replacement_comp_train.columns)\n",
    "xgb_vader_comp_model = XGBClassifier()\n",
    "XGB_vader_comp = xgb_vader_comp_model.fit(replacement_comp_train[train_columns],train_target3)\n",
    "XGB_vader_comp_predictions = XGB_vader_comp.predict(replacement_comp_train[train_columns])\n",
    "XGB_vader_comp_predictions_test = XGB_vader_comp.predict(replacement_comp_test[train_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  738    0\n",
       "1    0  873"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           scores\n",
       "accuracy      1.0\n",
       "precision     1.0\n",
       "recall        1.0\n",
       "f1            1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = XGB_vader_comp_predictions\n",
    "y_test = train_target3\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(train_target3, XGB_vader_comp_predictions))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1\n",
       "0  74  112\n",
       "1  83  109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.484127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.493213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.567708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.527845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.484127\n",
       "precision  0.493213\n",
       "recall     0.567708\n",
       "f1         0.527845"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = XGB_vader_comp_predictions_test\n",
    "y_test = test_target3\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(test_target3, XGB_vader_comp_predictions_test))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method XGBModel.get_xgb_params of XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)>"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_vader_comp.get_xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_vader_comp = Pipeline(steps=[('classifier', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_vader_comp_param_grid ={\n",
    "              'classifier__objective':['binary:logistic'],\n",
    "              'classifier__learning_rate': [0.05,0.1,0.2,0.3], #so called `eta` value\n",
    "              'classifier__max_depth': [3,4,5,6],\n",
    "              'classifier__min_child_weight': [1,2,3],\n",
    "              'classifier__subsample': [0.6,0.8],\n",
    "              'classifier__colsample_bytree': [0.5,0.6,0.7],\n",
    "              'classifier__n_estimators': [100,200,300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__colsample_bytree': 0.6, 'classifier__learning_rate': 0.3, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 100, 'classifier__objective': 'binary:logistic', 'classifier__subsample': 0.6}\n",
      "Training accuracy:0.544\n",
      "Validation accuracy: 0.492\n"
     ]
    }
   ],
   "source": [
    "xgb_vader_comp_CV = GridSearchCV(xgb_vader_comp, xgb_vader_comp_param_grid, n_jobs= 1)\n",
    "                  \n",
    "xgb_vader_comp_CV.fit(replacement_comp_train[train_columns],train_target3)  \n",
    "print(xgb_vader_comp_CV.best_params_)    \n",
    "print('Training accuracy:{0:.3f}'.format(xgb_vader_comp_CV.best_score_))\n",
    "print('Validation accuracy: {0:.3f}'.format(xgb_vader_comp_CV.best_estimator_.score(replacement_comp_test[train_columns],test_target3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So far, using XGB with unsupervised learning method (replace the each row whole sentence with positive and negative rate) in 20 news has the best result, over 74% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging sentiment scores and tfidf scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product of such 2 sentence vectors indicated whether overall sentiment was positive or negative (if the dot product was positive, the sentiment was positive, and in opposite case negative).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, file_weighting.clean, train_target3]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence', 'Label']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')\n",
    "replacement_df['sentiment'] = [1 if i==1 else 0 for i in replacement_df.Label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_coeff</th>\n",
       "      <th>tfidf_scores</th>\n",
       "      <th>sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>sentiment_rate</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-142.1863987647491, -140.5523584750102, -156....</td>\n",
       "      <td>[0.5105704172594034, 0.06648350506076688, 0.13...</td>\n",
       "      <td>georgia down russian warplane country brink wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>-898.290050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[145.37944654182874, -152.51986983618497, 149....</td>\n",
       "      <td>[0.10832823308845663, 0.10453405524416867, 0.0...</td>\n",
       "      <td>will not america nato help will not help help ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-650.214101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[162.70933776169736, 0, 151.806102333611, 148....</td>\n",
       "      <td>[0.11590573395133728, 0.19129616038259348, 0.0...</td>\n",
       "      <td>remember adorable year old sing open ceremony ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-881.077992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[152.81848857763183, -154.00723882950746, -153...</td>\n",
       "      <td>[0, 0, 0.042449700664268675, 0.053936316992438...</td>\n",
       "      <td>u s refuse israel weapon attack iran report ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-905.747513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-154.6357345800872, -156.77102601241518, 145....</td>\n",
       "      <td>[0.05553088482662119, 0.048169094930495183, 0....</td>\n",
       "      <td>expert admit legalise drug war south osetia pi...</td>\n",
       "      <td>1</td>\n",
       "      <td>-450.907357</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[128.57193760182696, -146.91414969500678, 142....</td>\n",
       "      <td>[0.0822750516310815, 0.04833963154368387, 0.04...</td>\n",
       "      <td>mom miss gay man bad year old cheerleader look...</td>\n",
       "      <td>1</td>\n",
       "      <td>-662.719122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[143.5473212015681, -135.45704788965222, 141.9...</td>\n",
       "      <td>[0.05770520656116902, 0.052360168984172006, 0....</td>\n",
       "      <td>afghan prison majority female prisoner serve y...</td>\n",
       "      <td>0</td>\n",
       "      <td>-35.558920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-148.17636178568966, -150.1901158506081, 149....</td>\n",
       "      <td>[0.031659371722355806, 0.03888473398247044, 0....</td>\n",
       "      <td>man arrest lock hour take photo police van ign...</td>\n",
       "      <td>0</td>\n",
       "      <td>-208.938989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-160.2465177128263, 149.7288617974364, 146.67...</td>\n",
       "      <td>[0.1580628915813233, 0.07799189835771139, 0.06...</td>\n",
       "      <td>elderly chinese woman sentence year education ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-227.615542</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-151.47629079271653, -157.00683331729218, -15...</td>\n",
       "      <td>[0.03752408111597063, 0.05624397466095859, 0.0...</td>\n",
       "      <td>british resident hold guantanamo bay win legal...</td>\n",
       "      <td>1</td>\n",
       "      <td>-456.619639</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentiment_coeff  \\\n",
       "0  [-142.1863987647491, -140.5523584750102, -156....   \n",
       "1  [145.37944654182874, -152.51986983618497, 149....   \n",
       "2  [162.70933776169736, 0, 151.806102333611, 148....   \n",
       "3  [152.81848857763183, -154.00723882950746, -153...   \n",
       "4  [-154.6357345800872, -156.77102601241518, 145....   \n",
       "5  [128.57193760182696, -146.91414969500678, 142....   \n",
       "6  [143.5473212015681, -135.45704788965222, 141.9...   \n",
       "7  [-148.17636178568966, -150.1901158506081, 149....   \n",
       "8  [-160.2465177128263, 149.7288617974364, 146.67...   \n",
       "9  [-151.47629079271653, -157.00683331729218, -15...   \n",
       "\n",
       "                                        tfidf_scores  \\\n",
       "0  [0.5105704172594034, 0.06648350506076688, 0.13...   \n",
       "1  [0.10832823308845663, 0.10453405524416867, 0.0...   \n",
       "2  [0.11590573395133728, 0.19129616038259348, 0.0...   \n",
       "3  [0, 0, 0.042449700664268675, 0.053936316992438...   \n",
       "4  [0.05553088482662119, 0.048169094930495183, 0....   \n",
       "5  [0.0822750516310815, 0.04833963154368387, 0.04...   \n",
       "6  [0.05770520656116902, 0.052360168984172006, 0....   \n",
       "7  [0.031659371722355806, 0.03888473398247044, 0....   \n",
       "8  [0.1580628915813233, 0.07799189835771139, 0.06...   \n",
       "9  [0.03752408111597063, 0.05624397466095859, 0.0...   \n",
       "\n",
       "                                            sentence Label  sentiment_rate  \\\n",
       "0  georgia down russian warplane country brink wa...     0     -898.290050   \n",
       "1  will not america nato help will not help help ...     1     -650.214101   \n",
       "2  remember adorable year old sing open ceremony ...     0     -881.077992   \n",
       "3    u s refuse israel weapon attack iran report ...     0     -905.747513   \n",
       "4  expert admit legalise drug war south osetia pi...     1     -450.907357   \n",
       "5  mom miss gay man bad year old cheerleader look...     1     -662.719122   \n",
       "6  afghan prison majority female prisoner serve y...     0      -35.558920   \n",
       "7  man arrest lock hour take photo police van ign...     0     -208.938989   \n",
       "8  elderly chinese woman sentence year education ...     1     -227.615542   \n",
       "9  british resident hold guantanamo bay win legal...     1     -456.619639   \n",
       "\n",
       "   prediction  sentiment  \n",
       "0           0          0  \n",
       "1           0          1  \n",
       "2           0          0  \n",
       "3           0          0  \n",
       "4           0          1  \n",
       "5           0          1  \n",
       "6           0          0  \n",
       "7           0          0  \n",
       "8           0          1  \n",
       "9           0          1  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>357</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  357  381\n",
       "1  439  434"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.490999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.532515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.497136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.514218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.490999\n",
       "precision  0.532515\n",
       "recall     0.497136\n",
       "f1         0.514218"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_classes = replacement_df.prediction\n",
    "y_test = replacement_df.sentiment\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(replacement_df.sentiment, replacement_df.prediction))\n",
    "print('Confusion Matrix')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
